{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 944030,
          "sourceType": "datasetVersion",
          "datasetId": 511638
        }
      ],
      "dockerImageVersionId": 29855,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Content:\n",
        "### 1. EDA\n",
        "\n",
        "https://www.sciencedirect.com/science/article/pii/S2352340918315191"
      ],
      "metadata": {
        "id": "msYIKFG802LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup, data inspection and cleanup are hidden for easier reading. Click the Code/Output buttons if you are curious."
      ],
      "metadata": {
        "id": "mdNPv-_u02LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eli5\n"
      ],
      "metadata": {
        "id": "MkK4fxOn2cVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "iw_uMZlX-x6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap --no-cache-dir\n"
      ],
      "metadata": {
        "id": "MGy-BaQvZTsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boruta\n"
      ],
      "metadata": {
        "id": "sLLArWL3sfdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Optuna"
      ],
      "metadata": {
        "id": "3rrvCPhUP6RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-tabnet\n"
      ],
      "metadata": {
        "id": "Tb9Qyp9fG0ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "# common:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import folium\n",
        "\n",
        "# for ML:\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import eli5 # Feature importance evaluation    cannot use, ignore\n",
        "\n",
        "\n",
        "\n",
        "# set some display options:\n",
        "sns.set(style=\"whitegrid\")\n",
        "pd.set_option(\"display.max_columns\", 36)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "H43cDti902LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data from drive"
      ],
      "metadata": {
        "id": "rcGdzf0v4Zpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "Q0wGvSp84g3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 設置 .zip 文件和解壓縮後的目錄路徑\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Hotel cancellation prediction/Dataset.zip'  # 請根據你的文件夾名稱和文件名修改此路徑\n",
        "extract_to = '/content/drive/MyDrive/Colab Notebooks/Hotel cancellation prediction'  # 可以是同一個文件夾，或者新建一個文件夾\n",
        "\n",
        "# 解壓縮文件\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# 列出解壓縮後的文件以確認\n",
        "os.listdir(extract_to)\n"
      ],
      "metadata": {
        "id": "8ilcrqL74g6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# 读取数据文件\n",
        "try:\n",
        "    data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Hotel cancellation prediction/hotel_bookings.csv')\n",
        "    print(data.head())  # 查看数据的前几行以确认加载成功\n",
        "except FileNotFoundError:\n",
        "    print(f'文件未找到：{data_path}')\n",
        "except Exception as e:\n",
        "    print(f'读取数据时发生错误：{e}')\n"
      ],
      "metadata": {
        "id": "BN3Smn1p6BDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_types=data.dtypes\n",
        "print(\"\\nData Types：\")\n",
        "print(data_types)"
      ],
      "metadata": {
        "id": "0Y8584WW7VuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing value"
      ],
      "metadata": {
        "id": "thR4f6qrJraE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "zuZJLbQs02LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values:\n",
        "# agent: If no agency is given, booking was most likely made without one.\n",
        "# company: If none given, it was most likely private.\n",
        "# rest should be self-explanatory.\n",
        "nan_replacements = {\"children:\": 0.0,\"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\n",
        "data_cln = data.fillna(nan_replacements)\n",
        "\n",
        "# \"meal\" contains values \"Undefined\", which is equal to SC.\n",
        "data_cln[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n",
        "\n",
        "# Some rows contain entreis with 0 adults, 0 children and 0 babies.\n",
        "# I'm dropping these entries with no guests.\n",
        "zero_guests = list(data_cln.loc[data_cln[\"adults\"]\n",
        "                   + data_cln[\"children\"]\n",
        "                   + data_cln[\"babies\"]==0].index)\n",
        "data_cln.drop(data_cln.index[zero_guests], inplace=True)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "ODHbNoSm02LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data_cln.isnull().sum())\n"
      ],
      "metadata": {
        "id": "VWr47RequrDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cln['children'].fillna(0.0, inplace=True)\n"
      ],
      "metadata": {
        "id": "pwVoQgCPojfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_cln['children'].isnull().sum())\n"
      ],
      "metadata": {
        "id": "ngQwa0b3onat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# double check\n",
        "print(data_cln.isnull().sum())\n"
      ],
      "metadata": {
        "id": "vonqfXyPpA-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How much data is left?\n",
        "data_cln.shape"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "eqdwOL7F02LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.EDA\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WAXuB9ZK02LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After cleaning, separate Resort and City hotel\n",
        "# To know the acutal visitor numbers, only bookings that were not canceled are included.\n",
        "rh = data_cln.loc[(data_cln[\"hotel\"] == \"Resort Hotel\") & (data_cln[\"is_canceled\"] == 0)]\n",
        "ch = data_cln.loc[(data_cln[\"hotel\"] == \"City Hotel\") & (data_cln[\"is_canceled\"] == 0)]"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "HRMLG32p02La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bookings by market segment"
      ],
      "metadata": {
        "id": "uPjeCXKM02Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total bookings per market segment (incl. canceled)\n",
        "segments=data_cln[\"market_segment\"].value_counts()\n",
        "\n",
        "# pie plot\n",
        "fig = px.pie(segments,\n",
        "             values=segments.values,\n",
        "             names=segments.index,\n",
        "             title=\"Bookings per market segment\",\n",
        "             template=\"seaborn\")\n",
        "fig.update_traces(rotation=-90, textinfo=\"percent+label\")\n",
        "fig.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "WF9vJUR702Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total bookings per market segment (incl. canceled)\n",
        "segments=data_cln[\"market_segment\"].value_counts()\n",
        "\n",
        "# pie plot\n",
        "fig = px.pie(segments,\n",
        "             values=segments.values,\n",
        "             names=segments.index,\n",
        "             title=\"Bookings per market segment\",\n",
        "             template=\"seaborn\")\n",
        "fig.update_traces(rotation=-90, textinfo=\"percent+label\")\n",
        "fig.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "DJatAFtPRBr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# First, separate bookings for City Hotel and Resort Hotel including cancelled ones\n",
        "city_hotel_segments = data_cln[data_cln[\"hotel\"] == \"City Hotel\"][\"market_segment\"].value_counts()\n",
        "resort_hotel_segments = data_cln[data_cln[\"hotel\"] == \"Resort Hotel\"][\"market_segment\"].value_counts()\n",
        "\n",
        "# Pie chart for City Hotel\n",
        "fig_city = px.pie(names=city_hotel_segments.index, values=city_hotel_segments.values,\n",
        "                  title=\"City Hotel - Bookings per Market Segment\",\n",
        "                  template=\"seaborn\")\n",
        "fig_city.update_traces(rotation=-90, textinfo=\"percent+label\")\n",
        "fig_city.show()\n",
        "\n",
        "# Pie chart for Resort Hotel\n",
        "fig_resort = px.pie(names=resort_hotel_segments.index, values=resort_hotel_segments.values,\n",
        "                    title=\"Resort Hotel - Bookings per Market Segment\",\n",
        "                    template=\"seaborn\")\n",
        "fig_resort.update_traces(rotation=-90, textinfo=\"percent+label\")\n",
        "fig_resort.show()\n"
      ],
      "metadata": {
        "id": "4vBPBAX9DqUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How many bookings were canceled?"
      ],
      "metadata": {
        "id": "Br8svcX302Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# absolute cancelations:\n",
        "total_cancelations = data_cln[\"is_canceled\"].sum()\n",
        "rh_cancelations = data_cln.loc[data_cln[\"hotel\"] == \"Resort Hotel\"][\"is_canceled\"].sum()\n",
        "ch_cancelations = data_cln.loc[data_cln[\"hotel\"] == \"City Hotel\"][\"is_canceled\"].sum()\n",
        "\n",
        "# as percent:\n",
        "rel_cancel = total_cancelations / data_cln.shape[0] * 100\n",
        "rh_rel_cancel = rh_cancelations / data_cln.loc[data_cln[\"hotel\"] == \"Resort Hotel\"].shape[0] * 100\n",
        "ch_rel_cancel = ch_cancelations / data_cln.loc[data_cln[\"hotel\"] == \"City Hotel\"].shape[0] * 100\n",
        "\n",
        "print(f\"Total bookings canceled: {total_cancelations:,} ({rel_cancel:.0f} %)\")\n",
        "print(f\"Resort hotel bookings canceled: {rh_cancelations:,} ({rh_rel_cancel:.0f} %)\")\n",
        "print(f\"City hotel bookings canceled: {ch_cancelations:,} ({ch_rel_cancel:.0f} %)\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "eKLweH7i02Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Data Cleaning& preprocessing"
      ],
      "metadata": {
        "id": "UD5SybCCTElH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# correlation matrix"
      ],
      "metadata": {
        "id": "8Ns6SCUpXIV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LabelEncoder"
      ],
      "metadata": {
        "id": "QzJ6P2keSZ_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_cln = data_cln.copy()\n",
        "\n",
        "# object\n",
        "object_columns = data_cln.select_dtypes(include=['object']).columns\n",
        "\n",
        "\n",
        "label_encoders = {}\n",
        "for col in object_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_cln[col] = le.fit_transform(data_cln[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "\n",
        "print(data_cln.dtypes)\n",
        "\n",
        "print(data_cln.head())"
      ],
      "metadata": {
        "id": "OEKyKPpDXIV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import fisher_exact\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def analyze_categorical_relationships(data, target_col='is_canceled'):\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for column in data.columns:\n",
        "        if column != target_col:\n",
        "\n",
        "            contingency_table = pd.crosstab(data[column], data[target_col])\n",
        "\n",
        "\n",
        "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "            # Cramer's V\n",
        "            n = contingency_table.sum().sum()\n",
        "            min_dim = min(contingency_table.shape) - 1\n",
        "            cramer_v = np.sqrt(chi2 / (n * min_dim))\n",
        "\n",
        "            results.append({\n",
        "                'Feature': column,\n",
        "                'Chi2': chi2,\n",
        "                'P_value': p_value,\n",
        "                'Cramer_V': cramer_v\n",
        "            })\n",
        "\n",
        "    # DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df = results_df.sort_values('Cramer_V', ascending=False)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "results = analyze_categorical_relationships(data_cln)\n",
        "\n",
        "\n",
        "print(\"Significance level set to 0.05\")\n",
        "print(\"\\nSignificantly correlated features:\")\n",
        "print(results[results['P_value'] < 0.05].to_string(index=False))"
      ],
      "metadata": {
        "id": "crXWhVITSgXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_significant_pairs(data, p_value_threshold=0.05):\n",
        "    significant_pairs = []\n",
        "\n",
        "\n",
        "    features = data.columns\n",
        "    for i in range(len(features)):\n",
        "        for j in range(i+1, len(features)):\n",
        "\n",
        "            contingency = pd.crosstab(data[features[i]], data[features[j]])\n",
        "\n",
        "\n",
        "            chi2, p_value, _, _ = chi2_contingency(contingency)\n",
        "\n",
        "\n",
        "            if p_value < p_value_threshold:\n",
        "                significant_pairs.append((features[i], features[j], p_value))\n",
        "\n",
        "\n",
        "    significant_pairs.sort(key=lambda x: x[2])\n",
        "\n",
        "    return significant_pairs\n",
        "\n",
        "\n",
        "sig_pairs = find_significant_pairs(data_cln)\n",
        "\n",
        "print(\"显著相关的特征对（p < 0.05）：\")\n",
        "for pair in sig_pairs:\n",
        "    print(f\"({pair[0]}, {pair[1]}) - p值: {pair[2]:.10f}\")"
      ],
      "metadata": {
        "id": "ddqdYW4JXHLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def calculate_cramers_v_matrix(data):\n",
        "    n_features = len(data.columns)\n",
        "    v_matrix = np.zeros((n_features, n_features))\n",
        "\n",
        "    for i, col1 in enumerate(data.columns):\n",
        "        for j, col2 in enumerate(data.columns):\n",
        "            contingency = pd.crosstab(data[col1], data[col2])\n",
        "            chi2, _, _, _ = chi2_contingency(contingency)\n",
        "            n = contingency.sum().sum()\n",
        "            min_dim = min(contingency.shape) - 1\n",
        "            v = np.sqrt(chi2 / (n * min_dim))\n",
        "            v_matrix[i,j] = v\n",
        "\n",
        "    return pd.DataFrame(v_matrix, index=data.columns, columns=data.columns)\n",
        "\n",
        "\n",
        "v_matrix = calculate_cramers_v_matrix(data_cln)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(v_matrix, annot=False, cmap='YlOrRd', vmin=0, vmax=1)\n",
        "plt.title(\"Cramer's V Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('cramers_v_heatmap.pdf')"
      ],
      "metadata": {
        "id": "59JezktUBBEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = [\n",
        "    'is_canceled', 'hotel', 'lead_time', 'arrival_date_month', 'stays_in_weekend_nights',\n",
        "    'stays_in_week_nights', 'adults', 'children', 'babies', 'meal', 'country',\n",
        "    'market_segment', 'distribution_channel', 'is_repeated_guest', 'previous_cancellations',\n",
        "    'previous_bookings_not_canceled', 'reserved_room_type', 'booking_changes', 'deposit_type',\n",
        "    'agent', 'company', 'days_in_waiting_list', 'customer_type', 'adr',\n",
        "    'required_car_parking_spaces', 'total_of_special_requests'\n",
        "]"
      ],
      "metadata": {
        "id": "GmlCZE8PB1SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "\n",
        "\n",
        "def calculate_cramers_v_matrix(data, selected_columns):\n",
        "    n_features = len(selected_columns)\n",
        "    v_matrix = np.zeros((n_features, n_features))\n",
        "\n",
        "    for i, col1 in enumerate(selected_columns):\n",
        "        for j, col2 in enumerate(selected_columns):\n",
        "            contingency = pd.crosstab(data[col1], data[col2])\n",
        "            chi2, _, _, _ = chi2_contingency(contingency)\n",
        "            n = contingency.sum().sum()\n",
        "            min_dim = min(contingency.shape) - 1\n",
        "            v = np.sqrt(chi2 / (n * min_dim))\n",
        "            v_matrix[i,j] = v\n",
        "\n",
        "    return pd.DataFrame(v_matrix, index=selected_columns, columns=selected_columns)\n",
        "\n",
        "# 计算并绘制热图\n",
        "plt.figure(figsize=(15, 12))\n",
        "v_matrix = calculate_cramers_v_matrix(data_cln[selected_columns], selected_columns)\n",
        "sns.heatmap(v_matrix, annot=True, cmap='YlOrRd', vmin=0, vmax=1, fmt='.2f',\n",
        "            xticklabels=selected_columns, yticklabels=selected_columns)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.title(\"Cramer's V Correlation Matrix \")\n",
        "plt.tight_layout()\n",
        "plt.savefig('cramers_v_selected_features.pdf', bbox_inches='tight', dpi=300)"
      ],
      "metadata": {
        "id": "hGxCubwQBqhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "v_matrix = calculate_cramers_v_matrix(data_cln[selected_columns], selected_columns)\n",
        "sns.heatmap(v_matrix, annot=False, cmap='YlOrRd', vmin=0, vmax=1,\n",
        "            xticklabels=selected_columns, yticklabels=selected_columns)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.title(\"Cramer's V Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('cramers_v_selected_features.pdf', bbox_inches='tight', dpi=300)"
      ],
      "metadata": {
        "id": "AHgsrPyFC_Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_columns)"
      ],
      "metadata": {
        "id": "NeidCZZHXIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "说明这两个中间肯定哪里变了selected_colums 把assigned room type放进去了"
      ],
      "metadata": {
        "id": "6it_6oYOXIV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_columns)"
      ],
      "metadata": {
        "id": "hLy-wxAyXIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-G87uQDvTZtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stratified Split"
      ],
      "metadata": {
        "id": "-XREg1ruTr05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data_cln['hotel'].unique())\n"
      ],
      "metadata": {
        "id": "SFcA8bzseDet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data_cln.groupby('hotel')['is_canceled'].mean())\n"
      ],
      "metadata": {
        "id": "Ne1ezbllh6cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H1+H\n",
        "train_data, test_data = train_test_split(data_cln, test_size=0.2, stratify=data_cln['is_canceled'], random_state=42)\n",
        "\n",
        "# City Hotel (H1)\n",
        "H1_data = data_cln[data_cln['hotel'] == 0]\n",
        "H1_train, H1_test = train_test_split(H1_data, test_size=0.2, stratify=H1_data['is_canceled'], random_state=42)\n",
        "\n",
        "# Resort Hotel (H2)\n",
        "H2_data = data_cln[data_cln['hotel'] == 1]\n",
        "H2_train, H2_test = train_test_split(H2_data, test_size=0.2, stratify=H2_data['is_canceled'], random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Total Train: {train_data.shape[0]}, Total Test: {test_data.shape[0]}\")\n",
        "print(f\"City Hotel Train (H1): {H1_train.shape[0]}, City Hotel Test (H1): {H1_test.shape[0]}\")\n",
        "print(f\"Resort Hotel Train (H2): {H2_train.shape[0]}, Resort Hotel Test (H2): {H2_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "yqOe7MyIYfhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "H1_train, H1_test = train_test_split(H1_data, test_size=0.2, stratify=H1_data['is_canceled'], random_state=42)\n",
        "H2_train, H2_test = train_test_split(H2_data, test_size=0.2, stratify=H2_data['is_canceled'], random_state=42)\n",
        "\n",
        "# combined\n",
        "combined_data = data_cln.copy()\n",
        "combined_data['strat_var'] = combined_data['hotel'].astype(str) + '_' + combined_data['is_canceled'].astype(str)\n",
        "combined_train, combined_test = train_test_split(combined_data, test_size=0.2,\n",
        "                                               stratify=combined_data['strat_var'],\n",
        "                                               random_state=42)\n",
        "\n",
        "print(\"H1 Distribution:\")\n",
        "print(f\"City Hotel Train (H1): {H1_train.shape[0]}, City Hotel Test (H1): {H1_test.shape[0]}\")\n",
        "print(\"\\nH2 Distribution:\")\n",
        "print(f\"Resort Hotel Train (H2): {H2_train.shape[0]}, Resort Hotel Test (H2): {H2_test.shape[0]}\")\n",
        "print(\"\\nCombined Dataset Distribution:\")\n",
        "print(combined_train.groupby(['hotel', 'is_canceled']).size())\n",
        "print(combined_test.groupby(['hotel', 'is_canceled']).size())\n"
      ],
      "metadata": {
        "id": "k2I_MO4GIuZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set size:\", len(combined_train))\n",
        "print(\"Test set size:\", len(combined_test))"
      ],
      "metadata": {
        "id": "CdMipYichStr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_values(datasets_dict):\n",
        "\n",
        "    for name, df in datasets_dict.items():\n",
        "        missing = df.isna().sum().sum()\n",
        "        print(f\"Number of NaN values in {name}: {missing}\")\n",
        "\n",
        "\n",
        "        if missing > 0:\n",
        "            print(f\"Detailed missing values in {name}:\")\n",
        "            print(df.isna().sum()[df.isna().sum() > 0])\n",
        "        print()\n",
        "\n",
        "datasets = {\n",
        "    'H1_train': H1_train,\n",
        "    'H1_test': H1_test,\n",
        "    'H2_train': H2_train,\n",
        "    'H2_test': H2_test,\n",
        "    'Combined_train': combined_train,\n",
        "    'Combined_test': combined_test\n",
        "}\n",
        "\n",
        "\n",
        "check_missing_values(datasets)"
      ],
      "metadata": {
        "id": "9WW6Bw2GeU7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#H1"
      ],
      "metadata": {
        "id": "w4P6lTJFoRT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 1.Logistic Regression\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LM9a7BLDfDSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# H1_train\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "# H1_test\n",
        "X_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "y_pred = log_reg_model.predict(X_test_scaled)\n",
        "y_pred_proba = log_reg_model.predict_proba(X_test_scaled)[:, 1]  # ROC-AUC\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ROC-AUC\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"\\nROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fiSTy8gziocs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(coefficients)\n"
      ],
      "metadata": {
        "id": "OPHfRaIQ6Bw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "#SHAP explainer\n",
        "explainer = shap.Explainer(log_reg_model, X_train_scaled_df)\n",
        "shap_values = explainer(X_train_scaled_df)\n",
        "\n",
        "#SHAP summary plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled_df, plot_type='bar', max_display=15)  # max_display 15\n",
        "\n",
        "#SHAP summary plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled_df, max_display=15)  # max_display 15\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KUAft8c37CyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "JTTSjP8oI_f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# H1_train\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Logistic\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "# 3-fold\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "\n",
        "        plt.text(j+ 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# ROC\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    log_reg_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h6kAET58zkHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficients"
      ],
      "metadata": {
        "id": "bc0td_aSC65_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(coefficients)"
      ],
      "metadata": {
        "id": "l2bUnjcoA3ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "})\n",
        "\n",
        "\n",
        "coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\n",
        "coefficients_sorted = coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(coefficients_sorted['Feature'], coefficients_sorted['Coefficient'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance (Coefficients)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8WQt6CaPA39T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "hDbKH0BcC9j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "explainer = shap.LinearExplainer(log_reg_model, X_train_scaled, feature_names=X_train.columns)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "shap_median_importance = np.median(np.abs(shap_values), axis=0)\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Median SHAP Value': shap_median_importance\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "plt.xlabel('Median SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance (Median SHAP Values)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "#SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_train, plot_type='dot', show=True)\n"
      ],
      "metadata": {
        "id": "Etrhmk7uEqWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# H1_train\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "boruta_selector = BorutaPy(rf_model, n_estimators='auto', random_state=42)\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "selected_features = X_train.columns[boruta_selector.support_]\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "# DataFrame\n",
        "feature_ranking = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Ranking': boruta_selector.ranking_\n",
        "}).sort_values(by='Ranking')\n",
        "\n",
        "\n",
        "selected_feature_ranking = feature_ranking[feature_ranking['Ranking'] == 1]\n"
      ],
      "metadata": {
        "id": "Nov6z4v8FAk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "vTRczHKb1wYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP 10"
      ],
      "metadata": {
        "id": "_IJYToqq2DDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient"
      ],
      "metadata": {
        "id": "jBJrlx4F2FdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# H1_train\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Logistic\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 10\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "})\n",
        "top_10_features = coefficients.reindex(coefficients.Coefficient.abs().sort_values(ascending=False).index).head(10)['Feature']\n",
        "print(\"Top 10 Features:\", top_10_features.values)\n",
        "\n",
        "# top 10\n",
        "X_train_top10 = H1_train[top_10_features]\n",
        "\n",
        "\n",
        "X_train_top10_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# Logistic\n",
        "log_reg_model_top10 = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model_top10.fit(X_train_top10_scaled, y_train)\n",
        "\n",
        "# 3-fold\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model_top10, X_train_top10_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model_top10, X_train_top10_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "#ROC\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_top10_scaled, y_train):\n",
        "    log_reg_model_top10.fit(X_train_top10_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model_top10.predict_proba(X_train_top10_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1foA5ylT13ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "8bTHWJu987ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "explainer = shap.LinearExplainer(log_reg_model, X_train_scaled, feature_names=X_train.columns)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "\n",
        "shap_median_importance = np.median(np.abs(shap_values), axis=0)\n",
        "\n",
        "\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Median SHAP Value': shap_median_importance\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "\n",
        "top_10_features = shap_importance_df['Feature'].head(10).values\n",
        "print(\"Top 10 SHAP Features:\", top_10_features)\n",
        "\n",
        "\n",
        "X_train_top10 = X_train[top_10_features]\n",
        "\n",
        "X_train_top10_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "\n",
        "log_reg_model_top10 = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model_top10.fit(X_train_top10_scaled, y_train)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv_top10 = cross_val_predict(log_reg_model_top10, X_train_top10_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_top10 = cross_val_predict(log_reg_model_top10, X_train_top10_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_top10 = confusion_matrix(y_train, y_pred_cv_top10)\n",
        "conf_matrix_percentage_top10 = conf_matrix_top10 / conf_matrix_top10.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_top10, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_top10.shape[0]):\n",
        "    for j in range(conf_matrix_top10.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_top10[i, j]:.1f}%\"\n",
        "        plt.text(j+0.2, i+0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Top 10 SHAP Features)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Top 10 SHAP Features):\")\n",
        "print(classification_report(y_train, y_pred_cv_top10))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_top10_scaled, y_train):\n",
        "    log_reg_model_top10.fit(X_train_top10_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold_top10 = log_reg_model_top10.predict_proba(X_train_top10_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold_top10)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold_top10)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV, Top 10 SHAP Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cQzh9FaT8_GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "J23B-R0e9Pe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_boruta = X_train[['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']]\n",
        "\n",
        "\n",
        "X_train_boruta_scaled = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "\n",
        "log_reg_model_boruta = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model_boruta.fit(X_train_boruta_scaled, y_train)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv_boruta = cross_val_predict(log_reg_model_boruta, X_train_boruta_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_boruta = cross_val_predict(log_reg_model_boruta, X_train_boruta_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_boruta = confusion_matrix(y_train, y_pred_cv_boruta)\n",
        "conf_matrix_percentage_boruta = conf_matrix_boruta / conf_matrix_boruta.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_boruta, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_boruta.shape[0]):\n",
        "    for j in range(conf_matrix_boruta.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_boruta[i, j]:.1f}%\"\n",
        "        plt.text(j+0.2, i+0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Boruta Selected Features):\")\n",
        "print(classification_report(y_train, y_pred_cv_boruta))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta_scaled, y_train):\n",
        "    log_reg_model_boruta.fit(X_train_boruta_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold_boruta = log_reg_model_boruta.predict_proba(X_train_boruta_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold_boruta)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold_boruta)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV, Boruta Selected Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p4YFpZ839RYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "ZihQ9b69AkbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optuna"
      ],
      "metadata": {
        "id": "wmo04MpMPs6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all features\n"
      ],
      "metadata": {
        "id": "qaEvm6XSPvkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "\n",
        "    log_reg_model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "y_pred_cv = cross_val_predict(best_log_reg_model, X_train_scaled, y_train, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_log_reg_model, X_train_scaled, y_train, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j+0.2, i+0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    best_log_reg_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_log_reg_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-6JRv8jpPsLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters (Optuna):\", study.best_params)\n"
      ],
      "metadata": {
        "id": "DCxw85Ms5nRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 coefficient features"
      ],
      "metadata": {
        "id": "gBjlFJjp6-rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "})\n",
        "top_10_features = coefficients.reindex(coefficients.Coefficient.abs().sort_values(ascending=False).index).head(10)['Feature']\n",
        "print(\"Top 10 Features:\", top_10_features.values)\n",
        "\n",
        "\n",
        "X_train_top10 = H1_train[top_10_features]\n",
        "X_train_top10_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    log_reg_model_optuna = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optuna, X_train_top10_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_log_reg_model, X_train_top10_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_log_reg_model, X_train_top10_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_top10_scaled, y_train):\n",
        "    best_log_reg_model.fit(X_train_top10_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_log_reg_model.predict_proba(X_train_top10_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "96Lqo0J77C-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP10 SHAP"
      ],
      "metadata": {
        "id": "JBFLwpIN8n7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_train = H1_train[['deposit_type', 'market_segment', 'total_of_special_requests', 'country',\n",
        "                    'lead_time', 'previous_cancellations', 'required_car_parking_spaces', 'adr',\n",
        "                    'stays_in_week_nights', 'stays_in_weekend_nights']]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "\n",
        "    log_reg_model_optuna = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optuna, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_log_reg_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_log_reg_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Top 10 SHAP Features)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Top 10 SHAP Features):\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    best_log_reg_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_log_reg_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV, Top 10 SHAP Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fttp4yyC8ror"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "WsOioEnpFU_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_train_boruta = X_train[['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_boruta_scaled = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "\n",
        "    log_reg_model_optuna = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optuna, X_train_boruta_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_log_reg_model, X_train_boruta_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_log_reg_model, X_train_boruta_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Boruta Selected Features):\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta_scaled, y_train):\n",
        "    best_log_reg_model.fit(X_train_boruta_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_log_reg_model.predict_proba(X_train_boruta_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (3-fold CV, Boruta Selected Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zGR6rPt6FXzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "GXlg8tybCVb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "Ykt_e6r5K1Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred_test = log_reg_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = log_reg_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fpr_test, tpr_test, label=f'Logistic Regression (AUC = {roc_auc_test:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ipoiP_w6CYg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline with Optuna"
      ],
      "metadata": {
        "id": "hzw0khRcK7oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "\n",
        "    log_reg_model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "best_log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "X_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred_test = best_log_reg_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_log_reg_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "adTpri2PQlNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 coefficients with optuna tuning"
      ],
      "metadata": {
        "id": "D0GLnmCfVG8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg_model.coef_[0]\n",
        "})\n",
        "top_10_features = coefficients.reindex(coefficients.Coefficient.abs().sort_values(ascending=False).index).head(10)['Feature']\n",
        "print(\"Top 10 Features:\", top_10_features.values)\n",
        "\n",
        "X_train_top10 = H1_train[top_10_features]\n",
        "X_train_top10_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    log_reg_model_optuna = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optuna, X_train_top10_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "best_log_reg_model.fit(X_train_top10_scaled, y_train)\n",
        "\n",
        "\n",
        "X_test_top10 = H1_test[top_10_features]\n",
        "X_test_top10_scaled = scaler.transform(X_test_top10)\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "\n",
        "y_pred_test = best_log_reg_model.predict(X_test_top10_scaled)\n",
        "y_pred_proba_test = best_log_reg_model.predict_proba(X_test_top10_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set, Top 10 Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3X2fq5UlVNxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 SHAP with optuna tuning"
      ],
      "metadata": {
        "id": "zaQVBt1TVlBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_train = H1_train[['deposit_type', 'market_segment', 'total_of_special_requests', 'country',\n",
        "                    'lead_time', 'previous_cancellations', 'required_car_parking_spaces', 'adr',\n",
        "                    'stays_in_week_nights', 'stays_in_weekend_nights']]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "\n",
        "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs']:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    log_reg_model_optuna = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=2000, random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optuna, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "\n",
        "best_log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "X_test = H1_test[['deposit_type', 'market_segment', 'total_of_special_requests', 'country',\n",
        "                  'lead_time', 'previous_cancellations', 'required_car_parking_spaces', 'adr',\n",
        "                  'stays_in_week_nights', 'stays_in_weekend_nights']]\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "\n",
        "y_pred_test = best_log_reg_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_log_reg_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set, Top 10 SHAP Features)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Test Set, Top 10 SHAP Features):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set, Top 10 SHAP Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yr03c5DmVsn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta with optuna tuning"
      ],
      "metadata": {
        "id": "A3Z7ztYeVpqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_boruta = H1_test[['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']]\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "\n",
        "X_test_boruta_scaled = scaler.transform(X_test_boruta)\n",
        "\n",
        "best_log_reg_model = LogisticRegression(**study.best_params, max_iter=2000, random_state=42)\n",
        "best_log_reg_model.fit(X_train_boruta_scaled, y_train)\n",
        "\n",
        "\n",
        "y_pred_test = best_log_reg_model.predict(X_test_boruta_scaled)\n",
        "y_pred_proba_test = best_log_reg_model.predict_proba(X_test_boruta_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Boruta Selected Features on Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (Boruta Selected Features on Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set, Boruta Selected Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xije7NLZYitT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H2 test set"
      ],
      "metadata": {
        "id": "eh__nDbuDbKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "91cFQP0lgVmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_H2 = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)  t\n",
        "\n",
        "\n",
        "y_pred_test_H2 = log_reg_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = log_reg_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_test_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_test_H2 = conf_matrix_test_H2 / conf_matrix_test_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix_test_H2.shape[0]):\n",
        "    for j in range(conf_matrix_test_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "\n",
        "fpr_test_H2, tpr_test_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_test_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fpr_test_H2, tpr_test_H2, label=f'Logistic Regression (AUC = {roc_auc_test_H2:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BMFrgGtaCY-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline with optuna tuning"
      ],
      "metadata": {
        "id": "mXG-0E9xg3-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_H2 = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "\n",
        "y_pred_test_H2 = best_log_reg_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_log_reg_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_H2 = conf_matrix_H2 / conf_matrix_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "\n",
        "for i in range(conf_matrix_H2.shape[0]):\n",
        "    for j in range(conf_matrix_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'AUC = {roc_auc_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0HWpkEC5g236"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 efficients with optuna tuning"
      ],
      "metadata": {
        "id": "YJRvD7B5qJCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_H2 = H2_test[top_10_features]\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "\n",
        "y_pred_test_H2 = best_log_reg_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_log_reg_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_H2 = conf_matrix_H2 / conf_matrix_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_H2.shape[0]):\n",
        "    for j in range(conf_matrix_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'AUC = {roc_auc_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set, Top 10 Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UMCmtcaxqOov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 SHAP with optuna tuning"
      ],
      "metadata": {
        "id": "NIrTe0dbzAqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_H2 = H2_test[['deposit_type', 'market_segment', 'total_of_special_requests', 'country',\n",
        "                     'lead_time', 'previous_cancellations', 'required_car_parking_spaces', 'adr',\n",
        "                     'stays_in_week_nights', 'stays_in_weekend_nights']]\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "\n",
        "y_pred_test_H2 = best_log_reg_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_log_reg_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "\n",
        "conf_matrix_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_H2 = conf_matrix_H2 / conf_matrix_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_H2.shape[0]):\n",
        "    for j in range(conf_matrix_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set, Top 10 SHAP Features)')\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "print(\"\\nClassification Report (H2 Test Set, Top 10 SHAP Features):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'AUC = {roc_auc_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set, Top 10 SHAP Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D20cGQoWzJc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "7oC1BkW6zE-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 H2_test 定义测试集特征和目标变量\n",
        "X_test_H2_boruta = H2_test[['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']]\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# 使用训练集的 scaler 对 H2_test 进行标准化\n",
        "X_test_H2_boruta_scaled = scaler.transform(X_test_H2_boruta)\n",
        "\n",
        "# 在 H2_test 上进行预测\n",
        "y_pred_test_H2 = best_log_reg_model.predict(X_test_H2_boruta_scaled)\n",
        "y_pred_proba_test_H2 = best_log_reg_model.predict_proba(X_test_H2_boruta_scaled)[:, 1]\n",
        "\n",
        "# 计算 H2_test 的混淆矩阵\n",
        "conf_matrix_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_H2 = conf_matrix_H2 / conf_matrix_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制 H2_test 的混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_H2.shape[0]):\n",
        "    for j in range(conf_matrix_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set, Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出 H2_test 的分类报告\n",
        "print(\"\\nClassification Report (H2 Test Set, Boruta Selected Features):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "# 绘制 H2_test 的 ROC 曲线\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'AUC = {roc_auc_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set, Boruta Selected Features with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YvF9WKXQzKIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2.Random Forest\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kc-Q9MYKfM1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "Pdrd_1JbEueI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用 H1_train 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据（随机森林通常不需要标准化，但可以保留以一致性）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 可以调整n_estimators等超参数\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eOEYsZmAZeAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "2OXBmU2WaAp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算并显示特征重要性\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 绘制特征重要性条形图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# 输出特征重要性数据表\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance_df)\n"
      ],
      "metadata": {
        "id": "aimOemSgaTKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "MlpTNyr3abyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "93XTDqBZ573c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values.shape)"
      ],
      "metadata": {
        "id": "dgNp4v-Ufhkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_sample.shape)"
      ],
      "metadata": {
        "id": "IOs2Rb-Sq1YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)         # 原始训练数据形状\n",
        "print(\"Sample data shape:\", sample_data.shape)  # 传入SHAP的数据形状\n"
      ],
      "metadata": {
        "id": "X-v_-VQ-yKEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm  # 进度条库\n",
        "\n",
        "# Step 1: 计算特征重要性并选择前10个重要特征\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 选择前10个重要特征\n",
        "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
        "print(\"Top 10 important features:\", top_features)\n",
        "\n",
        "# Step 2: 从训练集中抽取样本数据，仅保留前10个重要特征用于绘图\n",
        "sample_data = X_train[top_features].sample(n=500, random_state=42)\n",
        "\n",
        "# Step 3: 使用完整的训练数据作为背景数据初始化SHAP解释器\n",
        "start_time = time.time()\n",
        "print(\"Initializing SHAP TreeExplainer...\")\n",
        "\n",
        "# 使用完整训练数据作为背景数据，确保模型输入一致性\n",
        "explainer = shap.TreeExplainer(rf_model, data=X_train.sample(n=200, random_state=42), approximate=True)\n",
        "shap_values = explainer.shap_values(sample_data)\n",
        "\n",
        "# Step 4: 计算中位数SHAP值并绘制特征重要性图\n",
        "print(\"Calculating Median SHAP values...\")\n",
        "shap_median_importance = np.median(np.abs(shap_values[1]), axis=0)  # 使用类别1的SHAP值，适用于二分类模型\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Median SHAP Value': shap_median_importance\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "# 绘制特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "plt.xlabel('Median SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importance (Median SHAP Values) for Random Forest')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: 绘制SHAP summary plot\n",
        "print(\"Generating SHAP summary plot...\")\n",
        "shap.summary_plot(shap_values[1], sample_data, plot_type='dot', show=True)\n",
        "\n",
        "# 记录结束时间\n",
        "end_time = time.time()\n",
        "print(f\"Execution completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wvv6mtSVzIvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 计算特征重要性并选择前10个重要特征\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 选择前10个重要特征\n",
        "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
        "print(\"Top 10 important features:\", top_features)\n",
        "\n",
        "# 重新训练模型，仅使用前10个重要特征\n",
        "X_train_reduced = X_train[top_features]  # 保留前10个重要特征\n",
        "rf_model_reduced = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)  # 使用更简单的模型\n",
        "rf_model_reduced.fit(X_train_reduced, y_train)  # 使用前10个特征重新训练模型\n",
        "\n",
        "# 准备样本数据\n",
        "sample_data = X_train_reduced.sample(n=200, random_state=42)\n",
        "\n",
        "# 使用 KernelExplainer 进行 SHAP 分析\n",
        "start_time = time.time()\n",
        "print(\"Initializing SHAP KernelExplainer...\")\n",
        "explainer = shap.KernelExplainer(rf_model_reduced.predict, shap.kmeans(sample_data, 10))\n",
        "shap_values = explainer.shap_values(sample_data)\n",
        "\n",
        "# 绘制特征重要性图\n",
        "print(\"Calculating Median SHAP values...\")\n",
        "shap_median_importance = np.median(np.abs(shap_values), axis=0)\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Median SHAP Value': shap_median_importance\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "plt.xlabel('Median SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importance (Median SHAP Values) for Reduced Random Forest')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# 绘制SHAP summary plot\n",
        "print(\"Generating SHAP summary plot...\")\n",
        "shap.summary_plot(shap_values, sample_data, plot_type='dot', show=True)\n",
        "\n",
        "# 记录结束时间\n",
        "end_time = time.time()\n",
        "print(f\"Execution completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-JXIjai07F4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "zTzE_K-V8Mvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta 1114"
      ],
      "metadata": {
        "id": "_PKog4W3BSZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用 H1_train 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义Boruta模型并进行特征选择\n",
        "rf_boruta = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "boruta_selector = BorutaPy(rf_boruta, n_estimators='auto', random_state=42)\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取被选中的特征\n",
        "selected_features = X_train.columns[boruta_selector.support_]\n",
        "print(\"Selected features by Boruta:\", selected_features)\n",
        "\n",
        "# 使用Boruta筛选的特征重新定义训练数据\n",
        "X_train_boruta = X_train[selected_features]\n",
        "X_train_boruta_scaled = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "# 使用筛选后的特征构建新的随机森林模型\n",
        "rf_model_boruta = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv_boruta = cross_val_predict(rf_model_boruta, X_train_boruta_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_boruta = cross_val_predict(rf_model_boruta, X_train_boruta_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix_boruta = confusion_matrix(y_train, y_pred_cv_boruta)\n",
        "conf_matrix_percentage_boruta = conf_matrix_boruta / conf_matrix_boruta.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_boruta, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix_boruta.shape[0]):\n",
        "    for j in range(conf_matrix_boruta.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_boruta[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest with Boruta Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report (Random Forest with Boruta Features):\")\n",
        "print(classification_report(y_train, y_pred_cv_boruta))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta_scaled, y_train):\n",
        "    rf_model_boruta.fit(X_train_boruta_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model_boruta.predict_proba(X_train_boruta_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest with Boruta Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L4VTS7X8tX7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 绘制 Boruta 选择的特征的重要性条形图\n",
        "# 使用 Random Forest 的 feature_importances_\n",
        "rf_model_boruta.fit(X_train_boruta_scaled, y_train)  # 重新训练以获取特征重要性\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Importance': rf_model_boruta.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 绘制特征重要性条形图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance for Boruta-selected Features (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1mXxhN6svfj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "SH9xc4rsEu2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP10"
      ],
      "metadata": {
        "id": "P3TGtjAz9OtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature_importance"
      ],
      "metadata": {
        "id": "KFRNi2-iEu-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用特征重要性计算并选择前10个重要特征\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 选择前10个重要特征\n",
        "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
        "print(\"Top 10 important features based on feature_importance_:\", top_features)\n",
        "\n",
        "# 绘制特征重要性条形图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# 输出特征重要性数据表\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance_df)\n",
        "\n",
        "# 使用前10个重要特征重新定义特征和目标变量\n",
        "X_train_top10 = H1_train[top_features]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model_top10 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model_top10, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model_top10, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest with Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model_top10.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model_top10.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest with Top 10 Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PJKtGleY8CEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "BNX2K5KV8CQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用 SHAP 选出的10个特征\n",
        "selected_columns = ['lead_time', 'country', 'deposit_type', 'adr',\n",
        "                    'total_of_special_requests', 'agent', 'arrival_date_month',\n",
        "                    'stays_in_week_nights', 'market_segment', 'previous_cancellations']\n",
        "\n",
        "# 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5UQvcA3Z8EpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "i3gVcokW8E1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 定义 Boruta 筛选出的特征\n",
        "selected_columns = ['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']\n",
        "\n",
        "# 使用 H1_train 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据（随机森林通常不需要标准化，但为了流程一致可以保留）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Omn5LYxu8--1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "_j4gtEgeETcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to optimize\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
        "    }\n",
        "\n",
        "    # Create and evaluate model using cross-validation\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    model = RandomForestClassifier(**params, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_train_scaled, y_train):\n",
        "        X_fold_train = X_train_scaled[train_idx]\n",
        "        X_fold_val = X_train_scaled[val_idx]\n",
        "        y_fold_train = y_train.iloc[train_idx]\n",
        "        y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "        y_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
        "        score = roc_auc_score(y_fold_val, y_pred_proba)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Prepare data\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Create and run Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = study.best_params\n",
        "print(\"\\nBest parameters:\", best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
        "\n",
        "# Perform cross-validation with the best model\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_rf, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_rf, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Plot optimization history\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "plt.title('Optimization History')\n",
        "plt.show()\n",
        "\n",
        "# Plot parameter importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_param_importances(study)\n",
        "plt.title('Parameter Importances')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# ROC Curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    best_rf.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_rf.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Optimized Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance Plot\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': best_rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance (Optimized Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lIlIiVcff04P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 feature importance"
      ],
      "metadata": {
        "id": "Medy3vn333qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# 定义目标函数用于Optuna超参数调优\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "\n",
        "    # 创建随机森林模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # 进行3-fold交叉验证\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "\n",
        "    return auc_score\n",
        "\n",
        "# 使用Optuna进行超参数调优\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 输出最佳参数\n",
        "print(\"Best Parameters (Optuna):\", study.best_params)\n",
        "\n",
        "# 使用最佳参数重新创建随机森林模型\n",
        "best_rf_model = RandomForestClassifier(**study.best_params, random_state=42)\n",
        "\n",
        "# 在训练集上拟合最佳模型\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 在训练集上进行预测\n",
        "y_pred_train = best_rf_model.predict(X_train_scaled)\n",
        "y_pred_proba_train = best_rf_model.predict_proba(X_train_scaled)[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest with Best Parameters)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report (Training Set):\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "# 绘制 ROC 曲线\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba_train)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba_train)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Training Set, Random Forest with Best Parameters)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fz59oveN34lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "# 定义目标函数用于Optuna调参\n",
        "def objective(trial):\n",
        "    # 调整随机森林的超参数\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 5, 20)\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
        "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
        "\n",
        "    # 创建随机森林模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # 3折交叉验证\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_proba_cv = []\n",
        "    for train_idx, val_idx in cv.split(X_train_scaled, y_train):\n",
        "        rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "        y_pred_proba_cv.extend(rf_model.predict_proba(X_train_scaled[val_idx])[:, 1])\n",
        "\n",
        "    # 计算AUC\n",
        "    auc_score = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "    return auc_score\n",
        "\n",
        "# 使用Optuna进行超参数调优\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 输出最佳参数\n",
        "print(\"Best Parameters (Random Forest):\", study.best_params)\n",
        "\n",
        "# 使用最佳参数创建随机森林模型\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    n_estimators=study.best_params[\"n_estimators\"],\n",
        "    max_depth=study.best_params[\"max_depth\"],\n",
        "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
        "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
        "    max_features=study.best_params[\"max_features\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 在训练集上拟合模型\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 在测试集上进行预测\n",
        "X_test_scaled = scaler.transform(X_test)  # 使用训练集的scaler\n",
        "y_pred_test = best_rf_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 计算测试集的混淆矩阵\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Test Set with Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# 绘制ROC曲线\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set with Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "imMt6NYjRHg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_columns)"
      ],
      "metadata": {
        "id": "2gQDDsFyCO2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1126"
      ],
      "metadata": {
        "id": "JhOiuaRxL6pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna目标函数，用于优化随机森林的超参数\n",
        "    \"\"\"\n",
        "    # 定义超参数搜索空间\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
        "    }\n",
        "\n",
        "    # 创建模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    # 使用5折交叉验证评估模型\n",
        "    # 使用ROC AUC作为评估指标\n",
        "    scores = cross_val_score(\n",
        "        rf_model,\n",
        "        X_train_scaled,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 返回平均分数\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 创建study对象\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# 运行优化\n",
        "print(\"Starting hyperparameter optimization...\")\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "# 打印最佳结果\n",
        "print(\"\\nBest trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value (ROC AUC): \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# 使用最佳参数创建和训练最终模型\n",
        "best_params = study.best_params\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "# 在完整训练集上训练模型\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 进行交叉验证预测\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_rf_model, X_train_scaled, y_train, cv=cv)\n",
        "y_pred_proba_cv = cross_val_predict(best_rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 评估最佳模型\n",
        "print(\"\\nBest Model Evaluation:\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算和打印ROC AUC分数\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(10, 6))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba_cv)\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve of Optimized Random Forest Model')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix of Optimized Random Forest Model')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# 绘制优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "plt.title('Optimization History')\n",
        "plt.show()\n",
        "\n",
        "# 绘制参数重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_param_importances(study)\n",
        "plt.title('Parameter Importances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8u5WxuaqMAkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP10 SHAP"
      ],
      "metadata": {
        "id": "WOtnrJvr39RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 使用 SHAP 选出的10个特征\n",
        "selected_columns = ['lead_time', 'country', 'deposit_type', 'adr',\n",
        "                    'total_of_special_requests', 'agent', 'arrival_date_month',\n",
        "                    'stays_in_week_nights', 'market_segment', 'previous_cancellations']\n",
        "\n",
        "# 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 分割训练集为训练和验证集，用于Optuna调优\n",
        "X_train_optuna, X_val_optuna, y_train_optuna, y_val_optuna = train_test_split(\n",
        "    X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "# 定义目标函数\n",
        "def objective(trial):\n",
        "    # 定义搜索空间\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
        "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
        "\n",
        "    # 创建随机森林模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # 训练模型\n",
        "    rf_model.fit(X_train_optuna, y_train_optuna)\n",
        "\n",
        "    # 预测验证集\n",
        "    y_val_pred = rf_model.predict_proba(X_val_optuna)[:, 1]\n",
        "\n",
        "    # 返回AUC分数\n",
        "    return roc_auc_score(y_val_optuna, y_val_pred)\n",
        "\n",
        "# 创建Optuna研究\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 输出最佳超参数和最佳分数\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best AUC score:\", study.best_value)\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_params = study.best_params\n",
        "final_model = RandomForestClassifier(\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    max_depth=best_params[\"max_depth\"],\n",
        "    min_samples_split=best_params[\"min_samples_split\"],\n",
        "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
        "    max_features=best_params[\"max_features\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 使用交叉验证评估最终模型\n",
        "y_pred_cv_final = cross_val_predict(final_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_final = cross_val_predict(final_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 输出分类报告和混淆矩阵\n",
        "conf_matrix_final = confusion_matrix(y_train, y_pred_cv_final)\n",
        "print(\"\\nConfusion Matrix (Final Model):\")\n",
        "print(conf_matrix_final)\n",
        "print(\"\\nClassification Report (Final Model):\")\n",
        "print(classification_report(y_train, y_pred_cv_final))\n"
      ],
      "metadata": {
        "id": "MOP00jRo39sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 绘制测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Test Set with Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# 绘制测试集的ROC曲线\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set with Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JdJhuBMC6tIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "azT-gPiY4DL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1116"
      ],
      "metadata": {
        "id": "iVvuQZzD-7XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要库\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 定义 Boruta 筛选出的特征\n",
        "selected_columns = ['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']\n",
        "\n",
        "# 使用 Boruta 筛选的特征子集\n",
        "X_train = H1_train[selected_columns]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据（随机森林不需要标准化，但为了流程一致可以保留）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义优化目标函数\n",
        "def objective(trial):\n",
        "    # 定义需要优化的超参数\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "\n",
        "    # 创建随机森林模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # 使用 StratifiedKFold 进行交叉验证\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    auc_scores = []\n",
        "    for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "        rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "        y_pred_proba = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "        auc_scores.append(roc_auc_score(y_train.iloc[test_idx], y_pred_proba))\n",
        "\n",
        "    # 返回平均 AUC 作为目标优化的指标\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "# 创建 Optuna study 对象并优化\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 输出最佳参数和最高 AUC\n",
        "print(\"Best Parameters:\", study.best_params)\n",
        "print(\"Best AUC:\", study.best_value)\n",
        "\n",
        "# 使用最佳参数重新训练模型\n",
        "best_params = study.best_params\n",
        "optimized_rf_model = RandomForestClassifier(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf'],\n",
        "    max_features=best_params['max_features'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 使用最佳参数模型进行交叉验证预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(optimized_rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(optimized_rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的 ROC 曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    optimized_rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = optimized_rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Optimized Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K1QQ5bfG_fJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "u379ib4XEWJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare train data\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# Prepare test data with the same columns as training data\n",
        "X_test = H1_test[X_train.columns]  # This ensures we use exactly the same columns\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)  # Use the same scaler for test data\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to optimize\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
        "    }\n",
        "\n",
        "    # Create and evaluate model using cross-validation\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    model = RandomForestClassifier(**params, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_train_scaled, y_train):\n",
        "        X_fold_train = X_train_scaled[train_idx]\n",
        "        X_fold_val = X_train_scaled[val_idx]\n",
        "        y_fold_train = y_train.iloc[train_idx]\n",
        "        y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "        y_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
        "        score = roc_auc_score(y_fold_val, y_pred_proba)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Create and run Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = study.best_params\n",
        "print(\"\\nBest parameters:\", best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_test_pred = best_rf.predict(X_test_scaled)\n",
        "y_test_pred_proba = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "print(\"\\nTest Set Performance Metrics:\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {test_roc_auc:.4f}\")\n",
        "\n",
        "# Confusion Matrix for Test Set\n",
        "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "test_conf_matrix_percentage = test_conf_matrix / test_conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(test_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(test_conf_matrix.shape[0]):\n",
        "    for j in range(test_conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{test_conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Test Set Confusion Matrix (Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for Test Set\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ROC Curve for Test Set\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_test, tpr_test, label=f'Test Set (AUC = {test_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on Test Set (Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Feature importance analysis\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': best_rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance (Optimized Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZOcDrUGpt0KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_T7rGoVpb_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare train data\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# Prepare test data with the same columns as training data\n",
        "X_test = H1_test[X_train.columns]  # This ensures we use exactly the same columns\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)  # Use the same scaler for test data\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to optimize\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
        "    }\n",
        "\n",
        "    # Create and evaluate model using cross-validation\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    model = RandomForestClassifier(**params, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_train_scaled, y_train):\n",
        "        X_fold_train = X_train_scaled[train_idx]\n",
        "        X_fold_val = X_train_scaled[val_idx]\n",
        "        y_fold_train = y_train.iloc[train_idx]\n",
        "        y_fold_val = y_train.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "        y_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
        "        score = roc_auc_score(y_fold_val, y_pred_proba)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Create and run Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = study.best_params\n",
        "print(\"\\nBest parameters:\", best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_test_pred = best_rf.predict(X_test_scaled)\n",
        "y_test_pred_proba = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "print(\"\\nTest Set Performance Metrics:\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {test_roc_auc:.4f}\")\n",
        "\n",
        "# Confusion Matrix for Test Set\n",
        "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "test_conf_matrix_percentage = test_conf_matrix / test_conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(test_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(test_conf_matrix.shape[0]):\n",
        "    for j in range(test_conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{test_conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Test Set Confusion Matrix (Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for Test Set\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ROC Curve for Test Set\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_test, tpr_test, label=f'Test Set (AUC = {test_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on Test Set (Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Feature importance analysis\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': best_rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance (Optimized Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vx0LpGXHpdYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 feature importance"
      ],
      "metadata": {
        "id": "m8kmZwHx4JZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 H1_test 定义测试集特征和目标变量\n",
        "X_test = H1_test[top_features]\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# 使用训练集的 scaler 对测试集进行标准化\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 使用最佳模型预测测试集结果\n",
        "y_pred_test = best_rf_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 计算测试集的混淆矩阵\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# 计算测试集 ROC 曲线和 AUC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
        "print(f\"Test Set AUC: {roc_auc_test:.2f}\")\n",
        "\n",
        "# 绘制测试集 ROC 曲线\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc_test:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aGwtoZN1CmFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 H1_test 定义测试集特征和目标变量\n",
        "X_test = H1_test[top_features]\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# 使用训练集的 scaler 对测试集进行标准化\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 使用最佳模型预测测试集结果\n",
        "y_pred_test = best_rf_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 计算测试集的混淆矩阵\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# 计算测试集 ROC 曲线和 AUC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
        "print(f\"Test Set AUC: {roc_auc_test:.2f}\")\n",
        "\n",
        "# 绘制测试集 ROC 曲线\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc_test:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dNuwQf0pteOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP10 SHAP"
      ],
      "metadata": {
        "id": "lLwEooKU4JZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用 H1_test 定义测试集特征和目标变量\n",
        "X_test = H1_test[selected_columns]  # 使用 SHAP 选出的特征\n",
        "y_test = H1_test['is_canceled']  # 测试集目标变量\n",
        "\n",
        "# 使用训练集的 scaler 对测试集进行标准化\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 使用最佳参数创建随机森林模型\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    n_estimators=227,\n",
        "    max_depth=30,\n",
        "    min_samples_split=3,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='log2',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 使用训练集重新训练最佳模型\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 使用最佳模型预测测试集结果\n",
        "y_pred_test = best_rf_model.predict(X_test_scaled)\n",
        "y_pred_proba_test = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 计算测试集的混淆矩阵\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# 计算测试集 ROC 曲线和 AUC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
        "print(f\"Test Set AUC: {roc_auc_test:.2f}\")\n",
        "\n",
        "# 绘制测试集 ROC 曲线\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Test Set AUC = {roc_auc_test:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x5t4YGd07GGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "KF71Ekqc4JZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用最佳参数构建最终模型\n",
        "final_rf_model = RandomForestClassifier(\n",
        "    n_estimators=186,\n",
        "    max_depth=24,\n",
        "    min_samples_split=6,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='log2',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 准备测试数据\n",
        "X_test = H1_test[X_train.columns]  # 确保测试集使用和训练集完全相同的特征\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# 标准化测试数据\n",
        "X_test_scaled = scaler.transform(X_test)  # 使用训练集的 scaler 对测试集进行转换\n",
        "\n",
        "# 在训练集上训练模型\n",
        "final_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 在测试集上进行预测\n",
        "y_test_pred = final_rf_model.predict(X_test_scaled)\n",
        "y_test_proba = final_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 评估测试集上的表现\n",
        "# 混淆矩阵\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "conf_matrix_test_percentage = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_test_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# 绘制测试集 ROC 曲线\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_test, tpr_test, label=f'ROC Curve (AUC = {roc_auc_test:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on Test Set')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 输出 AUC\n",
        "print(f\"Test Set AUC: {roc_auc_test:.2f}\")\n"
      ],
      "metadata": {
        "id": "D9WxC-KcFDcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H2 test set"
      ],
      "metadata": {
        "id": "aukmCuj84Nww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Prepare train data\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# Prepare H2 test data\n",
        "X_test_H2 = H2_test[X_train.columns]  # Ensure consistent columns with training data\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)  # Use the same scaler for H2 test data\n",
        "\n",
        "# Use the optimized parameters\n",
        "best_params = {\n",
        "    'n_estimators': 98,\n",
        "    'max_depth': 20,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'sqrt',\n",
        "    'class_weight': 'balanced',\n",
        "}\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on H2 test set\n",
        "y_test_H2_pred = best_rf.predict(X_test_H2_scaled)\n",
        "y_test_H2_pred_proba = best_rf.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "# Calculate H2 test set metrics\n",
        "test_H2_accuracy = accuracy_score(y_test_H2, y_test_H2_pred)\n",
        "test_H2_roc_auc = roc_auc_score(y_test_H2, y_test_H2_pred_proba)\n",
        "\n",
        "print(\"\\nH2 Test Set Performance Metrics:\")\n",
        "print(f\"Accuracy: {test_H2_accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {test_H2_roc_auc:.4f}\")\n",
        "\n",
        "# Confusion Matrix for H2 Test Set\n",
        "test_H2_conf_matrix = confusion_matrix(y_test_H2, y_test_H2_pred)\n",
        "test_H2_conf_matrix_percentage = test_H2_conf_matrix / test_H2_conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(test_H2_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(test_H2_conf_matrix.shape[0]):\n",
        "    for j in range(test_H2_conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{test_H2_conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H2 Test Set Confusion Matrix (Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for H2 Test Set\n",
        "print(\"\\nH2 Test Set Classification Report:\")\n",
        "print(classification_report(y_test_H2, y_test_H2_pred))\n",
        "\n",
        "# ROC Curve for H2 Test Set\n",
        "fpr_test_H2, tpr_test_H2, _ = roc_curve(y_test_H2, y_test_H2_pred_proba)\n",
        "test_H2_auc = roc_auc_score(y_test_H2, y_test_H2_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_test_H2, tpr_test_H2, label=f'H2 Test Set (AUC = {test_H2_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on H2 Test Set (Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-tgPXfk_z-qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 feature importance"
      ],
      "metadata": {
        "id": "wGdDkuZiCkey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 H2_test 定义测试集特征和目标变量\n",
        "X_test_H2 = H2_test[top_features]\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# 使用训练集的 scaler 对 H2_test 数据集进行标准化\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "# 使用最佳模型预测 H2_test 的结果\n",
        "y_pred_test_H2 = best_rf_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "# 计算 H2_test 的混淆矩阵\n",
        "conf_matrix_test_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_test_H2 = conf_matrix_test_H2 / conf_matrix_test_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制 H2_test 混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test_H2.shape[0]):\n",
        "    for j in range(conf_matrix_test_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出 H2_test 分类报告\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "# 计算 H2_test ROC 曲线和 AUC\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_test_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "print(f\"H2 Test Set AUC: {roc_auc_test_H2:.2f}\")\n",
        "\n",
        "# 绘制 H2_test ROC 曲线\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'H2 Test Set AUC = {roc_auc_test_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VPsuW7xADC-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 使用 H2_test 定义测试集特征和目标变量\n",
        "X_test_H2 = H2_test[top_features]\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# 使用训练集的 scaler 对 H2 测试集进行标准化\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "# 使用最佳参数重新创建随机森林模型\n",
        "best_rf_model = RandomForestClassifier(\n",
        "    n_estimators=study.best_params[\"n_estimators\"],\n",
        "    max_depth=study.best_params[\"max_depth\"],\n",
        "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
        "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
        "    max_features=study.best_params[\"max_features\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 在训练集上拟合模型\n",
        "best_rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 在 H2 测试集上进行预测\n",
        "y_pred_test_H2 = best_rf_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "# 计算 H2 测试集的混淆矩阵\n",
        "conf_matrix_test_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_test_H2 = conf_matrix_test_H2 / conf_matrix_test_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制 H2 测试集的混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test_H2.shape[0]):\n",
        "    for j in range(conf_matrix_test_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (H2 Test Set with Optimized Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出 H2 测试集分类报告\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "# 绘制 H2 测试集的 ROC 曲线\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'H2 Test Set AUC = {roc_auc_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set with Optimized Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fEuQg7Y6U4Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP10 SHAP"
      ],
      "metadata": {
        "id": "c4s3SQGp4Ly_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare H2 test data\n",
        "X_test_H2 = H2_test[X_train.columns]  # 确保测试集的特征与训练集一致\n",
        "y_test_H2 = H2_test['is_canceled']  # 提取目标变量\n",
        "\n",
        "# 使用训练集的 scaler 对 H2_test 进行标准化\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "# 使用最佳模型预测 H2_test 结果\n",
        "y_pred_test_H2 = best_rf_model.predict(X_test_H2_scaled)\n",
        "y_pred_proba_test_H2 = best_rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "# 计算 H2_test 的混淆矩阵\n",
        "conf_matrix_test_H2 = confusion_matrix(y_test_H2, y_pred_test_H2)\n",
        "conf_matrix_percentage_test_H2 = conf_matrix_test_H2 / conf_matrix_test_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制 H2_test 混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_test_H2.shape[0]):\n",
        "    for j in range(conf_matrix_test_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test_H2[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出 H2_test 分类报告\n",
        "print(\"\\nClassification Report (H2 Test Set):\")\n",
        "print(classification_report(y_test_H2, y_pred_test_H2))\n",
        "\n",
        "# 计算 H2_test ROC 曲线和 AUC\n",
        "fpr_H2, tpr_H2, _ = roc_curve(y_test_H2, y_pred_proba_test_H2)\n",
        "roc_auc_test_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "print(f\"H2 Test Set AUC: {roc_auc_test_H2:.2f}\")\n",
        "\n",
        "# 绘制 H2_test ROC 曲线\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_H2, tpr_H2, label=f'H2 Test Set AUC = {roc_auc_test_H2:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (H2 Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3iJyfIwdMKtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "J5ygzbCM4Ly_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 准备 H2 测试数据\n",
        "X_test_H2 = H2_test[X_train.columns]  # 确保 H2 测试集使用和训练集相同的特征\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# 标准化 H2 测试数据\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)  # 使用训练集的 scaler 对 H2 测试集进行转换\n",
        "\n",
        "# 在 H2 测试集上进行预测\n",
        "y_test_H2_pred = final_rf_model.predict(X_test_H2_scaled)\n",
        "y_test_H2_proba = final_rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "# 评估 H2 测试集上的表现\n",
        "# 混淆矩阵\n",
        "conf_matrix_test_H2 = confusion_matrix(y_test_H2, y_test_H2_pred)\n",
        "conf_matrix_test_H2_percentage = conf_matrix_test_H2 / conf_matrix_test_H2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_test_H2, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix_test_H2.shape[0]):\n",
        "    for j in range(conf_matrix_test_H2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_test_H2_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (H2 Test Set)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report on H2 Test Set:\")\n",
        "print(classification_report(y_test_H2, y_test_H2_pred))\n",
        "\n",
        "# 绘制 H2 测试集 ROC 曲线\n",
        "fpr_test_H2, tpr_test_H2, _ = roc_curve(y_test_H2, y_test_H2_proba)\n",
        "roc_auc_test_H2 = roc_auc_score(y_test_H2, y_test_H2_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_test_H2, tpr_test_H2, label=f'ROC Curve (AUC = {roc_auc_test_H2:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve on H2 Test Set')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 输出 AUC\n",
        "print(f\"H2 Test Set AUC: {roc_auc_test_H2:.2f}\")\n"
      ],
      "metadata": {
        "id": "xaJ8keXnF40S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 3.TabNet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p6HqvyoDfNip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "gF0Vmpd-E-iz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1125"
      ],
      "metadata": {
        "id": "N-YX9oCM9NJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "# 定义特征和目标变量\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 设置TabNet参数\n",
        "tabnet_params = {\n",
        "    'n_d': 64,  # 决策步骤的维度\n",
        "    'n_a': 64,  # 注意力步骤的维度\n",
        "    'n_steps': 5,  # 决策步骤数\n",
        "    'gamma': 1.5,  # 特征选择的系数\n",
        "    'n_independent': 2,  # 独立特征转换器的数量\n",
        "    'n_shared': 2,  # 共享特征转换器的数量\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=2e-2),\n",
        "    'scheduler_params': dict(mode=\"min\",\n",
        "                           patience=5,\n",
        "                           min_lr=1e-5,\n",
        "                           factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 创建用于存储交叉验证预测的数组\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = np.zeros_like(y_train)\n",
        "y_pred_proba_cv = np.zeros_like(y_train, dtype=float)\n",
        "\n",
        "# 执行交叉验证\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    # 初始化TabNet模型\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 准备折内数据\n",
        "    X_fold_train = X_train_scaled[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx].values\n",
        "    X_fold_test = X_train_scaled[test_idx]\n",
        "    y_fold_test = y_train.iloc[test_idx].values\n",
        "\n",
        "    # 训练模型\n",
        "    clf.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_test, y_fold_test)],\n",
        "        max_epochs=100,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 保存预测结果\n",
        "    y_pred_cv[test_idx] = clf.predict(X_fold_test)\n",
        "    y_pred_proba_cv[test_idx] = clf.predict_proba(X_fold_test)[:, 1]\n",
        "\n",
        "    # 计算并绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    roc_auc_fold = roc_auc_score(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "# 完成ROC曲线图\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with TabNet (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with TabNet')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算并输出总体ROC AUC\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "# 训练最终模型用于特征重要性分析\n",
        "final_model = TabNetClassifier(**tabnet_params)\n",
        "final_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model (H1 Dataset)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "LxOjadhr9RRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "o-CcdT0DZ0Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# 创建 SHAP Explainer\n",
        "explainer = shap.Explainer(tabnet_model.predict_proba, X_train)\n",
        "\n",
        "# 计算 SHAP 值\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# 绘制特征重要性图\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n"
      ],
      "metadata": {
        "id": "7YU36TlbZ2bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# 从 feature_importance_df 中提取前10个重要特征\n",
        "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
        "print(\"Top 10 important features:\", top_features)\n",
        "\n",
        "# 使用完整特征集数据\n",
        "sample_data = X_train[:200]  # 从完整特征数据中选择前200个样本，以减少计算时间\n",
        "\n",
        "# 使用 SHAP 的 KernelExplainer 进行分析\n",
        "start_time = time.time()\n",
        "print(\"Initializing SHAP KernelExplainer...\")\n",
        "explainer = shap.KernelExplainer(tabnet_model.predict_proba, shap.kmeans(sample_data, 10))\n",
        "shap_values = explainer.shap_values(sample_data)\n",
        "\n",
        "# 计算 SHAP 中位数特征重要性，仅关注前10个特征\n",
        "print(\"Calculating Median SHAP values...\")\n",
        "shap_median_importance = np.median(np.abs(shap_values[1]), axis=0)  # 使用正类（取消）的 SHAP 值\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Median SHAP Value': shap_median_importance[:len(top_features)]  # 仅提取前10个特征的 SHAP 值\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "# 绘制 SHAP 特征重要性条形图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "plt.xlabel('Median SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importance (Median SHAP Values) for TabNet')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# 绘制 SHAP summary plot，使用完整特征集进行绘图\n",
        "print(\"Generating SHAP summary plot...\")\n",
        "shap.summary_plot(shap_values[1], sample_data, plot_type='dot', show=True)\n",
        "\n",
        "# 记录执行时间\n",
        "end_time = time.time()\n",
        "print(f\"Execution completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uRxiJeqKdq4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shap_median_importance:\", len(shap_median_importance))\n",
        "print(\"top_features:\", len(top_features))\n"
      ],
      "metadata": {
        "id": "LZHXuGGyjjyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 从 feature_importance_df 中提取前10个重要特征\n",
        "top_features = feature_importance_df['Feature'].head(10).tolist()\n",
        "print(\"Top 10 important features:\", top_features)\n",
        "\n",
        "# 使用前200个样本数据进行 SHAP 分析\n",
        "sample_data = X_train[:, :10][:200]  # 从完整特征集中选择前10个特征，并抽取前200个样本，减少计算时间\n",
        "\n",
        "# 使用 SHAP 的 KernelExplainer 进行分析\n",
        "start_time = time.time()\n",
        "print(\"Initializing SHAP KernelExplainer...\")\n",
        "explainer = shap.KernelExplainer(tabnet_model.predict_proba, shap.kmeans(sample_data, 10))\n",
        "shap_values = explainer.shap_values(sample_data)\n",
        "\n",
        "# 计算 SHAP 中位数重要性得分，仅关注类别1的特征\n",
        "print(\"Calculating Median SHAP values...\")\n",
        "shap_median_importance = np.median(np.abs(shap_values[1]), axis=0)  # 使用类别1的 SHAP 值\n",
        "shap_importance_df = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Median SHAP Value': shap_median_importance[:len(top_features)]  # 仅提取前10个特征的 SHAP 值\n",
        "}).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "# 绘制 SHAP 特征重要性条形图\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "plt.xlabel('Median SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importance (Median SHAP Values) for TabNet')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# 绘制 SHAP summary plot，使用完整特征集进行绘图\n",
        "print(\"Generating SHAP summary plot...\")\n",
        "shap.summary_plot(shap_values[1], sample_data, plot_type='dot', show=True)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Execution completed in {end_time - start_time:.2f} seconds.\")\n"
      ],
      "metadata": {
        "id": "eKix5w_wqpB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "BOirQcoKrRWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "\n",
        "# 使用 Boruta 选择的特征构建新的训练数据集\n",
        "# 假设 selected_features 已经包含 Boruta 选择的特征\n",
        "X_train_boruta = H1_train[selected_features].values\n",
        "y_train = H1_train['is_canceled'].values\n",
        "\n",
        "# 创建 TabNet 模型\n",
        "tabnet_model = TabNetClassifier(seed=42)\n",
        "\n",
        "# 定义 3 折交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = []\n",
        "y_pred_proba_cv = []\n",
        "\n",
        "# 进行交叉验证并预测\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta, y_train):\n",
        "    print(f\"Training fold {fold_count}...\")\n",
        "    X_train_fold, X_test_fold = X_train_boruta[train_idx], X_train_boruta[test_idx]\n",
        "    y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
        "\n",
        "    # 训练 TabNet 模型\n",
        "    tabnet_model.fit(X_train_fold, y_train_fold, max_epochs=100, patience=20, batch_size=1024, virtual_batch_size=128)\n",
        "\n",
        "    # 预测\n",
        "    y_pred_fold = tabnet_model.predict(X_test_fold)\n",
        "    y_pred_cv.extend(y_pred_fold)\n",
        "\n",
        "    # 预测概率\n",
        "    y_pred_proba_fold = tabnet_model.predict_proba(X_test_fold)[:, 1]\n",
        "    y_pred_proba_cv.extend(y_pred_proba_fold)\n",
        "\n",
        "    fold_count += 1\n",
        "\n",
        "# 将预测结果转换为数组\n",
        "y_pred_cv = np.array(y_pred_cv)\n",
        "y_pred_proba_cv = np.array(y_pred_proba_cv)\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (TabNet with Boruta-selected Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制 ROC 曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba_cv)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (TabNet with Boruta-selected Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SvcTWFLKrTMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Boruta 选择的特征列表\n",
        "selected_features = ['lead_time', 'country', 'deposit_type', 'agent', 'adr', 'total_of_special_requests']\n",
        "\n",
        "# 使用 Boruta 选择的特征定义训练数据和目标变量\n",
        "X_train_boruta = H1_train[selected_features]\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 确保 TabNet 数据格式正确\n",
        "X_train_boruta = X_train_boruta.values\n",
        "y_train = y_train.values\n",
        "\n",
        "# 创建 TabNet 模型\n",
        "tabnet_model = TabNetClassifier(seed=42)\n",
        "\n",
        "# 定义 3 折交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = []\n",
        "y_pred_proba_cv = []\n",
        "\n",
        "# 进行交叉验证并预测\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta, y_train):\n",
        "    print(f\"Training fold {fold_count}...\")\n",
        "    X_train_fold, X_test_fold = X_train_boruta[train_idx], X_train_boruta[test_idx]\n",
        "    y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
        "\n",
        "    # 训练 TabNet 模型\n",
        "    tabnet_model.fit(X_train_fold, y_train_fold, max_epochs=100, patience=20, batch_size=1024, virtual_batch_size=128)\n",
        "\n",
        "    # 预测\n",
        "    y_pred_fold = tabnet_model.predict(X_test_fold)\n",
        "    y_pred_cv.extend(y_pred_fold)\n",
        "\n",
        "    # 预测概率\n",
        "    y_pred_proba_fold = tabnet_model.predict_proba(X_test_fold)[:, 1]\n",
        "    y_pred_proba_cv.extend(y_pred_proba_fold)\n",
        "\n",
        "    fold_count += 1\n",
        "\n",
        "# 将预测结果转换为数组\n",
        "y_pred_cv = np.array(y_pred_cv)\n",
        "y_pred_proba_cv = np.array(y_pred_proba_cv)\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (TabNet with Boruta-selected Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report (TabNet with Boruta-selected Features):\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的 ROC 曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_boruta, y_train):\n",
        "    # 在每个折上获取预测概率\n",
        "    y_pred_proba_fold = tabnet_model.predict_proba(X_train_boruta[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (TabNet with Boruta-selected Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E_7jzzg1wbGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "NAiATXtiFBPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10"
      ],
      "metadata": {
        "id": "sTdFp-T0VD6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 首先训练一个模型来获取 top 10 特征\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.5),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    mask_type='entmax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 准备初始数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 训练初始模型获取特征重要性\n",
        "initial_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取 top 10 特征\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_10_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features:\")\n",
        "print(top_10_features)\n",
        "\n",
        "# 使用 top 10 特征重新准备数据\n",
        "X_train_top10 = X_train[top_10_features]\n",
        "X_train_scaled_top10 = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# TabNet参数\n",
        "tabnet_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 64,\n",
        "    'n_steps': 5,\n",
        "    'gamma': 1.5,\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=2e-2),\n",
        "    'scheduler_params': dict(mode=\"min\",\n",
        "                           patience=5,\n",
        "                           min_lr=1e-5,\n",
        "                           factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 创建用于存储交叉验证预测的数组\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = np.zeros_like(y_train)\n",
        "y_pred_proba_cv = np.zeros_like(y_train, dtype=float)\n",
        "\n",
        "# 执行交叉验证\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top10, y_train):\n",
        "    # 初始化TabNet模型\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 准备折内数据\n",
        "    X_fold_train = X_train_scaled_top10[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx].values\n",
        "    X_fold_test = X_train_scaled_top10[test_idx]\n",
        "    y_fold_test = y_train.iloc[test_idx].values\n",
        "\n",
        "    # 训练模型\n",
        "    clf.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_test, y_fold_test)],\n",
        "        max_epochs=100,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 保存预测结果\n",
        "    y_pred_cv[test_idx] = clf.predict(X_fold_test)\n",
        "    y_pred_proba_cv[test_idx] = clf.predict_proba(X_fold_test)[:, 1]\n",
        "\n",
        "    # 计算并绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    roc_auc_fold = roc_auc_score(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "# 完成ROC曲线图\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with TabNet (Top 10 Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with TabNet (Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算并输出总体ROC AUC\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "# 训练最终模型用于特征重要性分析\n",
        "final_model = TabNetClassifier(**tabnet_params)\n",
        "final_model.fit(\n",
        "    X_train_scaled_top10, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train_top10.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model (H1 Dataset, Top 10 Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train_top10)}\")\n",
        "print(f\"Number of Features: {X_train_top10.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "XuzWN3beVD6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10"
      ],
      "metadata": {
        "id": "fDowMZnXVD6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "import shap\n",
        "\n",
        "# 准备初始数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 首先训练一个初始模型用于SHAP值计算\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.5),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    mask_type='entmax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 训练初始模型\n",
        "initial_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 计算SHAP值\n",
        "background = shap.kmeans(X_train_scaled, k=20)  # 选择一些背景样本\n",
        "explainer = shap.KernelExplainer(initial_model.predict_proba, background)\n",
        "shap_values = explainer.shap_values(X_train_scaled[:100])  # 使用部分样本计算SHAP值\n",
        "\n",
        "# 计算每个特征的平均绝对SHAP值\n",
        "mean_abs_shap = np.mean(np.abs(shap_values[1]), axis=0)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': mean_abs_shap\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 获取top 10特征\n",
        "top_10_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features by SHAP:\")\n",
        "print(top_10_features)\n",
        "\n",
        "# 使用top 10特征重新准备数据\n",
        "X_train_top10 = X_train[top_10_features]\n",
        "X_train_scaled_top10 = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# TabNet参数\n",
        "tabnet_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 64,\n",
        "    'n_steps': 5,\n",
        "    'gamma': 1.5,\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=2e-2),\n",
        "    'scheduler_params': dict(mode=\"min\",\n",
        "                           patience=5,\n",
        "                           min_lr=1e-5,\n",
        "                           factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 创建用于存储交叉验证预测的数组\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = np.zeros_like(y_train)\n",
        "y_pred_proba_cv = np.zeros_like(y_train, dtype=float)\n",
        "\n",
        "# 执行交叉验证\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top10, y_train):\n",
        "    # 初始化TabNet模型\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 准备折内数据\n",
        "    X_fold_train = X_train_scaled_top10[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx].values\n",
        "    X_fold_test = X_train_scaled_top10[test_idx]\n",
        "    y_fold_test = y_train.iloc[test_idx].values\n",
        "\n",
        "    # 训练模型\n",
        "    clf.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_test, y_fold_test)],\n",
        "        max_epochs=100,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 保存预测结果\n",
        "    y_pred_cv[test_idx] = clf.predict(X_fold_test)\n",
        "    y_pred_proba_cv[test_idx] = clf.predict_proba(X_fold_test)[:, 1]\n",
        "\n",
        "    # 计算并绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    roc_auc_fold = roc_auc_score(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "# 完成ROC曲线图\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with TabNet (SHAP Top 10 Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with TabNet (SHAP Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算并输出总体ROC AUC\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "# 训练最终模型用于特征重要性分析\n",
        "final_model = TabNetClassifier(**tabnet_params)\n",
        "final_model.fit(\n",
        "    X_train_scaled_top10, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取特征重要性\n",
        "feature_importance_final = pd.DataFrame({\n",
        "    'Feature': X_train_top10.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance_final, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model (SHAP Top 10 Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印SHAP特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(shap_values[1][:, feature_importance.index[:10]],\n",
        "                 X_train.iloc[:100, feature_importance.index[:10]],\n",
        "                 plot_type=\"bar\")\n",
        "plt.title('SHAP Feature Importance (Top 10 Features)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train_top10)}\")\n",
        "print(f\"Number of Features: {X_train_top10.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "tbg_Fc7aVD60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA 4"
      ],
      "metadata": {
        "id": "sonqPsoUVD60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 准备初始数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用Boruta进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
        "\n",
        "# 运行Boruta\n",
        "boruta.fit(X_train_scaled, y_train.values)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_features = X_train.columns[boruta.support_].tolist()\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "print(selected_features)\n",
        "print(f\"\\nTotal number of selected features: {len(selected_features)}\")\n",
        "\n",
        "# 使用Boruta选中的特征重新准备数据\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "# TabNet参数\n",
        "tabnet_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 64,\n",
        "    'n_steps': 5,\n",
        "    'gamma': 1.5,\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=2e-2),\n",
        "    'scheduler_params': dict(mode=\"min\",\n",
        "                           patience=5,\n",
        "                           min_lr=1e-5,\n",
        "                           factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 创建用于存储交叉验证预测的数组\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = np.zeros_like(y_train)\n",
        "y_pred_proba_cv = np.zeros_like(y_train, dtype=float)\n",
        "\n",
        "# 执行交叉验证\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    # 初始化TabNet模型\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 准备折内数据\n",
        "    X_fold_train = X_train_scaled_selected[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx].values\n",
        "    X_fold_test = X_train_scaled_selected[test_idx]\n",
        "    y_fold_test = y_train.iloc[test_idx].values\n",
        "\n",
        "    # 训练模型\n",
        "    clf.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_test, y_fold_test)],\n",
        "        max_epochs=100,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 保存预测结果\n",
        "    y_pred_cv[test_idx] = clf.predict(X_fold_test)\n",
        "    y_pred_proba_cv[test_idx] = clf.predict_proba(X_fold_test)[:, 1]\n",
        "\n",
        "    # 计算并绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    roc_auc_fold = roc_auc_score(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "# 完成ROC曲线图\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with TabNet (Boruta Selected Features, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with TabNet (Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算并输出总体ROC AUC\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "# 训练最终模型用于特征重要性分析\n",
        "final_model = TabNetClassifier(**tabnet_params)\n",
        "final_model.fit(\n",
        "    X_train_scaled_selected, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train_selected.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model (H1 Dataset, Boruta Selected Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train_selected)}\")\n",
        "print(f\"Number of Features: {X_train_selected.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "KFSOfINhVD60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "gYkdvnXzFDx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE"
      ],
      "metadata": {
        "id": "VOmRGN6wVCaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "# 准备数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义Optuna优化目标函数\n",
        "def objective(trial):\n",
        "    tabnet_params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [8, 16, 32, 64]),\n",
        "        'n_a': trial.suggest_categorical('n_a', [8, 16, 32, 64]),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': trial.suggest_int('n_independent', 1, 3),\n",
        "        'n_shared': trial.suggest_int('n_shared', 1, 3),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.005])\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'mode': 'min',\n",
        "            'patience': 5,\n",
        "            'min_lr': 1e-5,\n",
        "            'factor': 0.5\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax',\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 使用单次验证集\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X_train_scaled, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train_split, y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        max_epochs=30,\n",
        "        patience=5,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    pred_proba = clf.predict_proba(X_val_split)[:, 1]\n",
        "    return roc_auc_score(y_val_split, pred_proba)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"Starting Optuna optimization...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "# 打印最佳参数\n",
        "print(\"\\nBest parameters:\", study.best_trial.params)\n",
        "print(\"Best AUC score:\", study.best_trial.value)\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "final_params = {\n",
        "    'n_d': best_params['n_d'],\n",
        "    'n_a': best_params['n_a'],\n",
        "    'n_steps': best_params['n_steps'],\n",
        "    'gamma': best_params['gamma'],\n",
        "    'n_independent': best_params['n_independent'],\n",
        "    'n_shared': best_params['n_shared'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "print(\"\\nTraining final model with best parameters...\")\n",
        "best_model = TabNetClassifier(**final_params)\n",
        "best_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    eval_set=[(X_train_scaled, y_train.values)],\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 计算预测和预测概率\n",
        "y_pred = best_model.predict(X_train_scaled)\n",
        "y_pred_proba = best_model.predict_proba(X_train_scaled)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label=f'Optimized TabNet (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with Optimized TabNet')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算和绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with Optimized TabNet')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# 分析特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized TabNet Model (H1 Dataset)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 绘制Optuna优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "plt.title('Optuna Optimization History')\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "h-sYWPoeVCaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10"
      ],
      "metadata": {
        "id": "Ngxrf3WdVCaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "# 准备初始数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 首先训练一个初始模型来获取 top 10 特征\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.5),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    mask_type='entmax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 训练初始模型获取特征重要性\n",
        "initial_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取 top 10 特征\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_10_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features:\")\n",
        "print(top_10_features)\n",
        "\n",
        "# 使用 top 10 特征重新准备数据\n",
        "X_train_top10 = X_train[top_10_features]\n",
        "X_train_scaled_top10 = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "# 定义Optuna优化目标函数\n",
        "def objective(trial):\n",
        "    tabnet_params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [8, 16, 32, 64]),\n",
        "        'n_a': trial.suggest_categorical('n_a', [8, 16, 32, 64]),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': trial.suggest_int('n_independent', 1, 3),\n",
        "        'n_shared': trial.suggest_int('n_shared', 1, 3),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.005])\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'mode': 'min',\n",
        "            'patience': 5,\n",
        "            'min_lr': 1e-5,\n",
        "            'factor': 0.5\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax',\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 使用单次验证集\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X_train_scaled_top10, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train_split, y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        max_epochs=30,\n",
        "        patience=5,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    pred_proba = clf.predict_proba(X_val_split)[:, 1]\n",
        "    return roc_auc_score(y_val_split, pred_proba)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"Starting Optuna optimization...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "# 打印最佳参数\n",
        "print(\"\\nBest parameters:\", study.best_trial.params)\n",
        "print(\"Best AUC score:\", study.best_trial.value)\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "final_params = {\n",
        "    'n_d': best_params['n_d'],\n",
        "    'n_a': best_params['n_a'],\n",
        "    'n_steps': best_params['n_steps'],\n",
        "    'gamma': best_params['gamma'],\n",
        "    'n_independent': best_params['n_independent'],\n",
        "    'n_shared': best_params['n_shared'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "print(\"\\nTraining final model with best parameters...\")\n",
        "best_model = TabNetClassifier(**final_params)\n",
        "best_model.fit(\n",
        "    X_train_scaled_top10, y_train.values,\n",
        "    eval_set=[(X_train_scaled_top10, y_train.values)],\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 计算预测和预测概率\n",
        "y_pred = best_model.predict(X_train_scaled_top10)\n",
        "y_pred_proba = best_model.predict_proba(X_train_scaled_top10)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label=f'Optimized TabNet (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with Optimized TabNet (Top 10 Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算和绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with Optimized TabNet (Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# 分析特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': top_10_features,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized TabNet Model (Top 10 Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 绘制Optuna优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "plt.title('Optuna Optimization History (Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train_top10)}\")\n",
        "print(f\"Number of Features: {X_train_top10.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "bu654TqHVCaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "5_W4Szz0VCaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "# 准备初始数据\n",
        "X_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H1_train['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用Boruta进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
        "\n",
        "# 运行Boruta\n",
        "boruta.fit(X_train_scaled, y_train.values)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_features = X_train.columns[boruta.support_].tolist()\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "print(selected_features)\n",
        "print(f\"\\nTotal number of selected features: {len(selected_features)}\")\n",
        "\n",
        "# 使用Boruta选中的特征重新准备数据\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "# 定义Optuna优化目标函数\n",
        "def objective(trial):\n",
        "    tabnet_params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [8, 16, 32, 64]),\n",
        "        'n_a': trial.suggest_categorical('n_a', [8, 16, 32, 64]),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': trial.suggest_int('n_independent', 1, 3),\n",
        "        'n_shared': trial.suggest_int('n_shared', 1, 3),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.005])\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'mode': 'min',\n",
        "            'patience': 5,\n",
        "            'min_lr': 1e-5,\n",
        "            'factor': 0.5\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax',\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 使用单次验证集\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X_train_scaled_selected, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train_split, y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        max_epochs=30,\n",
        "        patience=5,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    pred_proba = clf.predict_proba(X_val_split)[:, 1]\n",
        "    return roc_auc_score(y_val_split, pred_proba)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"Starting Optuna optimization...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "# 打印最佳参数\n",
        "print(\"\\nBest parameters:\", study.best_trial.params)\n",
        "print(\"Best AUC score:\", study.best_trial.value)\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "final_params = {\n",
        "    'n_d': best_params['n_d'],\n",
        "    'n_a': best_params['n_a'],\n",
        "    'n_steps': best_params['n_steps'],\n",
        "    'gamma': best_params['gamma'],\n",
        "    'n_independent': best_params['n_independent'],\n",
        "    'n_shared': best_params['n_shared'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "print(\"\\nTraining final model with best parameters...\")\n",
        "best_model = TabNetClassifier(**final_params)\n",
        "best_model.fit(\n",
        "    X_train_scaled_selected, y_train.values,\n",
        "    eval_set=[(X_train_scaled_selected, y_train.values)],\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 计算预测和预测概率\n",
        "y_pred = best_model.predict(X_train_scaled_selected)\n",
        "y_pred_proba = best_model.predict_proba(X_train_scaled_selected)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label=f'Optimized TabNet (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for H1 Dataset with Optimized TabNet (Boruta Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算和绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('H1 Confusion Matrix with Optimized TabNet (Boruta Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# 分析特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized TabNet Model (Boruta Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 绘制Optuna优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "plt.title('Optuna Optimization History (Boruta Features)')\n",
        "plt.show()\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train_selected)}\")\n",
        "print(f\"Number of Features: {X_train_selected.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "2IObcoDwVCaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "_0u1kPa3XSJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE"
      ],
      "metadata": {
        "id": "ICV2Ltu-Xbxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 最佳参数配置\n",
        "best_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 32,\n",
        "    'n_steps': 3,\n",
        "    'gamma': 1.0072198139700859,\n",
        "    'n_independent': 1,\n",
        "    'n_shared': 1,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': 0.02},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 准备数据\n",
        "# H1数据\n",
        "X_h1_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_train = H1_train['is_canceled']\n",
        "X_h1_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_test = H1_test['is_canceled']\n",
        "\n",
        "# H2数据\n",
        "X_h2_test = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h2_test = H2_test['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_h1_train_scaled = scaler.fit_transform(X_h1_train)\n",
        "X_h1_test_scaled = scaler.transform(X_h1_test)\n",
        "X_h2_test_scaled = scaler.transform(X_h2_test)\n",
        "\n",
        "# 训练模型\n",
        "print(\"Training model on H1 training data...\")\n",
        "model = TabNetClassifier(**best_params)\n",
        "model.fit(\n",
        "    X_h1_train_scaled, y_h1_train,\n",
        "    eval_set=[(X_h1_train_scaled, y_h1_train)],\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 在H1测试集上评估\n",
        "print(\"\\nEvaluating on H1 test set...\")\n",
        "y_h1_pred = model.predict(X_h1_test_scaled)\n",
        "y_h1_pred_proba = model.predict_proba(X_h1_test_scaled)[:, 1]\n",
        "\n",
        "# 在H2测试集上评估\n",
        "print(\"\\nEvaluating on H2 test set...\")\n",
        "y_h2_pred = model.predict(X_h2_test_scaled)\n",
        "y_h2_pred_proba = model.predict_proba(X_h2_test_scaled)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线对比\n",
        "plt.figure(figsize=(12, 8))\n",
        "# H1 ROC\n",
        "fpr_h1, tpr_h1, _ = roc_curve(y_h1_test, y_h1_pred_proba)\n",
        "roc_auc_h1 = roc_auc_score(y_h1_test, y_h1_pred_proba)\n",
        "plt.plot(fpr_h1, tpr_h1, label=f'H1 Test (AUC = {roc_auc_h1:.2f})', color='blue')\n",
        "\n",
        "# H2 ROC\n",
        "fpr_h2, tpr_h2, _ = roc_curve(y_h2_test, y_h2_pred_proba)\n",
        "roc_auc_h2 = roc_auc_score(y_h2_test, y_h2_pred_proba)\n",
        "plt.plot(fpr_h2, tpr_h2, label=f'H2 Test (AUC = {roc_auc_h2:.2f})', color='red')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison: H1 vs H2 Test Sets')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 创建混淆矩阵对比图\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# H1混淆矩阵\n",
        "conf_matrix_h1 = confusion_matrix(y_h1_test, y_h1_pred)\n",
        "conf_matrix_percentage_h1 = conf_matrix_h1 / conf_matrix_h1.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h1, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax1)\n",
        "for i in range(conf_matrix_h1.shape[0]):\n",
        "    for j in range(conf_matrix_h1.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h1[i, j]:.1f}%\"\n",
        "        ax1.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax1.set_title('H1 Test Set Confusion Matrix')\n",
        "ax1.set_xlabel('Predicted Label')\n",
        "ax1.set_ylabel('True Label')\n",
        "\n",
        "# H2混淆矩阵\n",
        "conf_matrix_h2 = confusion_matrix(y_h2_test, y_h2_pred)\n",
        "conf_matrix_percentage_h2 = conf_matrix_h2 / conf_matrix_h2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h2, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax2)\n",
        "for i in range(conf_matrix_h2.shape[0]):\n",
        "    for j in range(conf_matrix_h2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h2[i, j]:.1f}%\"\n",
        "        ax2.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax2.set_title('H2 Test Set Confusion Matrix')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "ax2.set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 对比性能指标\n",
        "def print_metrics(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(f\"ROC AUC Score: {roc_auc_score(y_true, y_pred_proba):.4f}\")\n",
        "\n",
        "print_metrics(y_h1_test, y_h1_pred, y_h1_pred_proba, \"H1 Test Set\")\n",
        "print_metrics(y_h2_test, y_h2_pred, y_h2_pred_proba, \"H2 Test Set\")\n",
        "\n",
        "# 特征重要性分析\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_h1_train.columns,\n",
        "    'Importance': model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 更新最后的性能指标对比部分\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 计算所有指标\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(y_h1_test, y_h1_pred), accuracy_score(y_h2_test, y_h2_pred)],\n",
        "    'ROC AUC': [roc_auc_score(y_h1_test, y_h1_pred_proba), roc_auc_score(y_h2_test, y_h2_pred_proba)],\n",
        "    'Precision': [precision_score(y_h1_test, y_h1_pred), precision_score(y_h2_test, y_h2_pred)],\n",
        "    'Recall': [recall_score(y_h1_test, y_h1_pred), recall_score(y_h2_test, y_h2_pred)],\n",
        "    'F1 Score': [f1_score(y_h1_test, y_h1_pred), f1_score(y_h2_test, y_h2_pred)]\n",
        "}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics, index=['H1 Test', 'H2 Test'])\n",
        "\n",
        "# 设置更大的图形尺寸以适应更多指标\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# 创建分组柱状图\n",
        "bar_width = 0.35\n",
        "x = np.arange(len(df_metrics.index))\n",
        "\n",
        "# 使用不同的颜色绘制每个指标\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEEAD']\n",
        "for i, (metric, values) in enumerate(df_metrics.items()):\n",
        "    plt.bar(x + i * bar_width, values, bar_width,\n",
        "            label=metric, color=colors[i % len(colors)])\n",
        "\n",
        "# 优化图表样式\n",
        "plt.title('Performance Metrics Comparison: H1 vs H2', fontsize=14, pad=20)\n",
        "plt.xlabel('Dataset', fontsize=12)\n",
        "plt.ylabel('Score', fontsize=12)\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# 设置x轴刻度\n",
        "plt.xticks(x + bar_width * 2, df_metrics.index)\n",
        "\n",
        "# 在每个柱子上添加数值标签\n",
        "for i, metric in enumerate(df_metrics.columns):\n",
        "    for j, value in enumerate(df_metrics[metric]):\n",
        "        plt.text(j + i * bar_width, value, f'{value:.3f}',\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "# 调整布局以确保图例完全可见\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印详细的指标对比表格\n",
        "print(\"\\nDetailed Performance Metrics:\")\n",
        "print(df_metrics.round(4))\n",
        "\n",
        "# 打印数据集信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(\"H1 Test Set:\")\n",
        "print(f\"Total Samples: {len(X_h1_test)}\")\n",
        "print(\"Class Distribution:\")\n",
        "print(y_h1_test.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "print(\"\\nH2 Test Set:\")\n",
        "print(f\"Total Samples: {len(X_h2_test)}\")\n",
        "print(\"Class Distribution:\")\n",
        "print(y_h2_test.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "0iqRnV1pXdAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 更新性能指标可视化部分\n",
        "import numpy as np\n",
        "\n",
        "# 准备数据\n",
        "datasets = ['H1 Test', 'H2 Test']\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(y_h1_test, y_h1_pred), accuracy_score(y_h2_test, y_h2_pred)],\n",
        "    'Precision': [precision_score(y_h1_test, y_h1_pred), precision_score(y_h2_test, y_h2_pred)],\n",
        "    'Recall': [recall_score(y_h1_test, y_h1_pred), recall_score(y_h2_test, y_h2_pred)],\n",
        "    'F1 Score': [f1_score(y_h1_test, y_h1_pred), f1_score(y_h2_test, y_h2_pred)],\n",
        "    'ROC AUC': [roc_auc_score(y_h1_test, y_h1_pred_proba), roc_auc_score(y_h2_test, y_h2_pred_proba)]\n",
        "}\n",
        "\n",
        "# 设置图形样式\n",
        "plt.figure(figsize=(12, 10))\n",
        "x = np.arange(len(datasets))\n",
        "width = 0.15  # 柱子的宽度\n",
        "multiplier = 0\n",
        "\n",
        "# 设置颜色方案\n",
        "colors = ['#4e79a7', '#f28e2b', '#59a14f', '#e15759', '#76b7b2']\n",
        "\n",
        "# 绘制每个指标的柱子\n",
        "for attribute, values in metrics.items():\n",
        "    offset = width * multiplier\n",
        "    rects = plt.bar(x + offset, values, width, label=attribute, color=colors[multiplier])\n",
        "    multiplier += 1\n",
        "\n",
        "# 优化图表样式\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance Metrics Comparison: H1 vs H2')\n",
        "plt.xticks(x + width * 2, datasets)  # 将x轴标签放在分组的中间\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "# 在柱子上添加数值标签\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        plt.text(rect.get_x() + rect.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', rotation=90)\n",
        "\n",
        "# 为所有柱子添加标签\n",
        "for container in plt.gca().containers:\n",
        "    autolabel(container)\n",
        "\n",
        "# 调整布局\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印详细的指标表格\n",
        "df_metrics = pd.DataFrame(metrics, index=datasets)\n",
        "print(\"\\nDetailed Performance Metrics:\")\n",
        "print(df_metrics.round(4))"
      ],
      "metadata": {
        "id": "HEFnr2kBgmC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10"
      ],
      "metadata": {
        "id": "FrxT6FwnXbxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 准备数据\n",
        "# H1数据\n",
        "X_h1_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_train = H1_train['is_canceled']\n",
        "X_h1_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_test = H1_test['is_canceled']\n",
        "\n",
        "# H2数据\n",
        "X_h2_test = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h2_test = H2_test['is_canceled']\n",
        "\n",
        "# 设置最佳参数\n",
        "best_params = {\n",
        "    'n_d': 8,\n",
        "    'n_a': 32,\n",
        "    'n_steps': 4,\n",
        "    'gamma': 1.1704703445472,\n",
        "    'n_independent': 3,\n",
        "    'n_shared': 2,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': 0.02},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 首先获取top 10特征\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params=dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.5),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    mask_type='entmax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_h1_train_scaled = scaler.fit_transform(X_h1_train)\n",
        "\n",
        "# 训练初始模型获取特征重要性\n",
        "initial_model.fit(\n",
        "    X_h1_train_scaled, y_h1_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取top 10特征\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_h1_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_10_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features:\")\n",
        "print(top_10_features)\n",
        "\n",
        "# 使用top 10特征准备数据\n",
        "X_h1_train_top10 = X_h1_train[top_10_features]\n",
        "X_h1_test_top10 = X_h1_test[top_10_features]\n",
        "X_h2_test_top10 = X_h2_test[top_10_features]\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_h1_train_scaled = scaler.fit_transform(X_h1_train_top10)\n",
        "X_h1_test_scaled = scaler.transform(X_h1_test_top10)\n",
        "X_h2_test_scaled = scaler.transform(X_h2_test_top10)\n",
        "\n",
        "# 训练最终模型\n",
        "final_model = TabNetClassifier(**best_params)\n",
        "final_model.fit(\n",
        "    X_h1_train_scaled, y_h1_train.values,\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 进行预测\n",
        "y_h1_pred = final_model.predict(X_h1_test_scaled)\n",
        "y_h1_pred_proba = final_model.predict_proba(X_h1_test_scaled)[:, 1]\n",
        "y_h2_pred = final_model.predict(X_h2_test_scaled)\n",
        "y_h2_pred_proba = final_model.predict_proba(X_h2_test_scaled)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线对比\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# H1 ROC\n",
        "fpr_h1, tpr_h1, _ = roc_curve(y_h1_test, y_h1_pred_proba)\n",
        "roc_auc_h1 = roc_auc_score(y_h1_test, y_h1_pred_proba)\n",
        "plt.plot(fpr_h1, tpr_h1, label=f'H1 Test (AUC = {roc_auc_h1:.2f})', color='blue')\n",
        "\n",
        "# H2 ROC\n",
        "fpr_h2, tpr_h2, _ = roc_curve(y_h2_test, y_h2_pred_proba)\n",
        "roc_auc_h2 = roc_auc_score(y_h2_test, y_h2_pred_proba)\n",
        "plt.plot(fpr_h2, tpr_h2, label=f'H2 Test (AUC = {roc_auc_h2:.2f})', color='red')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison: H1 vs H2 Test Sets (Top 10 Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 创建混淆矩阵对比图\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# H1混淆矩阵\n",
        "conf_matrix_h1 = confusion_matrix(y_h1_test, y_h1_pred)\n",
        "conf_matrix_percentage_h1 = conf_matrix_h1 / conf_matrix_h1.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h1, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax1)\n",
        "for i in range(conf_matrix_h1.shape[0]):\n",
        "    for j in range(conf_matrix_h1.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h1[i, j]:.1f}%\"\n",
        "        ax1.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax1.set_title('H1 Test Set Confusion Matrix (Top 10 Features)')\n",
        "ax1.set_xlabel('Predicted Label')\n",
        "ax1.set_ylabel('True Label')\n",
        "\n",
        "# H2混淆矩阵\n",
        "conf_matrix_h2 = confusion_matrix(y_h2_test, y_h2_pred)\n",
        "conf_matrix_percentage_h2 = conf_matrix_h2 / conf_matrix_h2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h2, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax2)\n",
        "for i in range(conf_matrix_h2.shape[0]):\n",
        "    for j in range(conf_matrix_h2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h2[i, j]:.1f}%\"\n",
        "        ax2.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax2.set_title('H2 Test Set Confusion Matrix (Top 10 Features)')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "ax2.set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 性能指标对比可视化\n",
        "datasets = ['H1 Test', 'H2 Test']\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(y_h1_test, y_h1_pred), accuracy_score(y_h2_test, y_h2_pred)],\n",
        "    'Precision': [precision_score(y_h1_test, y_h1_pred), precision_score(y_h2_test, y_h2_pred)],\n",
        "    'Recall': [recall_score(y_h1_test, y_h1_pred), recall_score(y_h2_test, y_h2_pred)],\n",
        "    'F1 Score': [f1_score(y_h1_test, y_h1_pred), f1_score(y_h2_test, y_h2_pred)],\n",
        "    'ROC AUC': [roc_auc_score(y_h1_test, y_h1_pred_proba), roc_auc_score(y_h2_test, y_h2_pred_proba)]\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "x = np.arange(len(datasets))\n",
        "width = 0.15\n",
        "multiplier = 0\n",
        "colors = ['#4e79a7', '#f28e2b', '#59a14f', '#e15759', '#76b7b2']\n",
        "\n",
        "for attribute, values in metrics.items():\n",
        "    offset = width * multiplier\n",
        "    rects = plt.bar(x + offset, values, width, label=attribute, color=colors[multiplier])\n",
        "    multiplier += 1\n",
        "\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance Metrics Comparison: H1 vs H2 (Top 10 Features)')\n",
        "plt.xticks(x + width * 2, datasets)\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        plt.text(rect.get_x() + rect.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', rotation=90)\n",
        "\n",
        "for container in plt.gca().containers:\n",
        "    autolabel(container)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 输出详细性能指标\n",
        "df_metrics = pd.DataFrame(metrics, index=datasets)\n",
        "print(\"\\nDetailed Performance Metrics:\")\n",
        "print(df_metrics.round(4))\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nH1 Test Set Classification Report:\")\n",
        "print(classification_report(y_h1_test, y_h1_pred))\n",
        "\n",
        "print(\"\\nH2 Test Set Classification Report:\")\n",
        "print(classification_report(y_h2_test, y_h2_pred))"
      ],
      "metadata": {
        "id": "r0MLEHMKAWn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "aVpjLCeuXbxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 准备数据\n",
        "# H1数据\n",
        "X_h1_train = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_train = H1_train['is_canceled']\n",
        "X_h1_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_test = H1_test['is_canceled']\n",
        "\n",
        "# H2数据\n",
        "X_h2_test = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h2_test = H2_test['is_canceled']\n",
        "\n",
        "# 设置最佳参数\n",
        "best_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 64,\n",
        "    'n_steps': 5,\n",
        "    'gamma': 1.0003359875270394,\n",
        "    'n_independent': 3,\n",
        "    'n_shared': 3,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': 0.02},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# 标准化初始数据用于Boruta\n",
        "scaler = StandardScaler()\n",
        "X_h1_train_scaled = scaler.fit_transform(X_h1_train)\n",
        "\n",
        "# 使用Boruta进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
        "\n",
        "# 运行Boruta\n",
        "boruta.fit(X_h1_train_scaled, y_h1_train.values)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_features = X_h1_train.columns[boruta.support_].tolist()\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "print(selected_features)\n",
        "print(f\"\\nTotal number of selected features: {len(selected_features)}\")\n",
        "\n",
        "# 使用Boruta选中的特征准备数据\n",
        "X_h1_train_selected = X_h1_train[selected_features]\n",
        "X_h1_test_selected = X_h1_test[selected_features]\n",
        "X_h2_test_selected = X_h2_test[selected_features]\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_h1_train_scaled = scaler.fit_transform(X_h1_train_selected)\n",
        "X_h1_test_scaled = scaler.transform(X_h1_test_selected)\n",
        "X_h2_test_scaled = scaler.transform(X_h2_test_selected)\n",
        "\n",
        "# 训练最终模型\n",
        "final_model = TabNetClassifier(**best_params)\n",
        "final_model.fit(\n",
        "    X_h1_train_scaled, y_h1_train.values,\n",
        "    max_epochs=100,\n",
        "    batch_size=2048,\n",
        "    virtual_batch_size=256\n",
        ")\n",
        "\n",
        "# 进行预测\n",
        "y_h1_pred = final_model.predict(X_h1_test_scaled)\n",
        "y_h1_pred_proba = final_model.predict_proba(X_h1_test_scaled)[:, 1]\n",
        "y_h2_pred = final_model.predict(X_h2_test_scaled)\n",
        "y_h2_pred_proba = final_model.predict_proba(X_h2_test_scaled)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线对比\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# H1 ROC\n",
        "fpr_h1, tpr_h1, _ = roc_curve(y_h1_test, y_h1_pred_proba)\n",
        "roc_auc_h1 = roc_auc_score(y_h1_test, y_h1_pred_proba)\n",
        "plt.plot(fpr_h1, tpr_h1, label=f'H1 Test (AUC = {roc_auc_h1:.2f})', color='blue')\n",
        "\n",
        "# H2 ROC\n",
        "fpr_h2, tpr_h2, _ = roc_curve(y_h2_test, y_h2_pred_proba)\n",
        "roc_auc_h2 = roc_auc_score(y_h2_test, y_h2_pred_proba)\n",
        "plt.plot(fpr_h2, tpr_h2, label=f'H2 Test (AUC = {roc_auc_h2:.2f})', color='red')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison: H1 vs H2 Test Sets (Boruta Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 创建混淆矩阵对比图\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# H1混淆矩阵\n",
        "conf_matrix_h1 = confusion_matrix(y_h1_test, y_h1_pred)\n",
        "conf_matrix_percentage_h1 = conf_matrix_h1 / conf_matrix_h1.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h1, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax1)\n",
        "for i in range(conf_matrix_h1.shape[0]):\n",
        "    for j in range(conf_matrix_h1.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h1[i, j]:.1f}%\"\n",
        "        ax1.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax1.set_title('H1 Test Set Confusion Matrix (Boruta Features)')\n",
        "ax1.set_xlabel('Predicted Label')\n",
        "ax1.set_ylabel('True Label')\n",
        "\n",
        "# H2混淆矩阵\n",
        "conf_matrix_h2 = confusion_matrix(y_h2_test, y_h2_pred)\n",
        "conf_matrix_percentage_h2 = conf_matrix_h2 / conf_matrix_h2.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_h2, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax2)\n",
        "for i in range(conf_matrix_h2.shape[0]):\n",
        "    for j in range(conf_matrix_h2.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_h2[i, j]:.1f}%\"\n",
        "        ax2.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "ax2.set_title('H2 Test Set Confusion Matrix (Boruta Features)')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "ax2.set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 性能指标对比可视化\n",
        "datasets = ['H1 Test', 'H2 Test']\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(y_h1_test, y_h1_pred), accuracy_score(y_h2_test, y_h2_pred)],\n",
        "    'Precision': [precision_score(y_h1_test, y_h1_pred), precision_score(y_h2_test, y_h2_pred)],\n",
        "    'Recall': [recall_score(y_h1_test, y_h1_pred), recall_score(y_h2_test, y_h2_pred)],\n",
        "    'F1 Score': [f1_score(y_h1_test, y_h1_pred), f1_score(y_h2_test, y_h2_pred)],\n",
        "    'ROC AUC': [roc_auc_score(y_h1_test, y_h1_pred_proba), roc_auc_score(y_h2_test, y_h2_pred_proba)]\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "x = np.arange(len(datasets))\n",
        "width = 0.15\n",
        "multiplier = 0\n",
        "colors = ['#4e79a7', '#f28e2b', '#59a14f', '#e15759', '#76b7b2']\n",
        "\n",
        "for attribute, values in metrics.items():\n",
        "    offset = width * multiplier\n",
        "    rects = plt.bar(x + offset, values, width, label=attribute, color=colors[multiplier])\n",
        "    multiplier += 1\n",
        "\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance Metrics Comparison: H1 vs H2 (Boruta Features)')\n",
        "plt.xticks(x + width * 2, datasets)\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        plt.text(rect.get_x() + rect.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', rotation=90)\n",
        "\n",
        "for container in plt.gca().containers:\n",
        "    autolabel(container)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 输出详细性能指标\n",
        "df_metrics = pd.DataFrame(metrics, index=datasets)\n",
        "print(\"\\nDetailed Performance Metrics:\")\n",
        "print(df_metrics.round(4))\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nH1 Test Set Classification Report:\")\n",
        "print(classification_report(y_h1_test, y_h1_pred))\n",
        "\n",
        "print(\"\\nH2 Test Set Classification Report:\")\n",
        "print(classification_report(y_h2_test, y_h2_pred))"
      ],
      "metadata": {
        "id": "t7jcwQ8mdZUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H2 test set"
      ],
      "metadata": {
        "id": "gSnoZtpiFGLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in test set"
      ],
      "metadata": {
        "id": "xYCTltEMCw4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE"
      ],
      "metadata": {
        "id": "5QK8isS4U_IL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7rQQIeBU_IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10"
      ],
      "metadata": {
        "id": "NveqTHUFU_IN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6zV1OTKU_IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10"
      ],
      "metadata": {
        "id": "6TiZ36PgU_IO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEYVVETBU_IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA"
      ],
      "metadata": {
        "id": "tDGGyZLoU_IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdxLns9NU_IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#H2"
      ],
      "metadata": {
        "id": "bRuXcw0podF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 1.Logistic Regression\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FIrA0XGV8134"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "3GTQdJMq77OI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### imbalanced data"
      ],
      "metadata": {
        "id": "xy4-DAPR8aD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# 使用 H2_train 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化数据（随机森林通常不需要标准化，但可以保留以一致性）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 可以调整n_estimators等超参数\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比，位于计数值的下方\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 绘制每个折的ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GKVMu8oqjOM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### handling imbalanced datasets"
      ],
      "metadata": {
        "id": "ZQsaxHO88f2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义采样方法，包括 \"未处理数据\"\n",
        "samplers = {\n",
        "    'No Sampling': None,  # 未处理数据\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 初始化结果存储\n",
        "metrics_data = []\n",
        "\n",
        "# 交叉验证设置\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 进行采样、训练和评估\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        # 未处理数据，直接使用原始数据\n",
        "        X_resampled, y_resampled = X_train_scaled, y_train\n",
        "    else:\n",
        "        # 应用采样方法\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    # 定义逻辑回归模型\n",
        "    log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "    # 执行交叉验证预测\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 计算混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    # 在单元格内显示百分比\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 将指标添加到结果\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 转换为 DataFrame 并显示汇总结果\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制汇总表格的条形图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CSKYaZ5UOgm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDe26oPwcL-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE效果最好"
      ],
      "metadata": {
        "id": "vM4KgRF6o75F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "j7WI0X_X79bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient"
      ],
      "metadata": {
        "id": "He6PJX5-o2Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1116"
      ],
      "metadata": {
        "id": "82jtrhT71u7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据提取重要特征\n",
        "log_reg_model_raw = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = log_reg_model_raw.coef_[0]\n",
        "features = X_train.columns  # 假设 X_train 的列名是特征名称\n",
        "coef_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
        "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
        "coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = coef_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2VDK453j1uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP"
      ],
      "metadata": {
        "id": "mBpCTKVJtUDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# 计算 SHAP 值\n",
        "explainer = shap.LinearExplainer(log_reg_model_smote, X_smote, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_smote)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_smote, feature_names=features, plot_type=\"bar\")\n"
      ],
      "metadata": {
        "id": "B6FV-VBAo1o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "\n",
        "# 计算 SHAP 值\n",
        "explainer = shap.LinearExplainer(log_reg_model_smote, X_smote, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_smote)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_smote, feature_names=features, plot_type=\"bar\")\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame([features, shap_sum]).T\n",
        "importance_df.columns = ['Feature', 'SHAP Importance']\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 特征\n",
        "X_train_top10_shap = X_train_scaled[:, X_train.columns.isin(top10_shap_features)]\n",
        "\n",
        "# 定义逻辑回归模型\n",
        "log_reg_model_top10_shap = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "# 3-fold 交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv_shap = cross_val_predict(log_reg_model_top10_shap, X_train_top10_shap, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_shap = cross_val_predict(log_reg_model_top10_shap, X_train_top10_shap, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix_shap = confusion_matrix(y_train, y_pred_cv_shap)\n",
        "conf_matrix_percentage_shap = conf_matrix_shap / conf_matrix_shap.sum(axis=1).reshape(-1, 1) * 100\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_shap, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_shap.shape[0]):\n",
        "    for j in range(conf_matrix_shap.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_shap[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (SHAP Logistic Regression)')\n",
        "plt.show()\n",
        "\n",
        "# 分类报告和 ROC 曲线\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv_shap))\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_top10_shap, y_train):\n",
        "    log_reg_model_top10_shap.fit(X_train_top10_shap[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold_shap = log_reg_model_top10_shap.predict_proba(X_train_top10_shap[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold_shap)\n",
        "    roc_auc_fold_shap = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold_shap)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold_shap:.2f})')\n",
        "    fold_count += 1\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (SHAP Logistic Regression, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lAQIacLnWr5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "PmxzRIt66sK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义初始逻辑回归模型并训练\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 使用 SHAP 计算特征重要性\n",
        "explainer = shap.LinearExplainer(log_reg_model, X_train_scaled, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP Importance': shap_sum})\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 SHAP 特征\n",
        "X_train_top10_shap = X_train[top10_shap_features]\n",
        "X_train_scaled_top10_shap = scaler.fit_transform(X_train_top10_shap)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 对每种采样方法的模型进行训练并评估\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top10_shap, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cyjQQb2d6yYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "x59kSFm_xJug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 假设 X_train_scaled 和 y_train 已经预处理完毕\n",
        "\n",
        "# 数据准备\n",
        "smote_sampler = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote_sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# 创建逻辑回归模型\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# 3折交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 保存各折ROC曲线数据\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "for train_idx, test_idx in cv.split(X_smote, y_smote):\n",
        "    X_train_fold, X_test_fold = X_smote[train_idx], X_smote[test_idx]\n",
        "    y_train_fold, y_test_fold = y_smote[train_idx], y_smote[test_idx]\n",
        "\n",
        "    log_reg.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_proba_fold = log_reg.predict_proba(X_test_fold)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test_fold, y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_test_fold, y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Logistic Regression, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 使用所有数据进行预测\n",
        "y_pred = cross_val_predict(log_reg, X_smote, y_smote, cv=cv, method=\"predict\")\n",
        "y_pred_proba = cross_val_predict(log_reg, X_smote, y_smote, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "# 混淆矩阵和百分比\n",
        "conf_matrix = confusion_matrix(y_smote, y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1)[:, None] * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# 在单元格内显示百分比\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Logistic Regression)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_smote, y_pred))\n"
      ],
      "metadata": {
        "id": "lzDFHs9w3s_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "YOGGxj--GC8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用 Boruta 进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 运行 Boruta\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_features = X_train.columns[boruta_selector.support_]\n",
        "print(\"\\nBoruta selected features:\")\n",
        "print(\"========================\")\n",
        "for feature in selected_features:\n",
        "    print(feature)\n",
        "print(\"\\nNumber of selected features:\", len(selected_features))\n",
        "\n",
        "# 使用 Boruta 选择的特征\n",
        "X_train_boruta = X_train[selected_features]\n",
        "X_train_scaled_boruta = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 对每种采样方法的模型进行训练并评估\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_boruta, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "\n",
        "    log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Boruta Selected Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "19NYKakpGG6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "W4GM-Sb57_XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "_JpPZHYlannK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义采样方法，包括 \"未处理数据\"\n",
        "samplers = {\n",
        "    'No Sampling': None,  # 未处理数据\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 初始化结果存储\n",
        "metrics_data = []\n",
        "\n",
        "# 交叉验证设置\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 定义目标函数用于超参数调优\n",
        "def objective(trial, X_resampled, y_resampled):\n",
        "    # 定义需要调优的超参数\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
        "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
        "\n",
        "    # 定义逻辑回归模型\n",
        "    log_reg_model = LogisticRegression(C=C, solver=solver, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用 F1 Score 作为目标函数\n",
        "    f1 = cross_val_score(log_reg_model, X_resampled, y_resampled, cv=cv, scoring=make_scorer(f1_score)).mean()\n",
        "    return f1\n",
        "\n",
        "# 进行采样、超参数调优、训练和评估\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        # 未处理数据，直接使用原始数据\n",
        "        X_resampled, y_resampled = X_train_scaled, y_train\n",
        "    else:\n",
        "        # 应用采样方法\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    # 使用 Optuna 进行超参数调优\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=50, timeout=600)\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # 打印每种方法的最佳参数\n",
        "    print(f\"Best parameters for {method}: {best_params}\")\n",
        "\n",
        "    # 使用最优超参数重新训练模型\n",
        "    log_reg_model_optimized = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 3-fold 交叉验证\n",
        "    y_pred_cv = cross_val_predict(log_reg_model_optimized, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model_optimized, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 将当前采样方法的指标存入列表\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 计算混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    # 在单元格内显示百分比\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# 转换为 DataFrame 并显示汇总结果\n",
        "metrics_df = pd.DataFrame(metrics_data).drop_duplicates().sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制汇总表格的条形图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods with Optimized Logistic Regression')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LMCa0iTzti6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBhxBwlwYQOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient 4"
      ],
      "metadata": {
        "id": "7a2rWAmxYXHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 提取 Top 10 特征（未处理数据）\n",
        "log_reg_model_raw = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = log_reg_model_raw.coef_[0]\n",
        "features = X_train.columns\n",
        "coef_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
        "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
        "coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False).head(10)\n",
        "\n",
        "top_features = coef_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 初始化交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 定义 Optuna 超参数调优函数\n",
        "def objective(trial, X, y):\n",
        "    param = {\n",
        "        'C': trial.suggest_loguniform('C', 1e-4, 10.0),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'lbfgs']),\n",
        "        'max_iter': 2000\n",
        "    }\n",
        "    model = LogisticRegression(**param, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(model, X, y, cv=cv, method='predict')\n",
        "    return f1_score(y, y_pred_cv, pos_label=1)\n",
        "\n",
        "# 记录每种平衡方法的最佳模型和指标\n",
        "metrics_data = []\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 使用 Optuna 调优超参数\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=30)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(f\"Best params for {method}: {best_params}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    best_model = LogisticRegression(**best_params, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    # 混淆矩阵可视化\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'Best Params': best_params\n",
        "    })\n",
        "\n",
        "# 转换为 DataFrame 并显示汇总结果\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制对比图表\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods with Optimized Logistic Regression')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aV11TygwYa-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP smote"
      ],
      "metadata": {
        "id": "pmahXnaGYbcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, make_scorer, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
        "import optuna\n",
        "\n",
        "# 计算 SHAP 值\n",
        "explainer = shap.LinearExplainer(log_reg_model_smote, X_smote, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_smote)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_smote, feature_names=features, plot_type=\"bar\")\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame([features, shap_sum]).T\n",
        "importance_df.columns = ['Feature', 'SHAP Importance']\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 特征\n",
        "X_train_top10_shap = X_train_scaled[:, X_train.columns.isin(top10_shap_features)]\n",
        "\n",
        "# 定义目标函数进行超参数调优\n",
        "def objective(trial):\n",
        "    # 定义需要调优的超参数\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e2)  # 正则化强度\n",
        "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
        "\n",
        "    # 定义逻辑回归模型\n",
        "    log_reg_model = LogisticRegression(C=C, solver=solver, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用 F1 Score 作为目标函数\n",
        "    f1 = cross_val_score(log_reg_model, X_train_top10_shap, y_train, cv=3, scoring=make_scorer(f1_score)).mean()\n",
        "    return f1\n",
        "\n",
        "# 使用 Optuna 进行调优\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "# 输出最优超参数\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Value: {study.best_value}\")\n",
        "print(f\"  Params: {study.best_params}\")\n",
        "\n",
        "# 使用最优超参数重新训练模型\n",
        "best_params = study.best_params\n",
        "log_reg_model_optimized = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "# 3-fold 交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv_optimized = cross_val_predict(log_reg_model_optimized, X_train_top10_shap, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_optimized = cross_val_predict(log_reg_model_optimized, X_train_top10_shap, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix_optimized = confusion_matrix(y_train, y_pred_cv_optimized)\n",
        "conf_matrix_percentage_optimized = conf_matrix_optimized / conf_matrix_optimized.sum(axis=1).reshape(-1, 1) * 100\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_optimized, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_optimized.shape[0]):\n",
        "    for j in range(conf_matrix_optimized.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_optimized[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (Optimized Logistic Regression)')\n",
        "plt.show()\n",
        "\n",
        "# 分类报告和 ROC 曲线\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv_optimized))\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_top10_shap, y_train):\n",
        "    log_reg_model_optimized.fit(X_train_top10_shap[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold_optimized = log_reg_model_optimized.predict_proba(X_train_top10_shap[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold_optimized)\n",
        "    roc_auc_fold_optimized = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold_optimized)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold_optimized:.2f})')\n",
        "    fold_count += 1\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Optimized Logistic Regression, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qK_iahNAYeFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap 1117"
      ],
      "metadata": {
        "id": "9eUkgn8W7JPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 定义目标函数，用于Optuna超参数调优\n",
        "def objective(trial, X_train, y_train):\n",
        "    # 定义需要调优的超参数\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
        "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
        "    penalty = trial.suggest_categorical('penalty', ['l2', 'none'] if solver == 'lbfgs' else ['l1', 'l2'])\n",
        "\n",
        "    # 创建逻辑回归模型\n",
        "    model = LogisticRegression(C=C, solver=solver, penalty=penalty, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用交叉验证评估模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv, method='predict')\n",
        "    return f1_score(y_train, y_pred_cv, pos_label=1)\n",
        "\n",
        "# 用于存储最终的评估结果\n",
        "metrics_data = []\n",
        "\n",
        "# 循环四种采样方法并应用调优\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top10_shap, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    # 使用Optuna进行超参数调优\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=30)  # 设置搜索次数为30\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "    log_reg_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 使用交叉验证进行预测\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 混淆矩阵绘制\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report for {method}:\")\n",
        "    print(classification_report(y_resampled, y_pred_cv))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 保存评估结果\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best Params': best_params,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 转换为DataFrame并排序\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制结果对比条形图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods with Optuna (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N7B_FmGz7JxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, X_train, y_train):\n",
        "    # 定义需要调优的超参数\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
        "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'none'])\n",
        "\n",
        "    # 跳过不支持的组合\n",
        "    if solver == 'lbfgs' and penalty == 'l1':\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # 创建逻辑回归模型\n",
        "    model = LogisticRegression(C=C, solver=solver, penalty=penalty, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用交叉验证评估模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv, method='predict')\n",
        "    return f1_score(y_train, y_pred_cv, pos_label=1)\n"
      ],
      "metadata": {
        "id": "ngeh1Jt98MZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义初始逻辑回归模型并训练\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 使用 SHAP 计算特征重要性\n",
        "explainer = shap.LinearExplainer(log_reg_model, X_train_scaled, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP Importance': shap_sum})\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 SHAP 特征\n",
        "X_train_top10_shap = X_train[top10_shap_features]\n",
        "X_train_scaled_top10_shap = scaler.fit_transform(X_train_top10_shap)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 定义目标函数，用于 Optuna 超参数调优\n",
        "def objective(trial, X_train, y_train):\n",
        "    # 定义需要调优的超参数\n",
        "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
        "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'none'])\n",
        "\n",
        "    # 跳过不支持的组合\n",
        "    if solver == 'lbfgs' and penalty == 'l1':\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    # 创建逻辑回归模型\n",
        "    model = LogisticRegression(C=C, solver=solver, penalty=penalty, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用交叉验证评估模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv, method='predict')\n",
        "    return f1_score(y_train, y_pred_cv, pos_label=1)\n",
        "\n",
        "# 用于存储最终的评估结果\n",
        "metrics_data = []\n",
        "\n",
        "# 循环四种采样方法并应用调优\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top10_shap, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    # 使用 Optuna 进行超参数调优\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=30)  # 设置搜索次数为30\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "    log_reg_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 使用交叉验证进行预测\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 混淆矩阵绘制\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report for {method}:\")\n",
        "    print(classification_report(y_resampled, y_pred_cv))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 保存评估结果\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best Params': best_params,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 转换为 DataFrame 并排序\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制结果对比条形图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods with Optuna (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MRg0AzzP8gJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial, X, y, sampler_type=None):\n",
        "    # Define hyperparameters to optimize\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-5, 100, log=True),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42,\n",
        "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'newton-cg', 'sag'])\n",
        "    }\n",
        "\n",
        "    # Apply sampling if specified\n",
        "    if sampler_type == 'Undersample':\n",
        "        sampler = RandomUnderSampler(random_state=42)\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    elif sampler_type == 'Oversample':\n",
        "        sampler = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    elif sampler_type == 'SMOTE':\n",
        "        k_neighbors = trial.suggest_int('k_neighbors', 2, 10)\n",
        "        sampler = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    # Create and evaluate model using cross-validation\n",
        "    model = LogisticRegression(**params)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_resampled, y_resampled):\n",
        "        X_train_fold, X_val_fold = X_resampled[train_idx], X_resampled[val_idx]\n",
        "        y_train_fold, y_val_fold = y_resampled[train_idx], y_resampled[val_idx]\n",
        "\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        y_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "def optimize_and_evaluate(X_train, y_train, sampler_type=None, n_trials=100):\n",
        "    \"\"\"Optimize model for a specific sampling method and evaluate results\"\"\"\n",
        "    # Create study\n",
        "    study = optuna.create_study(direction='maximize', study_name=f'{sampler_type}_optimization')\n",
        "\n",
        "    # Optimize\n",
        "    study.optimize(lambda trial: objective(trial, X_train, y_train, sampler_type), n_trials=n_trials)\n",
        "\n",
        "    # Get best parameters\n",
        "    best_params = study.best_params\n",
        "    best_params.update({'max_iter': 2000, 'random_state': 42})\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    if sampler_type == 'Undersample':\n",
        "        sampler = RandomUnderSampler(random_state=42)\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    elif sampler_type == 'Oversample':\n",
        "        sampler = RandomOverSampler(random_state=42)\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    elif sampler_type == 'SMOTE':\n",
        "        sampler = SMOTE(random_state=42, k_neighbors=best_params.get('k_neighbors', 5))\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X_train, y_train\n",
        "\n",
        "    model = LogisticRegression(**best_params)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'Balancing Method': sampler_type if sampler_type else 'No Sampling',\n",
        "        'Best Parameters': best_params,\n",
        "        'Best Score': study.best_value,\n",
        "        'Accuracy': accuracy_score(y_resampled, y_pred_cv),\n",
        "        'Precision': precision_score(y_resampled, y_pred_cv),\n",
        "        'Recall': recall_score(y_resampled, y_pred_cv),\n",
        "        'F1 Score': f1_score(y_resampled, y_pred_cv),\n",
        "        'ROC AUC': roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "    }\n",
        "\n",
        "    return metrics, y_pred_cv, y_pred_proba_cv, y_resampled\n",
        "\n",
        "# Main execution code\n",
        "def run_optimization(X_train, y_train, n_trials=100):\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Calculate SHAP values for feature selection\n",
        "    base_model = LogisticRegression(random_state=42)\n",
        "    base_model.fit(X_train_scaled, y_train)\n",
        "    explainer = shap.LinearExplainer(base_model, X_train_scaled)\n",
        "    shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "    # Get top 10 features\n",
        "    shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "    importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP Importance': shap_sum})\n",
        "    importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "    top10_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "    # Select top 10 features and scale\n",
        "    X_train_top10 = X_train[top10_features]\n",
        "    X_train_scaled_top10 = scaler.fit_transform(X_train_top10)\n",
        "\n",
        "    # Run optimization for each sampling method\n",
        "    sampling_methods = [None, 'Undersample', 'Oversample', 'SMOTE']\n",
        "    results = []\n",
        "\n",
        "    for method in sampling_methods:\n",
        "        print(f\"\\nOptimizing for {method if method else 'No Sampling'}...\")\n",
        "        metrics, y_pred, y_pred_proba, y_resampled = optimize_and_evaluate(\n",
        "            X_train_scaled_top10, y_train, method, n_trials\n",
        "        )\n",
        "        results.append(metrics)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "                plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green')\n",
        "        plt.title(f'Confusion Matrix ({method if method else \"No Sampling\"})')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'ROC (AUC = {metrics[\"ROC AUC\"]:.3f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve ({method if method else \"No Sampling\"})')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # Create and display results DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nOptimization Results:\")\n",
        "    print(results_df[['Balancing Method', 'Best Score', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']])\n",
        "\n",
        "    # Plot comparison of metrics\n",
        "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "    results_df.set_index('Balancing Method')[metrics_to_plot].plot(kind='bar', figsize=(12, 6))\n",
        "    plt.title('Comparison of Optimized Models')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Usage example:\n",
        "# Assuming X_train and y_train are your feature matrix and target vector\n",
        "# results = run_optimization(X_train, y_train, n_trials=100)"
      ],
      "metadata": {
        "id": "5gqU5Wx386Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 使用原始数据\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义初始逻辑回归模型并训练\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 使用 SHAP 计算特征重要性\n",
        "explainer = shap.LinearExplainer(log_reg_model, X_train_scaled, feature_perturbation=\"interventional\")\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train.columns, plot_type=\"bar\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP Importance': shap_sum})\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 SHAP 特征\n",
        "X_train_top10_shap = X_train[top10_shap_features]\n",
        "X_train_scaled_top10_shap = scaler.fit_transform(X_train_top10_shap)\n",
        "\n",
        "# 定义Optuna优化目标函数\n",
        "def objective(trial, X, y, sampler=None):\n",
        "    # 定义要优化的超参数\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-5, 100, log=True),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
        "        'solver': 'lbfgs',\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    # 应用采样方法\n",
        "    if sampler is not None:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    # 使用交叉验证评估模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    model = LogisticRegression(**params)\n",
        "    y_pred_proba = cross_val_predict(model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "    score = roc_auc_score(y_resampled, y_pred_proba)\n",
        "\n",
        "    return score\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 存储优化结果\n",
        "metrics_data = []\n",
        "\n",
        "# 对每种采样方法进行优化和评估\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "\n",
        "    # 创建Optuna study\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_scaled_top10_shap, y_train, sampler),\n",
        "                  n_trials=50)\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    best_params = study.best_params\n",
        "    best_params.update({'solver': 'lbfgs', 'max_iter': 2000, 'random_state': 42})\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top10_shap, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    # 使用最佳参数的模型进行预测\n",
        "    log_reg_model = LogisticRegression(**best_params)\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 打印最佳参数和分类报告\n",
        "    print(f\"\\nBest parameters: {best_params}\")\n",
        "    print(f\"Best ROC AUC score: {study.best_value:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_resampled, y_pred_cv))\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 存储评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best Parameters': best_params,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建并显示评估指标DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制评估指标比较图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(\n",
        "    kind='bar',\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "plt.title('Comparison of Optimized Balancing Methods (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印每个方法的最佳参数\n",
        "print(\"\\nBest Parameters for Each Method:\")\n",
        "for metric in metrics_data:\n",
        "    print(f\"\\n{metric['Balancing Method']}:\")\n",
        "    print(f\"Parameters: {metric['Best Parameters']}\")"
      ],
      "metadata": {
        "id": "MGf3--Ws9gaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta 4"
      ],
      "metadata": {
        "id": "8OnZNhwNYecg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用 Boruta 进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 运行 Boruta\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_features = X_train.columns[boruta_selector.support_]\n",
        "print(\"\\nBoruta selected features:\")\n",
        "print(\"========================\")\n",
        "for feature in selected_features:\n",
        "    print(feature)\n",
        "print(\"\\nNumber of selected features:\", len(selected_features))\n",
        "\n",
        "# 使用 Boruta 选择的特征\n",
        "X_train_boruta = X_train[selected_features]\n",
        "X_train_scaled_boruta = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 设置提前停止回调\n",
        "class OptunaCallback:\n",
        "    def __init__(self, early_stopping_rounds, early_stopping_value):\n",
        "        self.early_stopping_rounds = early_stopping_rounds\n",
        "        self.early_stopping_value = early_stopping_value\n",
        "        self.best_score = None\n",
        "        self.no_improvement_count = 0\n",
        "\n",
        "    def __call__(self, study, trial):\n",
        "        current_score = trial.value\n",
        "        if self.best_score is None or current_score > self.best_score:\n",
        "            self.best_score = current_score\n",
        "            self.no_improvement_count = 0\n",
        "        else:\n",
        "            self.no_improvement_count += 1\n",
        "\n",
        "        if self.best_score >= self.early_stopping_value:\n",
        "            study.stop()\n",
        "\n",
        "        if self.no_improvement_count >= self.early_stopping_rounds:\n",
        "            study.stop()\n",
        "\n",
        "def objective(trial, X, y, sampler=None):\n",
        "    # 定义更保守的超参数搜索空间\n",
        "    params = {\n",
        "        'C': trial.suggest_loguniform('C', 1e-3, 1e3),  # 缩小范围\n",
        "        'max_iter': trial.suggest_int('max_iter', 500, 1000),  # 增加最小迭代次数\n",
        "        'tol': trial.suggest_loguniform('tol', 1e-4, 1e-2),  # 放宽收敛容差\n",
        "    }\n",
        "\n",
        "    # 重采样（如果需要）\n",
        "    if sampler is not None:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    # 创建模型\n",
        "    model = LogisticRegression(\n",
        "        penalty='l2',  # 使用更稳定的L2正则化\n",
        "        solver='lbfgs',  # 使用更稳定的求解器\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # 使用3折交叉验证评估模型\n",
        "        scores = cross_val_score(\n",
        "            model,\n",
        "            X_resampled,\n",
        "            y_resampled,\n",
        "            cv=3,\n",
        "            scoring='roc_auc'\n",
        "        )\n",
        "        return scores.mean()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in trial: {str(e)}\")\n",
        "        return float('-inf')  # 返回一个很差的分数\n",
        "\n",
        "# 为每种采样方法优化超参数\n",
        "best_params = {}\n",
        "best_scores = {}\n",
        "n_trials = 30  # 减少试验次数\n",
        "\n",
        "# 设置早停回调\n",
        "early_stopping_callback = OptunaCallback(\n",
        "    early_stopping_rounds=10,  # 10轮内没有改善就停止\n",
        "    early_stopping_value=0.95  # 达到0.95的AUC就停止\n",
        ")\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\nOptimizing for {method}\")\n",
        "\n",
        "    # 设置更严格的时间限制\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    try:\n",
        "        study.optimize(\n",
        "            lambda trial: objective(trial, X_train_scaled_boruta, y_train, sampler),\n",
        "            n_trials=n_trials,\n",
        "            timeout=300,  # 5分钟超时\n",
        "            callbacks=[early_stopping_callback]\n",
        "        )\n",
        "\n",
        "        best_params[method] = study.best_params\n",
        "        best_scores[method] = study.best_value\n",
        "\n",
        "        print(f\"Best parameters for {method}:\")\n",
        "        print(study.best_params)\n",
        "        print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "        # 绘制优化历史\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        optuna.visualization.matplotlib.plot_optimization_history(study)\n",
        "        plt.title(f'Optimization History for {method}')\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed for {method}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# 使用优化后的参数进行最终评估\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    if method not in best_params:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n=== {method} with optimized parameters ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_boruta, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "\n",
        "    # 使用优化后的参数创建模型\n",
        "    optimized_params = best_params[method]\n",
        "    log_reg_model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        solver='lbfgs',\n",
        "        random_state=42,\n",
        "        **optimized_params\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "        y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "        # 计算评估指标\n",
        "        accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "        precision = precision_score(y_resampled, y_pred_cv)\n",
        "        recall = recall_score(y_resampled, y_pred_cv)\n",
        "        f1 = f1_score(y_resampled, y_pred_cv)\n",
        "        roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "        metrics_data.append({\n",
        "            'Balancing Method': method,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1,\n",
        "            'ROC AUC': roc_auc\n",
        "        })\n",
        "\n",
        "        # 绘制混淆矩阵\n",
        "        conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title(f'Confusion Matrix - {method}')\n",
        "        plt.show()\n",
        "\n",
        "        # 绘制ROC曲线\n",
        "        fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve - {method}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation failed for {method}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# 展示最终结果\n",
        "if metrics_data:\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    print(\"\\nFinal Results:\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    # 保存结果\n",
        "    metrics_df.to_csv('optimization_results.csv', index=False)\n",
        "    pd.DataFrame.from_dict(best_params, orient='index').to_csv('best_params.csv')"
      ],
      "metadata": {
        "id": "lBukxD-XNg_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous imports and setup remain the same...\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    if method not in best_params:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n=== {method} with optimized parameters ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_boruta, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "\n",
        "    # 使用优化后的参数创建模型\n",
        "    optimized_params = best_params[method]\n",
        "    log_reg_model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        solver='lbfgs',\n",
        "        random_state=42,\n",
        "        **optimized_params\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        y_pred_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "        y_pred_proba_cv = cross_val_predict(log_reg_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "        # 计算评估指标\n",
        "        accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "        precision = precision_score(y_resampled, y_pred_cv)\n",
        "        recall = recall_score(y_resampled, y_pred_cv)\n",
        "        f1 = f1_score(y_resampled, y_pred_cv)\n",
        "        roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "        # 绘制增强版混淆矩阵\n",
        "        conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "        # 添加百分比标注\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "                plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.title(f'Confusion Matrix with Counts and Percentages ({method})')\n",
        "        plt.show()\n",
        "\n",
        "        # 绘制增强版ROC曲线\n",
        "        fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve ({method})')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "        # 存储详细评估指标\n",
        "        metrics_data.append({\n",
        "            'Balancing Method': method,\n",
        "            'Best Parameters': best_params[method],\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1,\n",
        "            'ROC AUC': roc_auc\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation failed for {method}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# 创建并显示评估指标DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制评估指标比较图\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(\n",
        "    kind='bar',\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "plt.title('Comparison of Optimized Balancing Methods')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印每个方法的最佳参数\n",
        "print(\"\\nBest Parameters for Each Method:\")\n",
        "for metric in metrics_data:\n",
        "    print(f\"\\n{metric['Balancing Method']}:\")\n",
        "    print(f\"Parameters: {metric['Best Parameters']}\")\n",
        "\n",
        "# 保存结果\n",
        "metrics_df.to_csv('optimization_results.csv', index=False)\n",
        "pd.DataFrame.from_dict(best_params, orient='index').to_csv('best_params.csv')"
      ],
      "metadata": {
        "id": "YR04G9olPIdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgnyG2yXVUPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "3EyOuuNrI3u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline 4"
      ],
      "metadata": {
        "id": "cBIR8lMSv3aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 重新定义标准化器\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 将 H2_test 数据标准化\n",
        "H2_test_scaled = scaler.transform(H2_test[selected_columns].drop(columns=['is_canceled']))\n",
        "y_test = H2_test['is_canceled']\n",
        "\n",
        "# 初始化结果存储\n",
        "test_results = []\n",
        "\n",
        "# 对四种采样方法的最佳参数进行测试\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== Testing {method} on H2 Test Set ===\")\n",
        "\n",
        "    # 获取之前计算的最佳参数\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_scaled, y_train), n_trials=1)  # 仅获取最佳参数\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # 使用最佳参数重新定义模型\n",
        "    log_reg_model_optimized = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用 H2_test 数据进行预测\n",
        "    log_reg_model_optimized.fit(X_train_scaled, y_train)\n",
        "    y_test_pred = log_reg_model_optimized.predict(H2_test_scaled)\n",
        "    y_test_pred_proba = log_reg_model_optimized.predict_proba(H2_test_scaled)[:, 1]\n",
        "\n",
        "    # 计算测试指标\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_test_pred, pos_label=1)\n",
        "    f1 = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "    # 保存测试结果\n",
        "    test_results.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report for {method}:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # 绘制 ROC 曲线\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method}) on H2 Test Set')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# 将测试结果转换为 DataFrame 并显示\n",
        "test_results_df = pd.DataFrame(test_results).sort_values(by='ROC AUC', ascending=False)\n",
        "print(test_results_df)\n",
        "\n",
        "# 绘制测试结果对比条形图\n",
        "test_results_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods on H2 Test Set')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DZKRIyCPv6cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top10 feature importance 4"
      ],
      "metadata": {
        "id": "QNkzRvcQwMWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 记录每种平衡方法的最佳模型和指标\n",
        "metrics_data = []\n",
        "test_metrics_data = []\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 使用 Optuna 调优超参数\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=30)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(f\"Best params for {method}: {best_params}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    best_model = LogisticRegression(**best_params, random_state=42)\n",
        "    best_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 训练集预测\n",
        "    y_train_pred = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_train_pred_proba = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 测试集预测\n",
        "    y_test_pred = best_model.predict(X_test_scaled_top)\n",
        "    y_test_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "\n",
        "    # 计算训练集的指标\n",
        "    accuracy_train = accuracy_score(y_resampled, y_train_pred)\n",
        "    precision_train = precision_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    recall_train = recall_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    f1_train = f1_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    roc_auc_train = roc_auc_score(y_resampled, y_train_pred_proba)\n",
        "\n",
        "    # 计算测试集的指标\n",
        "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "    precision_test = precision_score(y_test, y_test_pred, pos_label=1)\n",
        "    recall_test = recall_score(y_test, y_test_pred, pos_label=1)\n",
        "    f1_test = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "    roc_auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "    # 保存训练集和测试集结果\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Train Accuracy': accuracy_train,\n",
        "        'Train Precision': precision_train,\n",
        "        'Train Recall': recall_train,\n",
        "        'Train F1': f1_train,\n",
        "        'Train ROC AUC': roc_auc_train\n",
        "    })\n",
        "    test_metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Test Accuracy': accuracy_test,\n",
        "        'Test Precision': precision_test,\n",
        "        'Test Recall': recall_test,\n",
        "        'Test F1': f1_test,\n",
        "        'Test ROC AUC': roc_auc_test\n",
        "    })\n",
        "\n",
        "# 转换为 DataFrame 并显示\n",
        "train_metrics_df = pd.DataFrame(metrics_data)\n",
        "test_metrics_df = pd.DataFrame(test_metrics_data)\n",
        "\n",
        "print(\"Train Metrics:\")\n",
        "print(train_metrics_df)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(test_metrics_df)\n",
        "\n",
        "# 绘制测试集对比图\n",
        "test_metrics_df.set_index('Balancing Method')[['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test ROC AUC']].plot(kind='bar', figsize=(12, 8))\n",
        "plt.title('Comparison of Balancing Methods on H2_test')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KVg-919iEomb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient 4 test set& H1 test set"
      ],
      "metadata": {
        "id": "URseBMUuMsK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义字典保存每种平衡方法的最佳参数\n",
        "best_params_dict = {}\n",
        "\n",
        "# 调优和保存最佳参数\n",
        "metrics_data = []\n",
        "test_metrics_data = []\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 使用 Optuna 调优超参数\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled), n_trials=30)\n",
        "\n",
        "    # 保存最佳参数到字典\n",
        "    best_params = study.best_params\n",
        "    best_params_dict[method] = best_params  # 将最佳参数存储到字典中\n",
        "    print(f\"Best params for {method}: {best_params}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    best_model = LogisticRegression(**best_params, random_state=42)\n",
        "    best_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 训练集预测\n",
        "    y_train_pred = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_train_pred_proba = cross_val_predict(best_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 测试集预测\n",
        "    y_test_pred = best_model.predict(X_test_scaled_top)\n",
        "    y_test_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "\n",
        "    # 计算训练集的指标\n",
        "    accuracy_train = accuracy_score(y_resampled, y_train_pred)\n",
        "    precision_train = precision_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    recall_train = recall_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    f1_train = f1_score(y_resampled, y_train_pred, pos_label=1)\n",
        "    roc_auc_train = roc_auc_score(y_resampled, y_train_pred_proba)\n",
        "\n",
        "    # 计算测试集的指标\n",
        "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "    precision_test = precision_score(y_test, y_test_pred, pos_label=1)\n",
        "    recall_test = recall_score(y_test, y_test_pred, pos_label=1)\n",
        "    f1_test = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "    roc_auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "    # 保存训练集和测试集结果\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Train Accuracy': accuracy_train,\n",
        "        'Train Precision': precision_train,\n",
        "        'Train Recall': recall_train,\n",
        "        'Train F1': f1_train,\n",
        "        'Train ROC AUC': roc_auc_train\n",
        "    })\n",
        "    test_metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Test Accuracy': accuracy_test,\n",
        "        'Test Precision': precision_test,\n",
        "        'Test Recall': recall_test,\n",
        "        'Test F1': f1_test,\n",
        "        'Test ROC AUC': roc_auc_test\n",
        "    })\n",
        "\n",
        "# 转换为 DataFrame 并显示\n",
        "train_metrics_df = pd.DataFrame(metrics_data)\n",
        "test_metrics_df = pd.DataFrame(test_metrics_data)\n",
        "\n",
        "print(\"Train Metrics:\")\n",
        "print(train_metrics_df)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(test_metrics_df)\n",
        "\n",
        "# 测试集对比图\n",
        "test_metrics_df.set_index('Balancing Method')[['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test ROC AUC']].plot(kind='bar', figsize=(12, 8))\n",
        "plt.title('Comparison of Balancing Methods on H2_test')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ======================\n",
        "# 在 H1_test 上进行测试\n",
        "# ======================\n",
        "\n",
        "# 假设 H1_train 和 H1_test 已定义\n",
        "X_train_h1 = H1_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train_h1 = H1_train['is_canceled']\n",
        "X_test_h1 = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test_h1 = H1_test['is_canceled']\n",
        "\n",
        "# 标准化 H1 数据\n",
        "X_train_h1_scaled = scaler.fit_transform(X_train_h1)\n",
        "X_test_h1_scaled = scaler.transform(X_test_h1)\n",
        "\n",
        "# 使用最佳参数在 H1_test 上测试\n",
        "test_metrics_data_h1 = []\n",
        "\n",
        "for method, params in best_params_dict.items():  # 从保存的字典加载最佳参数\n",
        "    print(f\"=== Testing {method} Model on H1_test ===\")\n",
        "\n",
        "    # 初始化模型并在 H1_train 上训练\n",
        "    best_model = LogisticRegression(**params, random_state=42)\n",
        "    best_model.fit(X_train_h1_scaled, y_train_h1)  # 在 H1_train 上拟合\n",
        "\n",
        "    # 在 H1_test 上预测\n",
        "    y_test_pred_h1 = best_model.predict(X_test_h1_scaled)\n",
        "    y_test_pred_proba_h1 = best_model.predict_proba(X_test_h1_scaled)[:, 1]\n",
        "\n",
        "    # 计算 H1_test 上的指标\n",
        "    accuracy_test_h1 = accuracy_score(y_test_h1, y_test_pred_h1)\n",
        "    precision_test_h1 = precision_score(y_test_h1, y_test_pred_h1, pos_label=1)\n",
        "    recall_test_h1 = recall_score(y_test_h1, y_test_pred_h1, pos_label=1)\n",
        "    f1_test_h1 = f1_score(y_test_h1, y_test_pred_h1, pos_label=1)\n",
        "    roc_auc_test_h1 = roc_auc_score(y_test_h1, y_test_pred_proba_h1)\n",
        "\n",
        "    # 保存 H1_test 的测试结果\n",
        "    test_metrics_data_h1.append({\n",
        "        'Balancing Method': method,\n",
        "        'Test Accuracy': accuracy_test_h1,\n",
        "        'Test Precision': precision_test_h1,\n",
        "        'Test Recall': recall_test_h1,\n",
        "        'Test F1': f1_test_h1,\n",
        "        'Test ROC AUC': roc_auc_test_h1\n",
        "    })\n",
        "\n",
        "# 打印并显示 H1_test 的测试结果\n",
        "test_metrics_df_h1 = pd.DataFrame(test_metrics_data_h1).sort_values(by='Test ROC AUC', ascending=False)\n",
        "print(\"\\nH1 Test Metrics:\")\n",
        "print(test_metrics_df_h1)\n",
        "\n",
        "# 绘制 H1_test 对比图\n",
        "test_metrics_df_h1.set_index('Balancing Method')[['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test ROC AUC']].plot(kind='bar', figsize=(12, 8))\n",
        "plt.title('Comparison of Balancing Methods on H1_test')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eKMzdZA7G1yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap4"
      ],
      "metadata": {
        "id": "pnStMDfKAZJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# 准备测试数据\n",
        "X_test = H2_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = H2_test['is_canceled']\n",
        "\n",
        "# 提取top10特征的测试数据\n",
        "X_test_top10 = X_test[top10_shap_features]\n",
        "X_test_scaled_top10 = scaler.transform(X_test_top10)\n",
        "\n",
        "# 存储测试集评估结果\n",
        "test_metrics_data = []\n",
        "\n",
        "# 对每个优化后的模型进行测试集评估\n",
        "for metric in metrics_data:\n",
        "    method = metric['Balancing Method']\n",
        "    best_params = metric['Best Parameters']\n",
        "    print(f\"\\n=== Testing {method} ===\")\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(**best_params)\n",
        "\n",
        "    # 根据不同的采样方法处理训练数据\n",
        "    if method == 'No Sampling':\n",
        "        X_train_final, y_train_final = X_train_scaled_top10_shap, y_train\n",
        "    elif method == 'Undersample':\n",
        "        sampler = RandomUnderSampler(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "    elif method == 'Oversample':\n",
        "        sampler = RandomOverSampler(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "    else:  # SMOTE\n",
        "        sampler = SMOTE(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    # 训练模型\n",
        "    log_reg_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "    # 在测试集上进行预测\n",
        "    y_pred = log_reg_model.predict(X_test_scaled_top10)\n",
        "    y_pred_proba = log_reg_model.predict_proba(X_test_scaled_top10)[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Test Set Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Test Set ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 存储评估指标\n",
        "    test_metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best Parameters': best_params,\n",
        "        'Test Accuracy': accuracy,\n",
        "        'Test Precision': precision,\n",
        "        'Test Recall': recall,\n",
        "        'Test F1 Score': f1,\n",
        "        'Test ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建并显示测试集评估指标DataFrame\n",
        "test_metrics_df = pd.DataFrame(test_metrics_data).sort_values(by='Test ROC AUC', ascending=False)\n",
        "print(\"\\nTest Set Results:\")\n",
        "print(test_metrics_df)\n",
        "\n",
        "# 绘制测试集评估指标比较图\n",
        "test_metrics_df.set_index('Balancing Method')[['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1 Score', 'Test ROC AUC']].plot(\n",
        "    kind='bar',\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "plt.title('Comparison of Optimized Models on Test Set (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印训练集和测试集的对比\n",
        "comparison_data = []\n",
        "for train_metric, test_metric in zip(metrics_data, test_metrics_data):\n",
        "    method = train_metric['Balancing Method']\n",
        "    comparison_data.append({\n",
        "        'Method': method,\n",
        "        'Train AUC': train_metric['ROC AUC'],\n",
        "        'Test AUC': test_metric['Test ROC AUC'],\n",
        "        'AUC Difference': train_metric['ROC AUC'] - test_metric['Test ROC AUC'],\n",
        "        'Train F1': train_metric['F1 Score'],\n",
        "        'Test F1': test_metric['Test F1 Score'],\n",
        "        'F1 Difference': train_metric['F1 Score'] - test_metric['Test F1 Score']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nTrain vs Test Performance Comparison:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# 绘制训练集vs测试集性能对比图\n",
        "plt.figure(figsize=(12, 6))\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, comparison_df['Train AUC'], width, label='Train AUC')\n",
        "plt.bar(x + width/2, comparison_df['Test AUC'], width, label='Test AUC')\n",
        "\n",
        "plt.xlabel('Balancing Method')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.title('Train vs Test ROC AUC Comparison')\n",
        "plt.xticks(x, comparison_df['Method'], rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fCDwshohAbpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta 4 types (there is a complete comparison version of H2 test set and H1 test set in the cross dataset section)"
      ],
      "metadata": {
        "id": "yTx6F4ocH638"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boruta 筛选后的特征\n",
        "X_train_boruta = X_train[selected_features]\n",
        "X_train_scaled_boruta = scaler.fit_transform(X_train_boruta)\n",
        "\n",
        "# 测试集的 Boruta 筛选特征\n",
        "X_test_boruta = H2_test[selected_features]\n",
        "X_test_scaled_boruta = scaler.transform(X_test_boruta)\n",
        "y_test = H2_test[\"is_canceled\"]\n",
        "\n",
        "# 定义最佳参数\n",
        "best_params = {\n",
        "    \"No Sampling\": {\"C\": 0.3417502706151835, \"max_iter\": 573, \"tol\": 0.00229469424632226},\n",
        "    \"Undersample\": {\"C\": 0.0031211003628310603, \"max_iter\": 552, \"tol\": 0.0004304546227332599},\n",
        "    \"Oversample\": {\"C\": 150.3689576094797, \"max_iter\": 759, \"tol\": 0.0003455003585976619},\n",
        "    \"SMOTE\": {\"C\": 1.4183467727092938, \"max_iter\": 655, \"tol\": 0.00017510842206403264},\n",
        "}\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    \"No Sampling\": None,\n",
        "    \"Undersample\": RandomUnderSampler(random_state=42),\n",
        "    \"Oversample\": RandomOverSampler(random_state=42),\n",
        "    \"SMOTE\": SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 使用测试集评估并记录结果\n",
        "final_metrics_data = []\n",
        "\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} Final Testing with Optimized Parameters ===\")\n",
        "\n",
        "    # 获取最佳参数\n",
        "    optimized_params = best_params[method]\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_boruta, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(\n",
        "        solver=\"lbfgs\",\n",
        "        random_state=42,\n",
        "        **optimized_params\n",
        "    )\n",
        "\n",
        "    # 训练模型\n",
        "    log_reg_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 在测试集上进行预测\n",
        "    y_pred_test = log_reg_model.predict(X_test_scaled_boruta)\n",
        "    y_pred_proba_test = log_reg_model.predict_proba(X_test_scaled_boruta)[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    precision = precision_score(y_test, y_pred_test)\n",
        "    recall = recall_score(y_test, y_pred_test)\n",
        "    f1 = f1_score(y_test, y_pred_test)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "\n",
        "    # 保存结果\n",
        "    final_metrics_data.append({\n",
        "        \"Balancing Method\": method,\n",
        "        \"Test Accuracy\": accuracy,\n",
        "        \"Test Precision\": precision,\n",
        "        \"Test Recall\": recall,\n",
        "        \"Test F1 Score\": f1,\n",
        "        \"Test ROC AUC\": roc_auc\n",
        "    })\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 14})\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(f\"Confusion Matrix ({method})\")\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制 ROC 曲线\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"{method} (AUC = {roc_auc:.2f})\")\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC Curve ({method})\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# 生成最终测试结果 DataFrame\n",
        "final_metrics_df = pd.DataFrame(final_metrics_data).sort_values(by=\"Test ROC AUC\", ascending=False)\n",
        "print(\"\\nFinal Test Results:\")\n",
        "print(final_metrics_df)\n",
        "\n",
        "# 保存评估结果\n",
        "final_metrics_df.to_csv(\"final_test_results_boruta.csv\", index=False)\n",
        "\n",
        "# 绘制评估对比图\n",
        "final_metrics_df.set_index(\"Balancing Method\")[[\"Test Accuracy\", \"Test Precision\", \"Test Recall\", \"Test F1 Score\", \"Test ROC AUC\"]].plot(\n",
        "    kind=\"bar\", figsize=(10, 6)\n",
        ")\n",
        "plt.title(\"Comparison of Balancing Methods (Boruta Selected Features)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xQxQPde8VadM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H1 test set"
      ],
      "metadata": {
        "id": "l7mUag748Jix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline 4"
      ],
      "metadata": {
        "id": "M3z_ONHVFQVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 重新定义标准化器\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 将 H1_test 数据标准化\n",
        "H1_test_scaled = scaler.transform(H1_test[selected_columns].drop(columns=['is_canceled']))\n",
        "y_test = H1_test['is_canceled']\n",
        "\n",
        "# 初始化结果存储\n",
        "test_results = []\n",
        "\n",
        "# 对四种采样方法的最佳参数进行测试\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== Testing {method} on H1 Test Set ===\")\n",
        "\n",
        "    # 获取之前计算的最佳参数\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_scaled, y_train), n_trials=1)  # 仅获取最佳参数\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # 使用最佳参数重新定义模型\n",
        "    log_reg_model_optimized = LogisticRegression(**best_params, max_iter=2000, random_state=42)\n",
        "\n",
        "    # 使用 H1_test 数据进行预测\n",
        "    log_reg_model_optimized.fit(X_train_scaled, y_train)\n",
        "    y_test_pred = log_reg_model_optimized.predict(H1_test_scaled)\n",
        "    y_test_pred_proba = log_reg_model_optimized.predict_proba(H1_test_scaled)[:, 1]\n",
        "\n",
        "    # 计算测试指标\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    precision = precision_score(y_test, y_test_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_test_pred, pos_label=1)\n",
        "    f1 = f1_score(y_test, y_test_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "    # 保存测试结果\n",
        "    test_results.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report for {method}:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # 绘制 ROC 曲线\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method}) on H1 Test Set')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# 将测试结果转换为 DataFrame 并显示\n",
        "test_results_df = pd.DataFrame(test_results).sort_values(by='ROC AUC', ascending=False)\n",
        "print(test_results_df)\n",
        "\n",
        "# 绘制测试结果对比条形图\n",
        "test_results_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods on H1 Test Set')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AEv4iDDVFVm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP 4"
      ],
      "metadata": {
        "id": "BbMIpyPBFXo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# 准备H1测试数据\n",
        "X_h1_test = H1_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_h1_test = H1_test['is_canceled']\n",
        "\n",
        "# 提取top10特征的测试数据\n",
        "X_h1_test_top10 = X_h1_test[top10_shap_features]\n",
        "X_h1_test_scaled_top10 = scaler.transform(X_h1_test_top10)\n",
        "\n",
        "# 存储H1测试集评估结果\n",
        "h1_test_metrics_data = []\n",
        "\n",
        "# 对每个优化后的模型进行H1测试集评估\n",
        "for metric in metrics_data:\n",
        "    method = metric['Balancing Method']\n",
        "    best_params = metric['Best Parameters']\n",
        "    print(f\"\\n=== Testing on H1 Dataset - {method} ===\")\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(**best_params)\n",
        "\n",
        "    # 根据不同的采样方法处理训练数据\n",
        "    if method == 'No Sampling':\n",
        "        X_train_final, y_train_final = X_train_scaled_top10_shap, y_train\n",
        "    elif method == 'Undersample':\n",
        "        sampler = RandomUnderSampler(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "    elif method == 'Oversample':\n",
        "        sampler = RandomOverSampler(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "    else:  # SMOTE\n",
        "        sampler = SMOTE(random_state=42)\n",
        "        X_train_final, y_train_final = sampler.fit_resample(X_train_scaled_top10_shap, y_train)\n",
        "\n",
        "    # 训练模型\n",
        "    log_reg_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "    # 在H1测试集上进行预测\n",
        "    y_pred = log_reg_model.predict(X_h1_test_scaled_top10)\n",
        "    y_pred_proba = log_reg_model.predict_proba(X_h1_test_scaled_top10)[:, 1]\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(y_h1_test, y_pred)\n",
        "    precision = precision_score(y_h1_test, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_h1_test, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_h1_test, y_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_h1_test, y_pred_proba)\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report (H1 Test Set):\")\n",
        "    print(classification_report(y_h1_test, y_pred))\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_h1_test, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'H1 Test Set Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_h1_test, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'H1 Test Set ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 存储评估指标\n",
        "    h1_test_metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best Parameters': best_params,\n",
        "        'H1 Test Accuracy': accuracy,\n",
        "        'H1 Test Precision': precision,\n",
        "        'H1 Test Recall': recall,\n",
        "        'H1 Test F1 Score': f1,\n",
        "        'H1 Test ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建并显示H1测试集评估指标DataFrame\n",
        "h1_test_metrics_df = pd.DataFrame(h1_test_metrics_data).sort_values(by='H1 Test ROC AUC', ascending=False)\n",
        "print(\"\\nH1 Test Set Results:\")\n",
        "print(h1_test_metrics_df)\n",
        "\n",
        "# 绘制H1测试集评估指标比较图\n",
        "h1_test_metrics_df.set_index('Balancing Method')[\n",
        "    ['H1 Test Accuracy', 'H1 Test Precision', 'H1 Test Recall', 'H1 Test F1 Score', 'H1 Test ROC AUC']\n",
        "].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Optimized Models on H1 Test Set (Top 10 SHAP Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 创建H2训练集、H2测试集和H1测试集的性能对比\n",
        "comparison_data = []\n",
        "for train_metric, h2_test_metric, h1_test_metric in zip(metrics_data, test_metrics_data, h1_test_metrics_data):\n",
        "    method = train_metric['Balancing Method']\n",
        "    comparison_data.append({\n",
        "        'Method': method,\n",
        "        'H2 Train AUC': train_metric['ROC AUC'],\n",
        "        'H2 Test AUC': h2_test_metric['Test ROC AUC'],\n",
        "        'H1 Test AUC': h1_test_metric['H1 Test ROC AUC'],\n",
        "        'H2 Train F1': train_metric['F1 Score'],\n",
        "        'H2 Test F1': h2_test_metric['Test F1 Score'],\n",
        "        'H1 Test F1': h1_test_metric['H1 Test F1 Score']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nH2 Train vs H2 Test vs H1 Test Performance Comparison:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# 绘制三个数据集的性能对比图\n",
        "plt.figure(figsize=(12, 6))\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, comparison_df['H2 Train AUC'], width, label='H2 Train AUC')\n",
        "plt.bar(x, comparison_df['H2 Test AUC'], width, label='H2 Test AUC')\n",
        "plt.bar(x + width, comparison_df['H1 Test AUC'], width, label='H1 Test AUC')\n",
        "\n",
        "plt.xlabel('Balancing Method')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.title('Performance Comparison Across Datasets')\n",
        "plt.xticks(x, comparison_df['Method'], rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 计算并展示性能差异\n",
        "performance_diff_df = pd.DataFrame({\n",
        "    'Method': comparison_df['Method'],\n",
        "    'H2 Train-Test Diff': comparison_df['H2 Train AUC'] - comparison_df['H2 Test AUC'],\n",
        "    'H2-H1 Test Diff': comparison_df['H2 Test AUC'] - comparison_df['H1 Test AUC']\n",
        "})\n",
        "print(\"\\nPerformance Differences:\")\n",
        "print(performance_diff_df)"
      ],
      "metadata": {
        "id": "pX08MaxzFZtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta 4"
      ],
      "metadata": {
        "id": "HJ6kjAEJFaCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试集的 Boruta 筛选特征（H1 和 H2 分开处理）\n",
        "# 对 H1_test 应用相同的 Boruta 筛选步骤\n",
        "X_test_boruta_H1 = H1_test[selected_features]\n",
        "X_test_scaled_boruta_H1 = scaler.transform(X_test_boruta_H1)\n",
        "y_test_H1 = H1_test[\"is_canceled\"]\n",
        "\n",
        "# 对 H2_test 已经处理完毕，直接使用\n",
        "X_test_boruta_H2 = H2_test[selected_features]\n",
        "X_test_scaled_boruta_H2 = scaler.transform(X_test_boruta_H2)\n",
        "y_test_H2 = H2_test[\"is_canceled\"]\n",
        "\n",
        "# 定义保存测试结果的列表\n",
        "final_metrics_data_H1 = []\n",
        "final_metrics_data_H2 = []\n",
        "\n",
        "# 遍历采样方法并测试 H1 和 H2\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} Final Testing on H1 and H2 with Optimized Parameters ===\")\n",
        "\n",
        "    # 获取最佳参数\n",
        "    optimized_params = best_params[method]\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_boruta, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "\n",
        "    # 使用最佳参数创建模型\n",
        "    log_reg_model = LogisticRegression(\n",
        "        solver=\"lbfgs\",\n",
        "        random_state=42,\n",
        "        **optimized_params\n",
        "    )\n",
        "\n",
        "    # 训练模型\n",
        "    log_reg_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 对 H1_test 进行预测\n",
        "    y_pred_test_H1 = log_reg_model.predict(X_test_scaled_boruta_H1)\n",
        "    y_pred_proba_test_H1 = log_reg_model.predict_proba(X_test_scaled_boruta_H1)[:, 1]\n",
        "\n",
        "    # 计算 H1 的评估指标\n",
        "    accuracy_H1 = accuracy_score(y_test_H1, y_pred_test_H1)\n",
        "    precision_H1 = precision_score(y_test_H1, y_pred_test_H1)\n",
        "    recall_H1 = recall_score(y_test_H1, y_pred_test_H1)\n",
        "    f1_H1 = f1_score(y_test_H1, y_pred_test_H1)\n",
        "    roc_auc_H1 = roc_auc_score(y_test_H1, y_pred_proba_test_H1)\n",
        "\n",
        "    # 保存 H1 的测试结果\n",
        "    final_metrics_data_H1.append({\n",
        "        \"Balancing Method\": method,\n",
        "        \"Test Accuracy\": accuracy_H1,\n",
        "        \"Test Precision\": precision_H1,\n",
        "        \"Test Recall\": recall_H1,\n",
        "        \"Test F1 Score\": f1_H1,\n",
        "        \"Test ROC AUC\": roc_auc_H1\n",
        "    })\n",
        "\n",
        "    # 对 H2_test 进行预测\n",
        "    y_pred_test_H2 = log_reg_model.predict(X_test_scaled_boruta_H2)\n",
        "    y_pred_proba_test_H2 = log_reg_model.predict_proba(X_test_scaled_boruta_H2)[:, 1]\n",
        "\n",
        "    # 计算 H2 的评估指标\n",
        "    accuracy_H2 = accuracy_score(y_test_H2, y_pred_test_H2)\n",
        "    precision_H2 = precision_score(y_test_H2, y_pred_test_H2)\n",
        "    recall_H2 = recall_score(y_test_H2, y_pred_test_H2)\n",
        "    f1_H2 = f1_score(y_test_H2, y_pred_test_H2)\n",
        "    roc_auc_H2 = roc_auc_score(y_test_H2, y_pred_proba_test_H2)\n",
        "\n",
        "    # 保存 H2 的测试结果\n",
        "    final_metrics_data_H2.append({\n",
        "        \"Balancing Method\": method,\n",
        "        \"Test Accuracy\": accuracy_H2,\n",
        "        \"Test Precision\": precision_H2,\n",
        "        \"Test Recall\": recall_H2,\n",
        "        \"Test F1 Score\": f1_H2,\n",
        "        \"Test ROC AUC\": roc_auc_H2\n",
        "    })\n",
        "\n",
        "# 生成 H1 和 H2 的测试结果 DataFrame\n",
        "final_metrics_df_H1 = pd.DataFrame(final_metrics_data_H1).sort_values(by=\"Test ROC AUC\", ascending=False)\n",
        "final_metrics_df_H2 = pd.DataFrame(final_metrics_data_H2).sort_values(by=\"Test ROC AUC\", ascending=False)\n",
        "\n",
        "# 打印结果\n",
        "print(\"\\nFinal Test Results on H1:\")\n",
        "print(final_metrics_df_H1)\n",
        "\n",
        "print(\"\\nFinal Test Results on H2:\")\n",
        "print(final_metrics_df_H2)\n",
        "\n",
        "# 保存评估结果\n",
        "final_metrics_df_H1.to_csv(\"final_test_results_boruta_H1.csv\", index=False)\n",
        "final_metrics_df_H2.to_csv(\"final_test_results_boruta_H2.csv\", index=False)\n",
        "\n",
        "# 绘制对比图（H1 和 H2 分别绘制）\n",
        "final_metrics_df_H1.set_index(\"Balancing Method\")[[\"Test Accuracy\", \"Test Precision\", \"Test Recall\", \"Test F1 Score\", \"Test ROC AUC\"]].plot(\n",
        "    kind=\"bar\", figsize=(10, 6)\n",
        ")\n",
        "plt.title(\"Comparison of Balancing Methods on H1 Test Set (Boruta Selected Features)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "final_metrics_df_H2.set_index(\"Balancing Method\")[[\"Test Accuracy\", \"Test Precision\", \"Test Recall\", \"Test F1 Score\", \"Test ROC AUC\"]].plot(\n",
        "    kind=\"bar\", figsize=(10, 6)\n",
        ")\n",
        "plt.title(\"Comparison of Balancing Methods on H2 Test Set (Boruta Selected Features)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Gj5yCqbOIAH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2.Random Forest\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YUbuOlQp85kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline 4"
      ],
      "metadata": {
        "id": "XlsdNv1gy8f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义Optuna的目标函数\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(rf, X, y, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    print(f\"Optimizing hyperparameters for {method}...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    # 打印最佳参数\n",
        "    print(f\"Best parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    rf_model = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with Optimized Parameters')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NAWqvjflb0Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "8k_iFyuK8-YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4"
      ],
      "metadata": {
        "id": "4VpMg71Leglj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bR8eSpMegZrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ue1LVrQc1SGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fBbOtbFb1TDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "27POVliFflQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AcymRKgV1nmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10 4"
      ],
      "metadata": {
        "id": "thRdtSPEgO2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义初始随机森林模型\n",
        "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 计算 SHAP 值\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "shap_values = explainer.shap_values(X_train_scaled)[1]  # 仅选择目标值为 1 的 SHAP 值\n",
        "\n",
        "# 绘制 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values, X_train, feature_names=X_train.columns, plot_type=\"bar\")\n",
        "\n",
        "# 获取 Top 10 SHAP 特征\n",
        "shap_sum = np.abs(shap_values).mean(axis=0)\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'SHAP Importance': shap_sum})\n",
        "importance_df.sort_values(by='SHAP Importance', ascending=False, inplace=True)\n",
        "top10_shap_features = importance_df.head(10)['Feature'].values\n",
        "\n",
        "# 筛选 Top 10 特征\n",
        "X_train_top10_shap = X_train[top10_shap_features]\n",
        "X_train_scaled_top10_shap = scaler.fit_transform(X_train_top10_shap)\n",
        "\n",
        "# 定义 3-fold 交叉验证\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 进行 3-fold 交叉验证\n",
        "rf_model_top10_shap = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "y_pred_cv_shap = cross_val_predict(rf_model_top10_shap, X_train_scaled_top10_shap, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv_shap = cross_val_predict(rf_model_top10_shap, X_train_scaled_top10_shap, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算并绘制混淆矩阵\n",
        "conf_matrix_shap = confusion_matrix(y_train, y_pred_cv_shap)\n",
        "conf_matrix_percentage_shap = conf_matrix_shap / conf_matrix_shap.sum(axis=1).reshape(-1, 1) * 100\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_shap, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix_shap.shape[0]):\n",
        "    for j in range(conf_matrix_shap.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_shap[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.5, i + 0.5, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix with Counts and Percentages (SHAP Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# 分类报告和 ROC 曲线\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv_shap))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top10_shap, y_train):\n",
        "    rf_model_top10_shap.fit(X_train_scaled_top10_shap[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold_shap = rf_model_top10_shap.predict_proba(X_train_scaled_top10_shap[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold_shap)\n",
        "    roc_auc_fold_shap = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold_shap)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold_shap:.2f})')\n",
        "    fold_count += 1\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (SHAP Random Forest, 3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 绘制 Top 10 SHAP 特征重要性图\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df.head(10), x='SHAP Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 SHAP Feature Importances')\n",
        "plt.xlabel('SHAP Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sSFYuS8lmAJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def analyze_feature_importance(X_train, y_train, rf_model_raw, n_features=10, sample_size=200):\n",
        "    \"\"\"\n",
        "    Analyze feature importance using SHAP values with proper error handling and data validation\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 使用原始模型提取特征重要性\n",
        "        feature_importances = rf_model_raw.feature_importances_\n",
        "        feature_importance_df = pd.DataFrame({\n",
        "            'Feature': X_train.columns,\n",
        "            'Importance': feature_importances\n",
        "        }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "        # 选择前n个重要特征\n",
        "        top_features = feature_importance_df['Feature'].head(n_features).tolist()\n",
        "        print(f\"Top {n_features} important features:\", top_features)\n",
        "\n",
        "        # 重新训练模型，仅使用前n个重要特征\n",
        "        X_train_reduced = X_train[top_features]\n",
        "\n",
        "        # 确保数据完整性\n",
        "        if X_train_reduced.isnull().any().any():\n",
        "            X_train_reduced = X_train_reduced.fillna(0)\n",
        "\n",
        "        # 使用更简单的模型\n",
        "        rf_model_reduced = RandomForestClassifier(\n",
        "            n_estimators=50,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        )\n",
        "        rf_model_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "        # 准备样本数据 - 确保样本大小不超过可用数据\n",
        "        sample_size = min(sample_size, len(X_train_reduced))\n",
        "        sample_data = X_train_reduced.sample(n=sample_size, random_state=42)\n",
        "\n",
        "        # 确保样本数据是完整的DataFrame\n",
        "        sample_data = sample_data.reset_index(drop=True)\n",
        "\n",
        "        print(\"Initializing SHAP KernelExplainer...\")\n",
        "        background = shap.kmeans(sample_data, 10)\n",
        "        explainer = shap.KernelExplainer(\n",
        "            rf_model_reduced.predict_proba,\n",
        "            background,\n",
        "            link=\"logit\"\n",
        "        )\n",
        "\n",
        "        # 计算SHAP值\n",
        "        shap_values = explainer.shap_values(sample_data)\n",
        "\n",
        "        # 验证SHAP值的维度\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values_target = shap_values[1]  # 对于二分类，使用正类的SHAP值\n",
        "        else:\n",
        "            shap_values_target = shap_values\n",
        "\n",
        "        # 计算和绘制特征重要性\n",
        "        print(\"Calculating Median SHAP values...\")\n",
        "        shap_median_importance = np.median(np.abs(shap_values_target), axis=0)\n",
        "\n",
        "        shap_importance_df = pd.DataFrame({\n",
        "            'Feature': top_features,\n",
        "            'Median SHAP Value': shap_median_importance\n",
        "        }).sort_values(by='Median SHAP Value', ascending=False)\n",
        "\n",
        "        # 绘图\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.barh(shap_importance_df['Feature'], shap_importance_df['Median SHAP Value'])\n",
        "        plt.xlabel('Median SHAP Value')\n",
        "        plt.ylabel('Feature')\n",
        "        plt.title(f'Top {n_features} Feature Importance (Median SHAP Values)')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # SHAP summary plot\n",
        "        print(\"Generating SHAP summary plot...\")\n",
        "        shap.summary_plot(\n",
        "            shap_values_target,\n",
        "            sample_data,\n",
        "            plot_type='dot',\n",
        "            show=True\n",
        "        )\n",
        "\n",
        "        return shap_importance_df, explainer, shap_values_target\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "        print(\"Traceback:\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "# 使用示例：\n",
        "# results, explainer, shap_values = analyze_feature_importance(\n",
        "#     X_train,\n",
        "#     y_train,\n",
        "#     rf_model_raw,\n",
        "#     n_features=10,\n",
        "#     sample_size=200\n",
        "# )"
      ],
      "metadata": {
        "id": "YeIv9Ha6420X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印长度\n",
        "print(f\"Length of top_features: {len(top_features)}\")\n",
        "print(f\"Length of shap_median_importance: {len(shap_median_importance)}\")\n",
        "\n",
        "# 打印内容（前几个元素以便对比）\n",
        "print(\"Top features:\", top_features)\n",
        "print(\"SHAP median importance values (first 10):\", shap_median_importance[:10])\n"
      ],
      "metadata": {
        "id": "EQzUPaRZ3qUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = rf_model_reduced.predict(X_train_reduced)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train_reduced, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_train_reduced, y_pred))\n"
      ],
      "metadata": {
        "id": "GxpQgRNpLX-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta 4"
      ],
      "metadata": {
        "id": "xIXodnpzgPM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "from boruta import BorutaPy\n",
        "import numpy as np\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用Boruta进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 运行Boruta\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "# 创建特征重要性DataFrame\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': boruta_selector.ranking_,\n",
        "    'Selected': selected_feat_mask\n",
        "})\n",
        "importance_df['Importance'] = max(importance_df['Importance']) - importance_df['Importance'] + 1\n",
        "importance_df = importance_df[importance_df['Selected']].sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 如果选中的特征超过10个，只取前10个\n",
        "top_features = importance_df['Feature'].head(10).tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和Boruta选择的特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(metrics_df)\n",
        "\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Comparison of Balancing Methods (Boruta Selected Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化Boruta选择的特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top Features Selected by Boruta')\n",
        "plt.xlabel('Importance Rank')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HVtjKTYG2SQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "OMfNrez-8-YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline 4"
      ],
      "metadata": {
        "id": "UtEyQppeHVpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 定义Optuna的目标函数\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(rf, X, y, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和所有特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    print(f\"Optimizing hyperparameters for {method}...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    # 打印最佳参数\n",
        "    print(f\"Best parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    rf_model = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with Optimized Parameters (Baseline Model)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化所有特征的重要性\n",
        "rf_model_baseline = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
        "rf_model_baseline.fit(X_train_scaled, y_train)\n",
        "feature_importances = rf_model_baseline.feature_importances_\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=importance_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 15 Feature Importances (Baseline Model)')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cC3r24IDHYWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4"
      ],
      "metadata": {
        "id": "yZxtQ06EgWJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 定义目标函数\n",
        "def objective(trial):\n",
        "    # 定义需要调优的超参数范围\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "\n",
        "    # 创建模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 使用交叉验证评估性能\n",
        "    scores = cross_val_score(rf_model, X_resampled, y_resampled, cv=cv, scoring='roc_auc')\n",
        "    return scores.mean()  # 返回平均 AUC 作为目标值\n",
        "\n",
        "# 选择采样方法，例如 'SMOTE'\n",
        "sampler = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "# 创建 Optuna Study 并优化\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # 运行 50 次试验\n",
        "\n",
        "# 输出最佳超参数和结果\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Value: {study.best_trial.value}\")\n",
        "print(f\"  Params: {study.best_trial.params}\")\n",
        "\n",
        "# 使用最佳超参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "rf_model_optimized = RandomForestClassifier(\n",
        "    **best_params,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model_optimized.fit(X_resampled, y_resampled)\n",
        "\n",
        "# 测试并评估模型性能\n",
        "y_pred_cv_optimized = cross_val_predict(rf_model_optimized, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "y_pred_proba_cv_optimized = cross_val_predict(rf_model_optimized, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "accuracy_optimized = accuracy_score(y_resampled, y_pred_cv_optimized)\n",
        "precision_optimized = precision_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "recall_optimized = recall_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "f1_optimized = f1_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "roc_auc_optimized = roc_auc_score(y_resampled, y_pred_proba_cv_optimized)\n",
        "\n",
        "print(\"Optimized Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_optimized:.4f}\")\n",
        "print(f\"Precision: {precision_optimized:.4f}\")\n",
        "print(f\"Recall: {recall_optimized:.4f}\")\n",
        "print(f\"F1 Score: {f1_optimized:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_optimized:.4f}\")\n"
      ],
      "metadata": {
        "id": "AI5VQAAHHY86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 定义目标函数\n",
        "def objective(trial):\n",
        "    # 定义需要调优的超参数范围\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "\n",
        "    # 创建模型\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 使用交叉验证评估性能\n",
        "    scores = cross_val_score(rf_model, X_resampled, y_resampled, cv=cv, scoring='roc_auc')\n",
        "    return scores.mean()  # 返回平均 AUC 作为目标值\n",
        "\n",
        "# 选择采样方法，例如 'SMOTE'\n",
        "sampler = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "# 创建 Optuna Study 并优化\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # 运行 50 次试验\n",
        "\n",
        "# 输出最佳超参数和结果\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Value: {study.best_trial.value}\")\n",
        "print(f\"  Params: {study.best_trial.params}\")\n",
        "\n",
        "# 使用最佳超参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "rf_model_optimized = RandomForestClassifier(\n",
        "    **best_params,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model_optimized.fit(X_resampled, y_resampled)\n",
        "\n",
        "# 测试并评估模型性能\n",
        "y_pred_cv_optimized = cross_val_predict(rf_model_optimized, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "y_pred_proba_cv_optimized = cross_val_predict(rf_model_optimized, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "accuracy_optimized = accuracy_score(y_resampled, y_pred_cv_optimized)\n",
        "precision_optimized = precision_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "recall_optimized = recall_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "f1_optimized = f1_score(y_resampled, y_pred_cv_optimized, pos_label=1)\n",
        "roc_auc_optimized = roc_auc_score(y_resampled, y_pred_proba_cv_optimized)\n",
        "\n",
        "print(\"Optimized Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_optimized:.4f}\")\n",
        "print(f\"Precision: {precision_optimized:.4f}\")\n",
        "print(f\"Recall: {recall_optimized:.4f}\")\n",
        "print(f\"F1 Score: {f1_optimized:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_optimized:.4f}\")\n"
      ],
      "metadata": {
        "id": "mMzSLd1JfXlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义Optuna的目标函数\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(rf, X, y, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    print(f\"Optimizing hyperparameters for {method}...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    # 打印最佳参数\n",
        "    print(f\"Best parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    rf_model = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with Optimized Parameters')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RWXvh4JBJSoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用未处理数据的随机森林提取重要特征\n",
        "rf_model_raw = RandomForestClassifier(random_state=42)\n",
        "rf_model_raw.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 提取特征重要性\n",
        "feature_importances = rf_model_raw.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义Optuna的目标函数\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(rf, X, y, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    print(f\"Optimizing hyperparameters for {method}...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    # 打印最佳参数\n",
        "    print(f\"Best parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    rf_model = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with Optimized Parameters')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vYHwIct-hrLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JaeFJno1rll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10 4"
      ],
      "metadata": {
        "id": "1BlZeGk2gWJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta 4"
      ],
      "metadata": {
        "id": "JxpX7WAfgWJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from boruta import BorutaPy\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用Boruta进行特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 运行Boruta\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取选中的特征\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "# 创建特征重要性DataFrame\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': boruta_selector.ranking_,\n",
        "    'Selected': selected_feat_mask\n",
        "})\n",
        "importance_df['Importance'] = max(importance_df['Importance']) - importance_df['Importance'] + 1\n",
        "importance_df = importance_df[importance_df['Selected']].sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 如果选中的特征超过10个，只取前10个\n",
        "top_features = importance_df['Feature'].head(10).tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义Optuna的目标函数\n",
        "def objective(trial, X, y):\n",
        "    # 定义超参数搜索空间\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(rf, X, y, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 对每种采样方法进行超参数优化和模型训练\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    print(f\"Optimizing hyperparameters for {method}...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=50, show_progress_bar=True)\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    best_params = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(best_params)\n",
        "    print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "    rf_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
        "    y_pred_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict')\n",
        "    y_pred_proba_cv = cross_val_predict(rf_model, X_resampled, y_resampled, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred_cv)\n",
        "    precision = precision_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred_cv, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba_cv)\n",
        "\n",
        "    # 混淆矩阵可视化\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred_cv)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    report = classification_report(y_resampled, y_pred_cv)\n",
        "    print(report)\n",
        "\n",
        "    # ROC曲线可视化\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba_cv)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 记录评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建并显示metrics比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Performance Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with Optimized Parameters')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 绘制Boruta选择的特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top Features Selected by Boruta')\n",
        "plt.xlabel('Importance Rank')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存最佳模型的参数\n",
        "best_method = metrics_df.iloc[0]['Balancing Method']\n",
        "print(f\"\\nBest performing method: {best_method}\")\n",
        "print(\"Best hyperparameters:\")\n",
        "for method, sampler in samplers.items():\n",
        "    if method == best_method:\n",
        "        if sampler is None:\n",
        "            X_final, y_final = X_train_scaled_top, y_train\n",
        "        else:\n",
        "            X_final, y_final = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(lambda trial: objective(trial, X_final, y_final),\n",
        "                      n_trials=50, show_progress_bar=True)\n",
        "        print(study.best_params)"
      ],
      "metadata": {
        "id": "ET0IGADV3QYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "tbJRAfPpI_0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline 4（H1&H2）"
      ],
      "metadata": {
        "id": "wef2hbCgG7ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1126"
      ],
      "metadata": {
        "id": "Mwwj9LPar1kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_test_sets(X_train_scaled, y_train, X_test_scaled, y_test, params, set_name):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on test set using given parameters\n",
        "    \"\"\"\n",
        "    # Train model\n",
        "    rf_model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_model.predict(X_test_scaled)\n",
        "    y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {set_name}\\nROC-AUC: {roc_auc:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {set_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\nClassification Report - {set_name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "def evaluate_all_models(X_train_scaled, y_train, X_test_scaled, y_test, best_params, set_name):\n",
        "    \"\"\"\n",
        "    Evaluate all sampling methods on the test set\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for method, params in best_params.items():\n",
        "        print(f\"\\n=== {method} - {set_name} ===\")\n",
        "        metrics = evaluate_test_sets(X_train_scaled, y_train, X_test_scaled, y_test, params, f\"{method} - {set_name}\")\n",
        "        metrics['Method'] = method\n",
        "        results.append(metrics)\n",
        "\n",
        "    # Create comparison DataFrame\n",
        "    results_df = pd.DataFrame(results).set_index('Method')\n",
        "\n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    results_df.plot(kind='bar')\n",
        "    plt.title(f'Model Performance Comparison - {set_name}')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Best parameters from previous optimization\n",
        "best_params = {\n",
        "    'No Sampling': {\n",
        "        'n_estimators': 210,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 4,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_estimators': 202,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_estimators': 283,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 4,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    },\n",
        "    'SMOTE': {\n",
        "        'n_estimators': 226,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 6,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Prepare test data (assuming you have these variables defined)\n",
        "# Make sure to run the data preparation code first to have these variables available\n",
        "X_test = H1_test[X_train.columns]  # Use same columns as training data\n",
        "y_test = H1_test['is_canceled']\n",
        "X_test_H2 = H2_test[X_train.columns]  # Use same columns as training data\n",
        "y_test_H2 = H2_test['is_canceled']\n",
        "\n",
        "# Scale test data using the same scaler used for training data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2)\n",
        "\n",
        "# Evaluate H1 test set\n",
        "print(\"\\nEvaluating H1 Test Set:\")\n",
        "h1_results = evaluate_all_models(X_train_scaled, y_train, X_test_scaled, y_test, best_params, \"H1 Test Set\")\n",
        "\n",
        "# Evaluate H2 test set\n",
        "print(\"\\nEvaluating H2 Test Set:\")\n",
        "h2_results = evaluate_all_models(X_train_scaled, y_train, X_test_H2_scaled, y_test_H2, best_params, \"H2 Test Set\")\n",
        "\n",
        "# Print final comparison\n",
        "print(\"\\nH1 Test Set Results:\")\n",
        "print(h1_results)\n",
        "print(\"\\nH2 Test Set Results:\")\n",
        "print(h2_results)"
      ],
      "metadata": {
        "id": "on6GZ9ozr0N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print H2 Test Set Results in the requested format\n",
        "print(\"H2 Test Set Results Summary:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Method':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10} {'ROC AUC':<10}\")\n",
        "print('-'*70)\n",
        "for method, metrics in h2_results.iterrows():\n",
        "    print(f\"{method:<15} {metrics['Accuracy']:.6f} {metrics['Precision']:.6f} {metrics['Recall']:.6f} {metrics['F1 Score']:.6f} {metrics['ROC AUC']:.6f}\")\n",
        "\n",
        "# Print H1 Test Set Results in the requested format\n",
        "print(\"\\nH1 Test Set Results Summary:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Method':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10} {'ROC AUC':<10}\")\n",
        "print('-'*70)\n",
        "for method, metrics in h1_results.iterrows():\n",
        "    print(f\"{method:<15} {metrics['Accuracy']:.6f} {metrics['Precision']:.6f} {metrics['Recall']:.6f} {metrics['F1 Score']:.6f} {metrics['ROC AUC']:.6f}\")"
      ],
      "metadata": {
        "id": "otRbMh4gs7Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4"
      ],
      "metadata": {
        "id": "v1uiwBiggW7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 首先打印出所有数据集的列名，看看是否一致\n",
        "print(\"X_train columns:\", X_train.columns.tolist())\n",
        "print(\"X_test columns:\", X_test.columns.tolist())\n",
        "print(\"X_test_H2 columns:\", X_test_H2.columns.tolist())\n",
        "\n",
        "# 2. 检查数据类型是否一致\n",
        "print(\"\\nX_train dtypes:\\n\", X_train.dtypes)\n",
        "print(\"\\nX_test dtypes:\\n\", X_test.dtypes)\n",
        "print(\"\\nX_test_H2 dtypes:\\n\", X_test_H2.dtypes)\n",
        "\n",
        "# 3. 查看是否有缺失值\n",
        "print(\"\\nMissing values in X_train:\\n\", X_train.isnull().sum())\n",
        "print(\"\\nMissing values in X_test:\\n\", X_test.isnull().sum())\n",
        "print(\"\\nMissing values in X_test_H2:\\n\", X_test_H2.isnull().sum())\n",
        "\n",
        "# 4. 检查数据集的形状\n",
        "print(\"\\nShapes:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"X_test_H2:\", X_test_H2.shape)"
      ],
      "metadata": {
        "id": "3iTnzUoQITkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 将数据集转换为 numpy 数组，避免特征名称问题\n",
        "X_train_array = X_train.values\n",
        "X_test_array = X_test.values\n",
        "X_test_H2_array = X_test_H2.values\n",
        "\n",
        "# 2. 对训练数据进行拟合和转换\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_array)\n",
        "\n",
        "# 3. 使用同一个 scaler 对测试数据进行转换\n",
        "X_test_scaled = scaler.transform(X_test_array)\n",
        "X_test_H2_scaled = scaler.transform(X_test_H2_array)\n",
        "\n",
        "# 4. 验证转换后的形状\n",
        "print(\"Scaled shapes:\")\n",
        "print(\"X_train_scaled:\", X_train_scaled.shape)\n",
        "print(\"X_test_scaled:\", X_test_scaled.shape)\n",
        "print(\"X_test_H2_scaled:\", X_test_H2_scaled.shape)"
      ],
      "metadata": {
        "id": "_rMXHwdPIiuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_all_models(X_train_scaled, y_train, X_test_scaled, y_test, X_test_H2_scaled, y_test_H2, best_params):\n",
        "\n",
        "    samplers = {\n",
        "        'No Sampling': None,\n",
        "        'Undersample': RandomUnderSampler(random_state=42),\n",
        "        'Oversample': RandomOverSampler(random_state=42),\n",
        "        'SMOTE': SMOTE(random_state=42)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for method, sampler in samplers.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Evaluating {method}\")\n",
        "        print('='*50)\n",
        "\n",
        "        # 对训练数据进行重采样\n",
        "        if sampler is None:\n",
        "            X_resampled, y_resampled = X_train_scaled, y_train\n",
        "        else:\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        # 使用最佳参数训练模型\n",
        "        rf_model = RandomForestClassifier(**best_params[method], random_state=42, n_jobs=-1)\n",
        "        rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # 评估H1测试集\n",
        "        print(\"\\nResults on H1 Test Set (City Hotel):\")\n",
        "        y_pred_h1 = rf_model.predict(X_test_scaled)\n",
        "        y_pred_proba_h1 = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "        # 计算H1指标\n",
        "        h1_metrics = calculate_metrics(y_test, y_pred_h1, y_pred_proba_h1, \"H1\")\n",
        "        plot_evaluation_charts(y_test, y_pred_h1, y_pred_proba_h1, method, \"H1 Test Set\")\n",
        "\n",
        "        # 评估H2测试集\n",
        "        print(\"\\nResults on H2 Test Set (Resort Hotel):\")\n",
        "        y_pred_h2 = rf_model.predict(X_test_H2_scaled)\n",
        "        y_pred_proba_h2 = rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "        # 计算H2指标\n",
        "        h2_metrics = calculate_metrics(y_test_H2, y_pred_h2, y_pred_proba_h2, \"H2\")\n",
        "        plot_evaluation_charts(y_test_H2, y_pred_h2, y_pred_proba_h2, method, \"H2 Test Set\")\n",
        "\n",
        "        # 保存结果\n",
        "        results.extend([h1_metrics, h2_metrics])\n",
        "\n",
        "    # 创建结果DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_pred_proba, test_set):\n",
        "    \"\"\"计算各种评估指标\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    print(f\"\\nClassification Report for {test_set}:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Test Set': test_set,\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "def plot_evaluation_charts(y_true, y_pred, y_pred_proba, method, test_set):\n",
        "    \"\"\"绘制评估图表\"\"\"\n",
        "    # 混淆矩阵\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Not Canceled', 'Canceled'],\n",
        "                yticklabels=['Not Canceled', 'Canceled'])\n",
        "    plt.title(f'Confusion Matrix\\n{method} - {test_set}')\n",
        "\n",
        "    # ROC曲线\n",
        "    plt.subplot(1, 2, 2)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score(y_true, y_pred_proba):.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{method} - {test_set}')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 定义最佳参数\n",
        "best_params = {\n",
        "    'SMOTE': {\n",
        "        'n_estimators': 241,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'log2'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_estimators': 178,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'log2'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_estimators': 300,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    },\n",
        "    'No Sampling': {\n",
        "        'n_estimators': 270,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 8,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 运行评估\n",
        "results_df = evaluate_all_models(\n",
        "    X_train_scaled, y_train,\n",
        "    X_test_scaled, y_test,\n",
        "    X_test_H2_scaled, y_test_H2,\n",
        "    best_params\n",
        ")\n",
        "\n",
        "# 打印最终结果汇总\n",
        "print(\"\\nFinal Results Summary:\")\n",
        "print(results_df.sort_values(['Test Set', 'ROC AUC'], ascending=[True, False]))\n",
        "\n",
        "# 绘制综合比较图\n",
        "plt.figure(figsize=(15, 6))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "\n",
        "for i, test_set in enumerate(['H1', 'H2']):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    test_results = results_df[results_df['Test Set'] == test_set]\n",
        "    test_results[metrics].plot(kind='bar', ax=plt.gca())\n",
        "    plt.title(f'{test_set} Test Set Results')\n",
        "    plt.xticks(range(len(test_results)), test_results['Method'], rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pi-7AR0nI2Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_all_models(X_train_scaled, y_train, X_test_scaled, y_test, X_test_H2_scaled, y_test_H2, best_params):\n",
        "\n",
        "    samplers = {\n",
        "        'No Sampling': None,\n",
        "        'Undersample': RandomUnderSampler(random_state=42),\n",
        "        'Oversample': RandomOverSampler(random_state=42),\n",
        "        'SMOTE': SMOTE(random_state=42)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for method, sampler in samplers.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Evaluating {method}\")\n",
        "        print('='*50)\n",
        "\n",
        "        # 对训练数据进行重采样\n",
        "        if sampler is None:\n",
        "            X_resampled, y_resampled = X_train_scaled, y_train\n",
        "        else:\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        # 使用最佳参数训练模型\n",
        "        rf_model = RandomForestClassifier(**best_params[method], random_state=42, n_jobs=-1)\n",
        "        rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # 评估H1测试集\n",
        "        print(\"\\nResults on H1 Test Set (City Hotel):\")\n",
        "        y_pred_h1 = rf_model.predict(X_test_scaled)\n",
        "        y_pred_proba_h1 = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "        # 计算H1指标\n",
        "        h1_metrics = calculate_metrics(y_test, y_pred_h1, y_pred_proba_h1, \"H1\")\n",
        "        plot_evaluation_charts(y_test, y_pred_h1, y_pred_proba_h1, method, \"H1 Test Set\")\n",
        "\n",
        "        # 评估H2测试集\n",
        "        print(\"\\nResults on H2 Test Set (Resort Hotel):\")\n",
        "        y_pred_h2 = rf_model.predict(X_test_H2_scaled)\n",
        "        y_pred_proba_h2 = rf_model.predict_proba(X_test_H2_scaled)[:, 1]\n",
        "\n",
        "        # 计算H2指标\n",
        "        h2_metrics = calculate_metrics(y_test_H2, y_pred_h2, y_pred_proba_h2, \"H2\")\n",
        "        plot_evaluation_charts(y_test_H2, y_pred_h2, y_pred_proba_h2, method, \"H2 Test Set\")\n",
        "\n",
        "        # 保存结果\n",
        "        results.extend([h1_metrics, h2_metrics])\n",
        "\n",
        "    # 创建结果DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, y_pred_proba, test_set):\n",
        "    \"\"\"计算各种评估指标\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    print(f\"\\nClassification Report for {test_set}:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Test Set': test_set,\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "def plot_evaluation_charts(y_true, y_pred, y_pred_proba, method, test_set):\n",
        "    \"\"\"绘制评估图表\"\"\"\n",
        "    # 混淆矩阵\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Not Canceled', 'Canceled'],\n",
        "                yticklabels=['Not Canceled', 'Canceled'])\n",
        "    plt.title(f'Confusion Matrix\\n{method} - {test_set}')\n",
        "\n",
        "    # ROC曲线\n",
        "    plt.subplot(1, 2, 2)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score(y_true, y_pred_proba):.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{method} - {test_set}')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 定义最佳参数\n",
        "best_params = {\n",
        "    'SMOTE': {\n",
        "        'n_estimators': 241,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'log2'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_estimators': 178,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'log2'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_estimators': 300,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    },\n",
        "    'No Sampling': {\n",
        "        'n_estimators': 270,\n",
        "        'max_depth': 15,\n",
        "        'min_samples_split': 8,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 运行评估\n",
        "results_df = evaluate_all_models(\n",
        "    X_train_scaled, y_train,\n",
        "    X_test_scaled, y_test,\n",
        "    X_test_H2_scaled, y_test_H2,\n",
        "    best_params\n",
        ")\n",
        "\n",
        "# 打印最终结果汇总\n",
        "print(\"\\nFinal Results Summary:\")\n",
        "print(results_df.sort_values(['Test Set', 'ROC AUC'], ascending=[True, False]))\n",
        "\n",
        "# 绘制综合比较图\n",
        "plt.figure(figsize=(15, 6))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "\n",
        "for i, test_set in enumerate(['H1', 'H2']):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    test_results = results_df[results_df['Test Set'] == test_set]\n",
        "    test_results[metrics].plot(kind='bar', ax=plt.gca())\n",
        "    plt.title(f'{test_set} Test Set Results')\n",
        "    plt.xticks(range(len(test_results)), test_results['Method'], rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iAMBs45zfKS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10 4"
      ],
      "metadata": {
        "id": "PavI1GZ7gW7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta 4（ H1H2）"
      ],
      "metadata": {
        "id": "xe-hYJAZgW7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from boruta import BorutaPy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, method_name, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_true, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # 混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {method_name}\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {method_name}\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report - {method_name} - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Method': method_name,\n",
        "        'Dataset': dataset_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "# 获取之前的特征选择结果\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 准备测试数据\n",
        "X_H2_test = H2_test[top_features]\n",
        "X_H2_test_scaled = scaler.transform(X_H2_test)\n",
        "y_H2_test = H2_test['is_canceled']\n",
        "\n",
        "X_H1_test = H1_test[top_features]\n",
        "X_H1_test_scaled = scaler.transform(X_H1_test)\n",
        "y_H1_test = H1_test['is_canceled']\n",
        "\n",
        "# 定义采样方法和它们的最佳参数\n",
        "sampling_methods = {\n",
        "    'No Sampling': {\n",
        "        'sampler': None,\n",
        "        'params': {\n",
        "            'n_estimators': 270,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 8,\n",
        "            'min_samples_leaf': 1,\n",
        "            'max_features': 'sqrt'\n",
        "        }\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'sampler': RandomUnderSampler(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': 300,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'max_features': 'sqrt'\n",
        "        }\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'sampler': RandomOverSampler(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': 178,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'max_features': 'log2'\n",
        "        }\n",
        "    },\n",
        "    'SMOTE': {\n",
        "        'sampler': SMOTE(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': 241,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'max_features': 'log2'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 存储所有评估结果\n",
        "all_results = []\n",
        "\n",
        "# 对每种采样方法进行评估\n",
        "for method_name, method_info in sampling_methods.items():\n",
        "    print(f\"\\n=== Evaluating {method_name} ===\")\n",
        "\n",
        "    # 使用采样方法处理训练数据\n",
        "    if method_info['sampler'] is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = method_info['sampler'].fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 使用最佳参数训练模型\n",
        "    rf_model = RandomForestClassifier(**method_info['params'], random_state=42, n_jobs=-1)\n",
        "    rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # 在H2测试集上评估\n",
        "    y_pred_H2 = rf_model.predict(X_H2_test_scaled)\n",
        "    y_pred_proba_H2 = rf_model.predict_proba(X_H2_test_scaled)[:, 1]\n",
        "    h2_results = evaluate_and_visualize(y_H2_test, y_pred_H2, y_pred_proba_H2, method_name, 'H2 Test Set')\n",
        "    all_results.append(h2_results)\n",
        "\n",
        "    # 在H1测试集上评估\n",
        "    y_pred_H1 = rf_model.predict(X_H1_test_scaled)\n",
        "    y_pred_proba_H1 = rf_model.predict_proba(X_H1_test_scaled)[:, 1]\n",
        "    h1_results = evaluate_and_visualize(y_H1_test, y_pred_H1, y_pred_proba_H1, method_name, 'H1 Test Set')\n",
        "    all_results.append(h1_results)\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# 创建图形和子图\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# 准备数据\n",
        "h2_data = results_df[results_df['Dataset'] == 'H2 Test Set'].set_index('Method')\n",
        "h1_data = results_df[results_df['Dataset'] == 'H1 Test Set'].set_index('Method')\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "\n",
        "# 设置柱状图的颜色\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "\n",
        "# H2测试集结果\n",
        "h2_data[metrics].plot(kind='bar', ax=ax1, width=0.8, color=colors)\n",
        "ax1.set_title('Performance on H2 Test Set', pad=20, fontsize=12)\n",
        "ax1.set_ylabel('Score', fontsize=10)\n",
        "ax1.set_ylim(0, 1)\n",
        "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "ax1.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "ax1.tick_params(axis='x', labelrotation=30)\n",
        "\n",
        "# H1测试集结果\n",
        "h1_data[metrics].plot(kind='bar', ax=ax2, width=0.8, color=colors)\n",
        "ax2.set_title('Performance on H1 Test Set', pad=20, fontsize=12)\n",
        "ax2.set_ylabel('Score', fontsize=10)\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "ax2.tick_params(axis='x', labelrotation=30)\n",
        "\n",
        "# 调整布局\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.85, wspace=0.25)\n",
        "\n",
        "# 显示图表\n",
        "plt.show()\n",
        "\n",
        "# 输出每个数据集的最佳方法\n",
        "for dataset in ['H2 Test Set', 'H1 Test Set']:\n",
        "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
        "    best_method = dataset_results.loc[dataset_results['ROC AUC'].idxmax()]\n",
        "    print(f\"\\nBest method for {dataset}:\")\n",
        "    print(f\"Method: {best_method['Method']}\")\n",
        "    print(f\"ROC AUC: {best_method['ROC AUC']:.4f}\")\n",
        "    print(f\"Accuracy: {best_method['Accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {best_method['F1 Score']:.4f}\")"
      ],
      "metadata": {
        "id": "0WDZC08oE8T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H1 test set"
      ],
      "metadata": {
        "id": "YfhCi6mnI_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous test set contains the cross dataset test results"
      ],
      "metadata": {
        "id": "xjo0g-enEV2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 3.TabNet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RApnhiF49E7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "uxmzek2t9BTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline 4"
      ],
      "metadata": {
        "id": "TujBDFy6SEtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设 H2_train 和 selected_columns 已经定义\n",
        "# 定义特征和目标变量\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 初始训练TabNet来获取特征重要性\n",
        "initial_tabnet = TabNetClassifier(\n",
        "    n_d=8,\n",
        "    n_a=8,\n",
        "    n_steps=3,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax',\n",
        "    device_name='auto'\n",
        ")\n",
        "\n",
        "initial_tabnet.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 获取特征重要性\n",
        "feature_importances = initial_tabnet.feature_importances_\n",
        "features = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# 提取 Top 10 特征\n",
        "top_features = importance_df_sorted['Feature'].tolist()\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义TabNet的基础配置\n",
        "def get_tabnet_config():\n",
        "    return {\n",
        "        'n_d': 8,  # 维度数\n",
        "        'n_a': 8,  # 注意力维度\n",
        "        'n_steps': 3,  # 步数\n",
        "        'gamma': 1.3,  # 功能选择单元的系数\n",
        "        'n_independent': 2,  # 独立层数\n",
        "        'n_shared': 2,  # 共享层数\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=2e-2),\n",
        "        'scheduler_params': {\"step_size\":10, \"gamma\":0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用采样方法和 Top 10 特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled, y_resampled = X_train_scaled_top, y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 初始化TabNet模型\n",
        "    tabnet_config = get_tabnet_config()\n",
        "    tabnet_model = TabNetClassifier(**tabnet_config)\n",
        "\n",
        "    # 训练模型\n",
        "    tabnet_model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 预测和评估\n",
        "    y_pred = tabnet_model.predict(X_resampled)\n",
        "    y_pred_proba = tabnet_model.predict_proba(X_resampled)[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred)\n",
        "    precision = precision_score(y_resampled, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_resampled, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_resampled, y_pred, pos_label=1)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba)\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nROC-AUC: {roc_auc:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    report = classification_report(y_resampled, y_pred)\n",
        "    print(report)\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 收集指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with TabNet')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df_sorted, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QF0J_BR5_1kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "eegRQ9md9BTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4"
      ],
      "metadata": {
        "id": "GEja_crcUADt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 使用已经获得的top 10 features\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_train_scaled_top = pd.DataFrame(X_train_scaled_top, columns=top_features)  # 转换为DataFrame保持索引\n",
        "\n",
        "# 定义TabNet基础配置\n",
        "def get_tabnet_config():\n",
        "    return {\n",
        "        'n_d': 16,\n",
        "        'n_a': 16,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.3,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=2e-2),\n",
        "        'scheduler_params': {\"step_size\":10, \"gamma\":0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 对每种采样方法训练TabNet模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_top.values\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "        X_resampled = np.array(X_resampled)  # 确保为numpy array\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 存储每个fold的预测结果\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    # 执行交叉验证\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        # 准备数据\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        # 初始化并训练模型\n",
        "        tabnet_model = TabNetClassifier(**get_tabnet_config())\n",
        "        tabnet_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=100,\n",
        "            patience=15,\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128\n",
        "        )\n",
        "\n",
        "        # 预测并存储结果\n",
        "        fold_preds = tabnet_model.predict(X_fold_val)\n",
        "        fold_pred_probas = tabnet_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 转换为numpy数组以便计算指标\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_y_true, all_y_pred))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - TabNet ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 收集评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建并显示结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison (TabNet):\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods - TabNet (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "18yHNd1GVe6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP top10 4"
      ],
      "metadata": {
        "id": "vFSvrrxAUNec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import shap\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 准备数据\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "# 初始化TabNet模型用于SHAP分析\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=8,\n",
        "    n_a=8,\n",
        "    n_steps=3,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax',\n",
        "    device_name='auto'\n",
        ")\n",
        "\n",
        "# 训练模型\n",
        "initial_model.fit(\n",
        "    X_train_scaled.values, y_train.values,\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 使用SHAP进行特征重要性分析\n",
        "background = shap.kmeans(X_train_scaled.values, 10)  # 创建背景数据集\n",
        "explainer = shap.KernelExplainer(initial_model.predict_proba, background)\n",
        "shap_values = explainer.shap_values(X_train_scaled.values[:100])  # 使用部分数据以加快计算\n",
        "\n",
        "# 修改 SHAP 值的计算和特征重要性的转换\n",
        "# 计算 SHAP 值的绝对平均值\n",
        "feature_importance = np.abs(shap_values[1]).mean(axis=0)  # 确保沿正确的轴计算平均值\n",
        "\n",
        "# 如果 feature_importance 是二维的，取第一列\n",
        "if len(feature_importance.shape) > 1:\n",
        "    feature_importance = feature_importance[:, 0]\n",
        "\n",
        "# 创建特征重要性 DataFrame\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_scaled.columns,\n",
        "    'Importance': feature_importance\n",
        "})\n",
        "\n",
        "# 确认数据形状\n",
        "print(\"Feature importance shape after processing:\", feature_importance.shape)\n",
        "print(\"Number of features:\", len(X_train_scaled.columns))\n",
        "\n",
        "# 排序并获取 top features\n",
        "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False)\n",
        "top_features = importance_df_sorted['Feature'].head(10).tolist()\n",
        "\n",
        "# 可视化SHAP重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(shap_values[1], X_train_scaled.values,\n",
        "                 feature_names=X_train_scaled.columns,\n",
        "                 show=False)\n",
        "plt.title(\"SHAP Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 准备基于SHAP选择的top features的数据\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 使用SHAP选择的Top 10特征训练模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_top\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "    # 初始化TabNet模型\n",
        "    tabnet_model = TabNetClassifier(\n",
        "        n_d=8,\n",
        "        n_a=8,\n",
        "        n_steps=3,\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=2e-2),\n",
        "        scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "        mask_type='sparsemax',\n",
        "        device_name='auto'\n",
        "    )\n",
        "\n",
        "    # 训练模型\n",
        "    tabnet_model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    # 预测和评估\n",
        "    y_pred = tabnet_model.predict(X_resampled)\n",
        "    y_pred_proba = tabnet_model.predict_proba(X_resampled)[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_resampled, y_pred)\n",
        "    precision = precision_score(y_resampled, y_pred)\n",
        "    recall = recall_score(y_resampled, y_pred)\n",
        "    f1 = f1_score(y_resampled, y_pred)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred_proba)\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix ({method})\\nROC-AUC: {roc_auc:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_resampled, y_pred))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods with TabNet (SHAP-selected features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存SHAP分析结果和模型性能\n",
        "results = {\n",
        "    'shap_top_features': top_features,\n",
        "    'feature_importance': importance_df_sorted.to_dict(),\n",
        "    'model_metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('tabnet_shap_analysis_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "HYE0UwouUZKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shap_values[1] shape:\", np.array(shap_values[1]).shape)\n",
        "print(\"feature_importance shape:\", feature_importance.shape)\n",
        "print(\"X_train_scaled.columns length:\", len(X_train_scaled.columns))"
      ],
      "metadata": {
        "id": "sowIe_p7Yaxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "triple"
      ],
      "metadata": {
        "id": "T7s18VSVWSVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import shap\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 准备数据\n",
        "X_train = H2_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = H2_train['is_canceled']\n",
        "\n",
        "# 标准化特征\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "# 1. Feature Importance\n",
        "initial_model = TabNetClassifier(\n",
        "    n_d=8, n_a=8, n_steps=3,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax'\n",
        ")\n",
        "\n",
        "initial_model.fit(\n",
        "    X_train_scaled.values, y_train.values,\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=1024\n",
        ")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "})\n",
        "importance_features = feature_importance.nlargest(10, 'Importance')['Feature'].tolist()\n",
        "\n",
        "# 2. SHAP Analysis\n",
        "background = shap.kmeans(X_train_scaled.values[:100], 10)\n",
        "explainer = shap.KernelExplainer(initial_model.predict_proba, background)\n",
        "shap_values = explainer.shap_values(X_train_scaled.values[:100])[1]\n",
        "\n",
        "shap_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.abs(shap_values).mean(0)\n",
        "})\n",
        "shap_features = shap_importance.nlargest(10, 'Importance')['Feature'].tolist()\n",
        "\n",
        "# 3. Boruta\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
        "boruta.fit(X_train_scaled.values, y_train.values)\n",
        "\n",
        "boruta_features = X_train.columns[boruta.support_].tolist()\n",
        "if len(boruta_features) > 10:\n",
        "    boruta_features = boruta_features[:10]\n",
        "\n",
        "# 打印选择的特征\n",
        "print(\"\\nSelected Features by Each Method:\")\n",
        "print(\"Feature Importance:\", importance_features)\n",
        "print(\"\\nSHAP:\", shap_features)\n",
        "print(\"\\nBoruta:\", boruta_features)\n",
        "\n",
        "# 特征选择方法字典\n",
        "feature_sets = {\n",
        "    'Feature Importance': importance_features,\n",
        "    'SHAP': shap_features,\n",
        "    'Boruta': boruta_features\n",
        "}\n",
        "\n",
        "# 平衡方法字典\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 存储所有结果\n",
        "all_results = {}\n",
        "\n",
        "# 对每种特征选择方法和每种平衡方法进行训练和评估\n",
        "for feature_method, selected_features in feature_sets.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Processing {feature_method} features\")\n",
        "    print('='*50)\n",
        "\n",
        "    # 准备该特征集的数据\n",
        "    X_selected = X_train_scaled[selected_features]\n",
        "    all_results[feature_method] = {}\n",
        "\n",
        "    # 对每种平衡方法进行训练\n",
        "    for sampler_name, sampler in samplers.items():\n",
        "        print(f\"\\nTraining with {sampler_name}\")\n",
        "\n",
        "        # 应用采样方法\n",
        "        if sampler is None:\n",
        "            X_resampled = X_selected\n",
        "            y_resampled = y_train\n",
        "        else:\n",
        "            X_resampled, y_resampled = sampler.fit_resample(X_selected, y_train)\n",
        "\n",
        "        # 训练集和验证集分割\n",
        "        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "            X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # 初始化和训练模型\n",
        "        model = TabNetClassifier(\n",
        "            n_d=8, n_a=8, n_steps=3,\n",
        "            optimizer_fn=torch.optim.Adam,\n",
        "            optimizer_params=dict(lr=2e-2),\n",
        "            scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "            scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "            mask_type='sparsemax'\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_split, y_train_split,\n",
        "            eval_set=[(X_val_split, y_val_split)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=1024\n",
        "        )\n",
        "\n",
        "        # 预测和评估\n",
        "        y_pred = model.predict(X_val_split)\n",
        "        y_pred_proba = model.predict_proba(X_val_split)[:, 1]\n",
        "\n",
        "        # 存储结果\n",
        "        all_results[feature_method][sampler_name] = {\n",
        "            'accuracy': accuracy_score(y_val_split, y_pred),\n",
        "            'precision': precision_score(y_val_split, y_pred),\n",
        "            'recall': recall_score(y_val_split, y_pred),\n",
        "            'f1': f1_score(y_val_split, y_pred),\n",
        "            'roc_auc': roc_auc_score(y_val_split, y_pred_proba),\n",
        "            'predictions': y_pred,\n",
        "            'probabilities': y_pred_proba,\n",
        "            'true_values': y_val_split\n",
        "        }\n",
        "\n",
        "        # 打印分类报告\n",
        "        print(f\"\\nClassification Report for {feature_method} - {sampler_name}:\")\n",
        "        print(classification_report(y_val_split, y_pred))\n",
        "\n",
        "        # 绘制混淆矩阵\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        conf_matrix = confusion_matrix(y_val_split, y_pred)\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "                plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "        plt.title(f'Confusion Matrix\\n{feature_method} - {sampler_name}')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.show()\n",
        "\n",
        "# 创建综合性能比较表\n",
        "comparison_data = []\n",
        "for feature_method in feature_sets.keys():\n",
        "    for sampler_name in samplers.keys():\n",
        "        results = all_results[feature_method][sampler_name]\n",
        "        comparison_data.append({\n",
        "            'Feature Method': feature_method,\n",
        "            'Sampling Method': sampler_name,\n",
        "            'Accuracy': results['accuracy'],\n",
        "            'Precision': results['precision'],\n",
        "            'Recall': results['recall'],\n",
        "            'F1 Score': results['f1'],\n",
        "            'ROC AUC': results['roc_auc']\n",
        "        })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# 绘制综合性能比较图\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    comparison_pivot = comparison_df.pivot(\n",
        "        index='Sampling Method',\n",
        "        columns='Feature Method',\n",
        "        values=metric\n",
        "    )\n",
        "    comparison_pivot.plot(kind='bar')\n",
        "    plt.title(f'{metric} Comparison')\n",
        "    plt.xlabel('Sampling Method')\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend(title='Feature Selection Method', bbox_to_anchor=(1.05, 1))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 为每种特征选择方法绘制ROC曲线比较图\n",
        "for feature_method in feature_sets.keys():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for sampler_name in samplers.keys():\n",
        "        results = all_results[feature_method][sampler_name]\n",
        "        fpr, tpr, _ = roc_curve(results['true_values'], results['probabilities'])\n",
        "        plt.plot(fpr, tpr,\n",
        "                label=f'{sampler_name} (AUC = {results[\"roc_auc\"]:.3f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curves Comparison - {feature_method}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# 保存完整结果\n",
        "final_results = {\n",
        "    'feature_sets': {k: v for k, v in feature_sets.items()},\n",
        "    'metrics': comparison_df.to_dict('records'),\n",
        "    'feature_importance_scores': {\n",
        "        'tabnet': feature_importance.to_dict(),\n",
        "        'shap': shap_importance.to_dict(),\n",
        "        'boruta': {'selected_features': boruta_features}\n",
        "    }\n",
        "}\n",
        "\n",
        "# 保存为JSON文件\n",
        "with open('complete_comparison_results.json', 'w') as f:\n",
        "    json.dump(final_results, f, indent=4)\n",
        "\n",
        "# 显示最佳组合\n",
        "print(\"\\nBest Combinations by Different Metrics:\")\n",
        "for metric in metrics:\n",
        "    best_idx = comparison_df[metric].idxmax()\n",
        "    best_combo = comparison_df.iloc[best_idx]\n",
        "    print(f\"\\nBest {metric}:\")\n",
        "    print(f\"Feature Method: {best_combo['Feature Method']}\")\n",
        "    print(f\"Sampling Method: {best_combo['Sampling Method']}\")\n",
        "    print(f\"Score: {best_combo[metric]:.4f}\")"
      ],
      "metadata": {
        "id": "BZeWiqwfWXb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA 4"
      ],
      "metadata": {
        "id": "P1KzM4heUODz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 首先进行Boruta特征选择\n",
        "print(\"Starting Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',  # 自动选择评估次数\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    max_iter=100  # 最大迭代次数\n",
        ")\n",
        "\n",
        "# 准备数据用于Boruta（需要numpy array格式）\n",
        "X_for_boruta = X_train.values\n",
        "y_for_boruta = y_train.values\n",
        "\n",
        "# 运行Boruta特征选择\n",
        "boruta_selector.fit(X_for_boruta, y_for_boruta)\n",
        "\n",
        "# 获取选中的特征\n",
        "feature_names = X_train.columns.tolist()\n",
        "boruta_features = [feature for feature, selected in zip(feature_names, boruta_selector.support_) if selected]\n",
        "\n",
        "print(f\"\\nBoruta selected {len(boruta_features)} features:\")\n",
        "print(boruta_features)\n",
        "\n",
        "# 使用boruta筛选出的特征\n",
        "X_train_boruta = X_train[boruta_features]\n",
        "X_train_scaled_boruta = scaler.fit_transform(X_train_boruta)\n",
        "X_train_scaled_boruta = pd.DataFrame(X_train_scaled_boruta, columns=boruta_features)\n",
        "\n",
        "# 定义TabNet基础配置\n",
        "def get_tabnet_config():\n",
        "    return {\n",
        "        'n_d': 16,\n",
        "        'n_a': 16,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.3,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=2e-2),\n",
        "        'scheduler_params': {\"step_size\":10, \"gamma\":0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 对每种采样方法训练TabNet模型\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== {method} ===\")\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_boruta.values\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 存储每个fold的预测结果\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    # 执行交叉验证\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        tabnet_model = TabNetClassifier(**get_tabnet_config())\n",
        "        tabnet_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=100,\n",
        "            patience=15,\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128\n",
        "        )\n",
        "\n",
        "        fold_preds = tabnet_model.predict(X_fold_val)\n",
        "        fold_pred_probas = tabnet_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 计算评估指标\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet with Boruta Features ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_y_true, all_y_pred))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - TabNet with Boruta Features ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "# 创建结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison (TabNet with Boruta Features):\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods - TabNet (Boruta Selected Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存Boruta特征选择结果和模型评估结果\n",
        "results = {\n",
        "    'boruta_features': boruta_features,\n",
        "    'metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('tabnet_boruta_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "VdkqgCqOUZ5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "f-AH34Ka9BTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE 4"
      ],
      "metadata": {
        "id": "75xteaVCUlB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 准备数据 - 使用所有特征\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled = np.array(X_train_scaled)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "def objective(trial, X, y):\n",
        "    # 简化的超参数搜索空间\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=50,  # 减少训练轮次\n",
        "            patience=10,    # 减少patience\n",
        "            batch_size=512, # 减小batch size\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"\\n=== Optimizing Baseline Model (All Features) ===\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: objective(trial, X_train_scaled, y_train),\n",
        "              n_trials=15,  # 使用15次试验\n",
        "              show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_config = {\n",
        "    'n_d': study.best_params['n_d'],\n",
        "    'n_a': study.best_params['n_a'],\n",
        "    'n_steps': study.best_params['n_steps'],\n",
        "    'gamma': study.best_params['gamma'],\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'momentum': 0.02,\n",
        "    'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'step_size': 10,\n",
        "        'gamma': 0.9\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "    'mask_type': 'sparsemax',\n",
        "    'device_name': 'auto'\n",
        "}\n",
        "\n",
        "# 评估最终模型\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_proba = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_scaled, y_train)):\n",
        "    print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "    X_fold_train = X_train_scaled[train_idx]\n",
        "    y_fold_train = y_train[train_idx]\n",
        "    X_fold_val = X_train_scaled[val_idx]\n",
        "    y_fold_val = y_train[val_idx]\n",
        "\n",
        "    best_model = TabNetClassifier(**best_config)\n",
        "    best_model.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_val, y_fold_val)],\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=512,\n",
        "        virtual_batch_size=64\n",
        "    )\n",
        "\n",
        "    fold_preds = best_model.predict(X_fold_val)\n",
        "    fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "    all_y_true.extend(y_fold_val)\n",
        "    all_y_pred.extend(fold_preds)\n",
        "    all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "# 计算评估指标\n",
        "all_y_true = np.array(all_y_true)\n",
        "all_y_pred = np.array(all_y_pred)\n",
        "all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "precision = precision_score(all_y_true, all_y_pred)\n",
        "recall = recall_score(all_y_true, all_y_pred)\n",
        "f1 = f1_score(all_y_true, all_y_pred)\n",
        "roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "print(\"\\nModel Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix - Baseline TabNet (All Features)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "# 打印分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_y_true, all_y_pred))\n",
        "\n",
        "# 绘制ROC曲线\n",
        "fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'Baseline (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Baseline TabNet (All Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 绘制优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "plt.xlabel('Trial Number')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.title('Optimization History (Baseline)')\n",
        "plt.show()\n",
        "\n",
        "# 保存结果\n",
        "results = {\n",
        "    'best_params': study.best_params,\n",
        "    'best_score': study.best_value,\n",
        "    'metrics': {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('tabnet_baseline_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "zxjfso8YUuCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The remaining three balance methods"
      ],
      "metadata": {
        "id": "oERRCC3h7kFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def objective(trial, X, y, sampler=None):\n",
        "    # 定义超参数搜索空间\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    if sampler is not None:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X, y\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X_resampled, y_resampled):\n",
        "        X_train_fold = X_resampled[train_idx]\n",
        "        y_train_fold = y_resampled[train_idx]\n",
        "        X_val_fold = X_resampled[val_idx]\n",
        "        y_val_fold = y_resampled[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=512,\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 准备数据\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train_scaled = np.array(X_train_scaled)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 存储结果\n",
        "best_params = {}\n",
        "metrics_data = []\n",
        "\n",
        "# 对每种采样方法进行优化\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_scaled, y_train, sampler),\n",
        "                  n_trials=15,\n",
        "                  show_progress_bar=True)\n",
        "\n",
        "    best_params[method] = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练最终模型\n",
        "    best_config = {\n",
        "        'n_d': study.best_params['n_d'],\n",
        "        'n_a': study.best_params['n_a'],\n",
        "        'n_steps': study.best_params['n_steps'],\n",
        "        'gamma': study.best_params['gamma'],\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "    # 应用采样方法\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    # 评估最终模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        best_model = TabNetClassifier(**best_config)\n",
        "        best_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=512,\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        fold_preds = best_model.predict(X_fold_val)\n",
        "        fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 计算评估指标\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    metrics_data.append({\n",
        "        'Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - TabNet ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制优化历史\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "    plt.xlabel('Trial Number')\n",
        "    plt.ylabel('ROC-AUC Score')\n",
        "    plt.title(f'Optimization History ({method})')\n",
        "    plt.show()\n",
        "\n",
        "# 创建结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).set_index('Method')\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 保存结果\n",
        "results = {\n",
        "    'best_params': best_params,\n",
        "    'metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "with open('tabnet_balance_methods_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "5CYH7dui7qE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4"
      ],
      "metadata": {
        "id": "LA6EGAFJUKWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE cannot run, but the other three can produce results normally, which can be used as a reference; SMOTE is the only one in the back cell"
      ],
      "metadata": {
        "id": "Fxoi0xid6ORx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 使用已经获得的top 10 features\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_train_scaled_top = pd.DataFrame(X_train_scaled_top, columns=top_features)\n",
        "\n",
        "# 定义Optuna目标函数\n",
        "def objective(trial, X, y):\n",
        "    # 定义超参数搜索空间\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 64),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 64),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
        "        'n_independent': trial.suggest_int('n_independent', 1, 5),\n",
        "        'n_shared': trial.suggest_int('n_shared', 1, 5),\n",
        "        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': trial.suggest_int('step_size', 5, 20),\n",
        "            'gamma': trial.suggest_float('scheduler_gamma', 0.8, 0.95)\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=100,\n",
        "            patience=15,\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 存储每种方法的最佳参数和结果\n",
        "best_params = {}\n",
        "metrics_data = []\n",
        "\n",
        "# 对每种采样方法进行优化\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_top.values\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=20,  # 可以根据需要调整试验次数\n",
        "                  show_progress_bar=True)\n",
        "\n",
        "    best_params[method] = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练最终模型\n",
        "    best_config = {\n",
        "        'n_d': study.best_params['n_d'],\n",
        "        'n_a': study.best_params['n_a'],\n",
        "        'n_steps': study.best_params['n_steps'],\n",
        "        'gamma': study.best_params['gamma'],\n",
        "        'n_independent': study.best_params['n_independent'],\n",
        "        'n_shared': study.best_params['n_shared'],\n",
        "        'momentum': study.best_params['momentum'],\n",
        "        'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "        'scheduler_params': {\n",
        "            'step_size': study.best_params['step_size'],\n",
        "            'gamma': study.best_params['scheduler_gamma']\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "    # 存储每个fold的预测结果\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    # 执行交叉验证\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        # 使用最佳参数训练模型\n",
        "        best_model = TabNetClassifier(**best_config)\n",
        "        best_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=100,\n",
        "            patience=15,\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128\n",
        "        )\n",
        "\n",
        "        fold_preds = best_model.predict(X_fold_val)\n",
        "        fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 转换为numpy数组\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    # 计算评估指标\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet ({method})\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_y_true, all_y_pred))\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - Optimized TabNet ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 存储评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 绘制优化历史\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "    plt.xlabel('Trial Number')\n",
        "    plt.ylabel('ROC-AUC Score')\n",
        "    plt.title(f'Optimization History ({method})')\n",
        "    plt.show()\n",
        "\n",
        "# 创建并显示结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison (Optimized TabNet):\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best ROC-AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods - Optimized TabNet (Top 10 Features)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存最佳参数和结果\n",
        "results = {\n",
        "    'best_params': best_params,\n",
        "    'metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "# 保存结果到文件\n",
        "import json\n",
        "with open('tabnet_optimization_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "EMK7KOmnUcp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 使用已经获得的top 10 features\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_train_scaled_top = pd.DataFrame(X_train_scaled_top, columns=top_features)\n",
        "\n",
        "def objective(trial, X, y):\n",
        "\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 0.01, 0.1)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    model = TabNetClassifier(**param)\n",
        "\n",
        "    try:\n",
        "        model.fit(\n",
        "            X_train_split, y_train_split,\n",
        "            eval_set=[(X_val_split, y_val_split)],\n",
        "            max_epochs=30,  # 减少训练轮数\n",
        "            patience=5,     # 减少早停轮数\n",
        "            batch_size=2048,  # 增大批量\n",
        "            virtual_batch_size=256\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_split)[:, 1]\n",
        "        score = roc_auc_score(y_val_split, y_pred)\n",
        "        return score\n",
        "    except Exception as e:\n",
        "        print(f\"Trial failed: {e}\")\n",
        "        return 0  # 返回一个很差的分数\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)  # 只使用最常用的两种重采样方法\n",
        "}\n",
        "\n",
        "# 存储结果\n",
        "best_params = {}\n",
        "metrics_data = []\n",
        "start_time = datetime.now()\n",
        "\n",
        "# 对每种采样方法进行优化\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "    print(f\"Start time: {datetime.now()}\")\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_top.values\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 创建和运行优化研究\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "        n_trials=10,  # 减少试验次数\n",
        "        timeout=1800,  # 设置30分钟超时\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    best_params[method] = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练最终模型\n",
        "    best_config = {\n",
        "        'n_d': study.best_params['n_d'],\n",
        "        'n_a': study.best_params['n_a'],\n",
        "        'n_steps': study.best_params['n_steps'],\n",
        "        'gamma': study.best_params['gamma'],\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "    # 使用train_test_split进行最终评估\n",
        "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "        X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        "    )\n",
        "\n",
        "    # 训练最终模型\n",
        "    final_model = TabNetClassifier(**best_config)\n",
        "    final_model.fit(\n",
        "        X_train_final, y_train_final,\n",
        "        eval_set=[(X_test_final, y_test_final)],\n",
        "        max_epochs=50,  # 最终模型使用更多轮数\n",
        "        patience=10,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    # 预测和评估\n",
        "    y_pred = final_model.predict(X_test_final)\n",
        "    y_pred_proba = final_model.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "    # 计算指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy_score(y_test_final, y_pred),\n",
        "        'Precision': precision_score(y_test_final, y_pred),\n",
        "        'Recall': recall_score(y_test_final, y_pred),\n",
        "        'F1 Score': f1_score(y_test_final, y_pred),\n",
        "        'ROC AUC': roc_auc_score(y_test_final, y_pred_proba)\n",
        "    })\n",
        "\n",
        "    print(f\"Time elapsed for {method}: {datetime.now() - start_time}\")\n",
        "\n",
        "# 创建结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 绘制性能比较图\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics_df.set_index('Balancing Method')[['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']].plot(kind='bar')\n",
        "plt.title('Comparison of Balancing Methods - Optimized TabNet')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存结果\n",
        "results = {\n",
        "    'best_params': best_params,\n",
        "    'metrics': metrics_df.to_dict(),\n",
        "    'total_time': str(datetime.now() - start_time)\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('tabnet_efficient_optimization_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "hrtiyCsoDuDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "smote"
      ],
      "metadata": {
        "id": "OBMpEZhd59K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 假设X_train_scaled_top和y_train已经准备好\n",
        "# 如果没有，需要先进行特征选择和标准化\n",
        "# X_train_top = X_train[top_features]\n",
        "# X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "# X_train_scaled_top = pd.DataFrame(X_train_scaled_top, columns=top_features)\n",
        "\n",
        "def objective(trial, X, y):\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 64),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 64),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
        "        'n_independent': trial.suggest_int('n_independent', 1, 5),\n",
        "        'n_shared': trial.suggest_int('n_shared', 1, 5),\n",
        "        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': trial.suggest_int('step_size', 5, 20),\n",
        "            'gamma': trial.suggest_float('scheduler_gamma', 0.8, 0.95)\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 增加到5折交叉验证\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=100,\n",
        "            patience=20,  # 增加patience\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 应用SMOTE\n",
        "print(\"Applying SMOTE...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_scaled_top, y_train)\n",
        "X_resampled = np.array(X_resampled)\n",
        "y_resampled = np.array(y_resampled)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"\\nStarting Optuna optimization...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "              n_trials=50,  # 增加到50次试验\n",
        "              show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nBest parameters:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_config = {\n",
        "    'n_d': study.best_params['n_d'],\n",
        "    'n_a': study.best_params['n_a'],\n",
        "    'n_steps': study.best_params['n_steps'],\n",
        "    'gamma': study.best_params['gamma'],\n",
        "    'n_independent': study.best_params['n_independent'],\n",
        "    'n_shared': study.best_params['n_shared'],\n",
        "    'momentum': study.best_params['momentum'],\n",
        "    'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'step_size': study.best_params['step_size'],\n",
        "        'gamma': study.best_params['scheduler_gamma']\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "    'mask_type': 'sparsemax',\n",
        "    'device_name': 'auto'\n",
        "}\n",
        "\n",
        "# 存储每个fold的预测结果\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "all_y_pred_proba = []\n",
        "\n",
        "# 执行交叉验证\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 使用5折交叉验证\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "    print(f\"Training fold {fold + 1}/5...\")\n",
        "\n",
        "    X_fold_train = X_resampled[train_idx]\n",
        "    y_fold_train = y_resampled[train_idx]\n",
        "    X_fold_val = X_resampled[val_idx]\n",
        "    y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "    best_model = TabNetClassifier(**best_config)\n",
        "    best_model.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_val, y_fold_val)],\n",
        "        max_epochs=100,\n",
        "        patience=20,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    fold_preds = best_model.predict(X_fold_val)\n",
        "    fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "    all_y_true.extend(y_fold_val)\n",
        "    all_y_pred.extend(fold_preds)\n",
        "    all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "# 计算评估指标\n",
        "all_y_true = np.array(all_y_true)\n",
        "all_y_pred = np.array(all_y_pred)\n",
        "all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "precision = precision_score(all_y_true, all_y_pred)\n",
        "recall = recall_score(all_y_true, all_y_pred)\n",
        "f1 = f1_score(all_y_true, all_y_pred)\n",
        "roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "# 打印评估结果\n",
        "print(\"\\nModel Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix - TabNet with SMOTE\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "# 打印分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_y_true, all_y_pred))\n",
        "\n",
        "# 绘制ROC曲线\n",
        "fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'SMOTE (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Optimized TabNet with SMOTE')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 绘制优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "plt.xlabel('Trial Number')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.title('Optimization History (SMOTE)')\n",
        "plt.show()\n",
        "\n",
        "# 保存最佳参数和结果\n",
        "results = {\n",
        "    'best_params': study.best_params,\n",
        "    'best_score': study.best_value,\n",
        "    'metrics': {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "}\n",
        "\n",
        "# 保存结果到文件\n",
        "import json\n",
        "with open('tabnet_smote_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "wHG5qKsi5_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def objective(trial, X, y):\n",
        "    # 简化的超参数搜索空间\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),  # 缩小范围\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),  # 缩小范围\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),  # 缩小范围\n",
        "        'gamma': 1.5,  # 固定值\n",
        "        'n_independent': 2,  # 固定值\n",
        "        'n_shared': 2,  # 固定值\n",
        "        'momentum': 0.02,  # 固定值\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,  # 固定值\n",
        "            'gamma': 0.9  # 固定值\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 减少到3折\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=50,  # 减少训练轮次\n",
        "            patience=10,  # 减少patience\n",
        "            batch_size=512,  # 减小batch size\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 应用SMOTE\n",
        "print(\"Applying SMOTE...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_scaled_top, y_train)\n",
        "X_resampled = np.array(X_resampled)\n",
        "y_resampled = np.array(y_resampled)\n",
        "\n",
        "# 运行Optuna优化\n",
        "print(\"\\nStarting Optuna optimization...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "              n_trials=20,  # 减少试验次数\n",
        "              show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nBest parameters:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_config = {\n",
        "    'n_d': study.best_params['n_d'],\n",
        "    'n_a': study.best_params['n_a'],\n",
        "    'n_steps': study.best_params['n_steps'],\n",
        "    'gamma': 1.5,\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'momentum': 0.02,\n",
        "    'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'step_size': 10,\n",
        "        'gamma': 0.9\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "    'mask_type': 'sparsemax',\n",
        "    'device_name': 'auto'\n",
        "}\n",
        "\n",
        "# 训练最终模型\n",
        "final_model = TabNetClassifier(**best_config)\n",
        "final_model.fit(\n",
        "    X_resampled, y_resampled,\n",
        "    eval_set=[(X_resampled, y_resampled)],\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=64\n",
        ")\n",
        "\n",
        "# 获取预测结果\n",
        "y_pred = final_model.predict(X_resampled)\n",
        "y_pred_proba = final_model.predict_proba(X_resampled)[:, 1]\n",
        "\n",
        "# 保存模型和结果\n",
        "results = {\n",
        "    'best_params': study.best_params,\n",
        "    'best_score': study.best_value\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('fast_tabnet_smote_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "DaypBRvlO9ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameters:\n",
        "{'n_d': 23, 'n_a': 32, 'n_steps': 3, 'lambda_sparse': 2.298427358180666e-06, 'learning_rate': 0.0063223512856359545}"
      ],
      "metadata": {
        "id": "qqZosdE21beT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# 计算评估指标\n",
        "y_pred = final_model.predict(X_resampled)\n",
        "y_pred_proba = final_model.predict_proba(X_resampled)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "f1 = f1_score(y_resampled, y_pred)\n",
        "roc_auc = roc_auc_score(y_resampled, y_pred_proba)\n",
        "\n",
        "# 打印评估指标\n",
        "print(\"\\nModel Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix - TabNet with SMOTE\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "# 打印分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_resampled, y_pred))\n",
        "\n",
        "# 绘制ROC曲线\n",
        "fpr, tpr, _ = roc_curve(y_resampled, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'SMOTE (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Optimized TabNet with SMOTE')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 绘制优化历史\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "plt.xlabel('Trial Number')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.title('Optimization History (SMOTE)')\n",
        "plt.show()\n",
        "\n",
        "# 保存完整结果\n",
        "results = {\n",
        "    'best_params': study.best_params,\n",
        "    'best_score': study.best_value,\n",
        "    'metrics': {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "}\n",
        "\n",
        "# 保存结果到文件\n",
        "with open('tabnet_smote_visualization_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "GXtzzlAr1iJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA 4种"
      ],
      "metadata": {
        "id": "hzve4iFAUdtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 首先进行Boruta特征选择\n",
        "print(\"Starting Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    max_iter=50  # 减少迭代次数以加快速度\n",
        ")\n",
        "\n",
        "# 准备数据用于Boruta\n",
        "X_for_boruta = X_train.values\n",
        "y_for_boruta = y_train.values\n",
        "\n",
        "# 运行Boruta特征选择\n",
        "boruta_selector.fit(X_for_boruta, y_for_boruta)\n",
        "\n",
        "# 获取选中的特征\n",
        "feature_names = X_train.columns.tolist()\n",
        "boruta_features = [feature for feature, selected in zip(feature_names, boruta_selector.support_) if selected]\n",
        "\n",
        "print(f\"\\nBoruta selected {len(boruta_features)} features:\")\n",
        "print(boruta_features)\n",
        "\n",
        "# 使用boruta筛选出的特征\n",
        "X_train_boruta = X_train[boruta_features]\n",
        "X_train_scaled_boruta = scaler.fit_transform(X_train_boruta)\n",
        "X_train_scaled_boruta = pd.DataFrame(X_train_scaled_boruta, columns=boruta_features)\n",
        "\n",
        "# 简化的Optuna目标函数\n",
        "def objective(trial, X, y):\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),  # 缩小范围\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),  # 缩小范围\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),  # 缩小范围\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),  # 缩小范围\n",
        "        'n_independent': 2,  # 固定值\n",
        "        'n_shared': 2,  # 固定值\n",
        "        'momentum': 0.02,  # 固定值\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,  # 固定值\n",
        "            'gamma': 0.9  # 固定值\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    # 减少交叉验证折数\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=50,  # 减少训练轮次\n",
        "            patience=10,  # 减少patience\n",
        "            batch_size=512,  # 减小batch size\n",
        "            virtual_batch_size=64  # 减小virtual batch size\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'SMOTE': SMOTE(random_state=42)  # 只保留SMOTE方法来加快速度\n",
        "}\n",
        "\n",
        "# 存储结果\n",
        "best_params = {}\n",
        "metrics_data = []\n",
        "\n",
        "# 对每种采样方法进行优化\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_boruta.values\n",
        "        y_resampled = y_train.values\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=15,  # 减少试验次数\n",
        "                  show_progress_bar=True)\n",
        "\n",
        "    best_params[method] = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练最终模型\n",
        "    best_config = {\n",
        "        'n_d': study.best_params['n_d'],\n",
        "        'n_a': study.best_params['n_a'],\n",
        "        'n_steps': study.best_params['n_steps'],\n",
        "        'gamma': study.best_params['gamma'],\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "    # 评估最终模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        best_model = TabNetClassifier(**best_config)\n",
        "        best_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=512,\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        fold_preds = best_model.predict(X_fold_val)\n",
        "        fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 计算评估指标\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    # 存储评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet with Boruta Features ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - TabNet with Boruta Features ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# 保存结果\n",
        "results = {\n",
        "    'boruta_features': boruta_features,\n",
        "    'best_params': best_params,\n",
        "    'metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "# 保存到文件\n",
        "with open('fast_tabnet_boruta_optuna_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "ZNYMP3_FUdtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No classification report is output. The Excel result is derived from the confusion matrix. The following code does not need to be run to output"
      ],
      "metadata": {
        "id": "bZ-MfnSgoyKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undersampling和Oversampling"
      ],
      "metadata": {
        "id": "Jsa4Zz1mxutm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 定义Optuna目标函数（简化版）\n",
        "def objective(trial, X, y):\n",
        "    param = {\n",
        "        'n_d': trial.suggest_int('n_d', 8, 32),\n",
        "        'n_a': trial.suggest_int('n_a', 8, 32),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax'\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(X, y):\n",
        "        X_train_fold = X[train_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "\n",
        "        model = TabNetClassifier(\n",
        "            device_name='auto',\n",
        "            **param\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            eval_set=[(X_val_fold, y_val_fold)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=512,\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
        "        score = roc_auc_score(y_val_fold, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42)\n",
        "}\n",
        "\n",
        "# 存储结果\n",
        "best_params = {}\n",
        "metrics_data = []\n",
        "\n",
        "# 对两种采样方法进行优化\n",
        "for method, sampler in samplers.items():\n",
        "    print(f\"\\n=== Optimizing {method} ===\")\n",
        "\n",
        "    # 应用采样方法\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "    X_resampled = np.array(X_resampled)\n",
        "    y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 运行Optuna优化\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_resampled, y_resampled),\n",
        "                  n_trials=15,\n",
        "                  show_progress_bar=True)\n",
        "\n",
        "    best_params[method] = study.best_params\n",
        "    print(f\"\\nBest parameters for {method}:\")\n",
        "    print(study.best_params)\n",
        "    print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
        "\n",
        "    # 使用最佳参数训练最终模型\n",
        "    best_config = {\n",
        "        'n_d': study.best_params['n_d'],\n",
        "        'n_a': study.best_params['n_a'],\n",
        "        'n_steps': study.best_params['n_steps'],\n",
        "        'gamma': study.best_params['gamma'],\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'lambda_sparse': study.best_params['lambda_sparse'],\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': study.best_params['learning_rate']},\n",
        "        'scheduler_params': {\n",
        "            'step_size': 10,\n",
        "            'gamma': 0.9\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "\n",
        "    # 评估最终模型\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "    all_y_pred_proba = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_resampled, y_resampled)):\n",
        "        print(f\"Training fold {fold + 1}/3...\")\n",
        "\n",
        "        X_fold_train = X_resampled[train_idx]\n",
        "        y_fold_train = y_resampled[train_idx]\n",
        "        X_fold_val = X_resampled[val_idx]\n",
        "        y_fold_val = y_resampled[val_idx]\n",
        "\n",
        "        best_model = TabNetClassifier(**best_config)\n",
        "        best_model.fit(\n",
        "            X_fold_train, y_fold_train,\n",
        "            eval_set=[(X_fold_val, y_fold_val)],\n",
        "            max_epochs=50,\n",
        "            patience=10,\n",
        "            batch_size=512,\n",
        "            virtual_batch_size=64\n",
        "        )\n",
        "\n",
        "        fold_preds = best_model.predict(X_fold_val)\n",
        "        fold_pred_probas = best_model.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "        all_y_true.extend(y_fold_val)\n",
        "        all_y_pred.extend(fold_preds)\n",
        "        all_y_pred_proba.extend(fold_pred_probas)\n",
        "\n",
        "    # 计算评估指标\n",
        "    all_y_true = np.array(all_y_true)\n",
        "    all_y_pred = np.array(all_y_pred)\n",
        "    all_y_pred_proba = np.array(all_y_pred_proba)\n",
        "\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
        "\n",
        "    # 存储评估指标\n",
        "    metrics_data.append({\n",
        "        'Balancing Method': method,\n",
        "        'Best ROC-AUC': study.best_value,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    # 绘制混淆矩阵\n",
        "    conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - TabNet with Boruta Features ({method})')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(all_y_true, all_y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'{method} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - TabNet with Boruta Features ({method})')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 绘制优化历史\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot([trial.number for trial in study.trials], [trial.value for trial in study.trials], marker='o')\n",
        "    plt.xlabel('Trial Number')\n",
        "    plt.ylabel('ROC-AUC Score')\n",
        "    plt.title(f'Optimization History ({method})')\n",
        "    plt.show()\n",
        "\n",
        "# 创建结果比较表\n",
        "metrics_df = pd.DataFrame(metrics_data).sort_values(by='ROC AUC', ascending=False)\n",
        "print(\"\\nFinal Results Comparison:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# 保存结果\n",
        "results = {\n",
        "    'best_params': best_params,\n",
        "    'metrics': metrics_df.to_dict()\n",
        "}\n",
        "\n",
        "with open('tabnet_under_over_sampling_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "UamH2GyaxoZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "OJKDwbEUJB2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASELINE 4种"
      ],
      "metadata": {
        "id": "xKDonb-lUveY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    roc_curve\n",
        ")\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\\nPreparing test data...\")\n",
        "\n",
        "# 确保特征列的一致性\n",
        "feature_columns = [col for col in selected_columns if col != 'is_canceled']\n",
        "\n",
        "# 准备数据\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 修改：准备训练数据\n",
        "# 使用整体训练集（包含H1和H2的组合）\n",
        "X_train = pd.concat([H1_train, H2_train])[feature_columns]\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "y_train = pd.concat([H1_train, H2_train])['is_canceled'].values\n",
        "\n",
        "# H2测试集数据准备\n",
        "X_H2_test = H2_test[feature_columns]\n",
        "X_H2_test_scaled = scaler.transform(X_H2_test)\n",
        "y_H2_test = H2_test['is_canceled'].values\n",
        "\n",
        "# H1测试集数据准备\n",
        "X_H1_test = H1_test[feature_columns]\n",
        "X_H1_test_scaled = scaler.transform(X_H1_test)\n",
        "y_H1_test = H1_test['is_canceled'].values\n",
        "\n",
        "# 确认数据形状\n",
        "print(f\"Training features: {feature_columns}\")\n",
        "print(f\"Number of features: {len(feature_columns)}\")\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"H2 test set shape: {X_H2_test_scaled.shape}\")\n",
        "print(f\"H1 test set shape: {X_H1_test_scaled.shape}\")\n",
        "\n",
        "# 定义最佳配置（保持不变）\n",
        "best_configs = {\n",
        "    'No Sampling': {\n",
        "        'n_d': 28,\n",
        "        'n_a': 27,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.3091649976992965,\n",
        "        'lambda_sparse': 9.421983411532464e-06,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.01880243119491898},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_d': 24,\n",
        "        'n_a': 25,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.2008839910132765,\n",
        "        'lambda_sparse': 0.00033250842281105973,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.015659252876444294},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_d': 24,\n",
        "        'n_a': 17,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.1198251412675357,\n",
        "        'lambda_sparse': 4.621721552688596e-06,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.02327241095705265},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'SMOTE': {\n",
        "        'n_d': 26,\n",
        "        'n_a': 15,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.127935814907823,\n",
        "        'lambda_sparse': 0.00010489631802618515,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.026034337812760464},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "results_h1 = []\n",
        "results_h2 = []\n",
        "\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 对每种方法训练和评估模型\n",
        "for method, config in best_configs.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training and evaluating {method} model\")\n",
        "    print('='*50)\n",
        "\n",
        "    # 使用相应的采样方法处理训练数据\n",
        "    sampler = samplers[method]\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled\n",
        "        y_resampled = y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    print(f\"Training data shape after {method}: {X_resampled.shape}\")\n",
        "\n",
        "    # 训练模型\n",
        "    model = TabNetClassifier(**config)\n",
        "    model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=512,\n",
        "        virtual_batch_size=64\n",
        "    )\n",
        "\n",
        "    # 评估 H2 测试集\n",
        "    y_pred_h2 = model.predict(X_H2_test_scaled)\n",
        "    y_pred_proba_h2 = model.predict_proba(X_H2_test_scaled)[:, 1]\n",
        "\n",
        "    results_h2.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H2_test, y_pred_h2),\n",
        "        'Precision': precision_score(y_H2_test, y_pred_h2),\n",
        "        'Recall': recall_score(y_H2_test, y_pred_h2),\n",
        "        'F1 Score': f1_score(y_H2_test, y_pred_h2),\n",
        "        'ROC AUC': roc_auc_score(y_H2_test, y_pred_proba_h2)\n",
        "    })\n",
        "\n",
        "    # 评估 H1 测试集和其他评估代码保持不变...\n",
        "\n",
        "    print(\"\\nH1 Test Set Results Summary:\")\n",
        "    print(\"=\"*80)\n",
        "    print(results_df_h1)\n",
        "\n",
        "# 保存结果部分保持不变..."
      ],
      "metadata": {
        "id": "CgrUMw2TUrnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_H2_test_scaled shape: {X_H2_test_scaled.shape}\")\n",
        "print(f\"y_H2_test shape: {y_H2_test.shape}\")\n",
        "print(f\"X_H1_test_scaled shape: {X_H1_test_scaled.shape}\")\n",
        "print(f\"y_H1_test shape: {y_H1_test.shape}\")"
      ],
      "metadata": {
        "id": "L2vbdp5WV44v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "update version"
      ],
      "metadata": {
        "id": "nHUOWUu1T_Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\\nPreparing test data...\")\n",
        "\n",
        "\n",
        "\n",
        "# 首先确保特征列的一致性\n",
        "feature_columns = [col for col in selected_columns if col != 'is_canceled']\n",
        "\n",
        "# 准备测试数据\n",
        "X_H2_test_scaled = scaler.transform(H2_test[feature_columns])\n",
        "y_H2_test = np.array(H2_test['is_canceled'])  # 直接转换为numpy数组\n",
        "\n",
        "X_H1_test_scaled = scaler.transform(H1_test[feature_columns])\n",
        "y_H1_test = np.array(H1_test['is_canceled'])  # 直接转换为numpy数组\n",
        "\n",
        "# 准备训练数据\n",
        "X_train_scaled = scaler.transform(X_train[feature_columns])\n",
        "if isinstance(y_train, pd.Series) or isinstance(y_train, pd.DataFrame):\n",
        "    y_train = y_train.values\n",
        "else:\n",
        "    y_train = np.array(y_train)  # 确保是numpy数组\n",
        "\n",
        "\n",
        "# 定义最佳配置\n",
        "best_configs = {\n",
        "    'No Sampling': {\n",
        "        'n_d': 28,\n",
        "        'n_a': 27,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.3091649976992965,\n",
        "        'lambda_sparse': 9.421983411532464e-06,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.01880243119491898},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_d': 24,\n",
        "        'n_a': 25,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.2008839910132765,\n",
        "        'lambda_sparse': 0.00033250842281105973,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.015659252876444294},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_d': 24,\n",
        "        'n_a': 17,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.1198251412675357,\n",
        "        'lambda_sparse': 4.621721552688596e-06,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.02327241095705265},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'SMOTE': {\n",
        "        'n_d': 26,\n",
        "        'n_a': 15,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.127935814907823,\n",
        "        'lambda_sparse': 0.00010489631802618515,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.026034337812760464},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "results_h1 = []\n",
        "results_h2 = []\n",
        "\n",
        "# 对每种采样方法训练和评估模型\n",
        "for method, config in best_configs.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training and evaluating {method} model\")\n",
        "    print('='*50)\n",
        "\n",
        "    # 使用相应的采样方法处理训练数据\n",
        "    sampler = samplers[method]\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled\n",
        "        y_resampled = y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 训练模型\n",
        "    model = TabNetClassifier(**config)\n",
        "    model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=512,\n",
        "        virtual_batch_size=64\n",
        "    )\n",
        "\n",
        "    # 评估 H2 测试集\n",
        "    y_pred_h2 = model.predict(X_H2_test_scaled)\n",
        "    y_pred_proba_h2 = model.predict_proba(X_H2_test_scaled)[:, 1]\n",
        "\n",
        "    results_h2.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H2_test, y_pred_h2),\n",
        "        'Precision': precision_score(y_H2_test, y_pred_h2),\n",
        "        'Recall': recall_score(y_H2_test, y_pred_h2),\n",
        "        'F1 Score': f1_score(y_H2_test, y_pred_h2),\n",
        "        'ROC AUC': roc_auc_score(y_H2_test, y_pred_proba_h2)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH2 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H2_test, y_pred_h2))\n",
        "\n",
        "    # 评估 H1 测试集\n",
        "    y_pred_h1 = model.predict(X_H1_test_scaled)\n",
        "    y_pred_proba_h1 = model.predict_proba(X_H1_test_scaled)[:, 1]\n",
        "\n",
        "    results_h1.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H1_test, y_pred_h1),\n",
        "        'Precision': precision_score(y_H1_test, y_pred_h1),\n",
        "        'Recall': recall_score(y_H1_test, y_pred_h1),\n",
        "        'F1 Score': f1_score(y_H1_test, y_pred_h1),\n",
        "        'ROC AUC': roc_auc_score(y_H1_test, y_pred_proba_h1)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH1 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H1_test, y_pred_h1))\n",
        "\n",
        "# 创建结果DataFrame\n",
        "results_df_h2 = pd.DataFrame(results_h2).set_index('Method')\n",
        "results_df_h1 = pd.DataFrame(results_h1).set_index('Method')\n",
        "\n",
        "# 显示结果\n",
        "print(\"\\nH2 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h2)\n",
        "\n",
        "print(\"\\nH1 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h1)\n",
        "\n",
        "# 绘制结果对比图\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "results_df_h2.plot(kind='bar', ax=ax1)\n",
        "ax1.set_title('H2 Test Set Performance')\n",
        "ax1.set_xticklabels(results_df_h2.index, rotation=45)\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "results_df_h1.plot(kind='bar', ax=ax2)\n",
        "ax2.set_title('H1 Test Set Performance')\n",
        "ax2.set_xticklabels(results_df_h1.index, rotation=45)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存结果\n",
        "test_results = {\n",
        "    'features_used': selected_columns,\n",
        "    'H1_test_results': results_df_h1.to_dict(),\n",
        "    'H2_test_results': results_df_h2.to_dict(),\n",
        "    'best_configs': {k: {kk: str(vv) if isinstance(vv, type) else vv\n",
        "                        for kk, vv in v.items()}\n",
        "                    for k, v in best_configs.items()}\n",
        "}\n",
        "\n",
        "with open('tabnet_final_test_results.json', 'w') as f:\n",
        "    json.dump(test_results, f, indent=4)"
      ],
      "metadata": {
        "id": "q5UBaWp4T0cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance top10 4（H2+H1 test set)"
      ],
      "metadata": {
        "id": "OquZkfdoUK2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "import torch\n",
        "\n",
        "print(\"\\nUsing Top 10 Features:\", top_features)\n",
        "\n",
        "# 准备测试数据并转换为numpy数组\n",
        "X_H2_test_scaled = scaler.transform(H2_test[top_features])\n",
        "y_H2_test = H2_test['is_canceled'].values  # 转换为numpy数组\n",
        "\n",
        "X_H1_test_scaled = scaler.transform(H1_test[top_features])\n",
        "y_H1_test = H1_test['is_canceled'].values  # 转换为numpy数组\n",
        "\n",
        "# 确保训练数据也是numpy数组格式\n",
        "X_train_scaled_top = scaler.transform(X_train[top_features])  # 直接使用numpy数组\n",
        "y_train = y_train.values  # 转换为numpy数组\n",
        "\n",
        "best_configs = {\n",
        "    'SMOTE': {\n",
        "        'n_d': 24,\n",
        "        'n_a': 13,\n",
        "        'n_steps': 5,\n",
        "        'gamma': 1.199946860351268,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.03975153101157348},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Oversample': {\n",
        "        'n_d': 28,\n",
        "        'n_a': 25,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.1337063206604574,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.014560530996164776},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_d': 30,\n",
        "        'n_a': 25,\n",
        "        'n_steps': 5,\n",
        "        'gamma': 1.0982928910742795,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.05171330246308425},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'No Sampling': {\n",
        "        'n_d': 27,\n",
        "        'n_a': 15,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.0020143247588822,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.021460813045738256},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "results_h1 = []\n",
        "results_h2 = []\n",
        "\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "# 对每种采样方法训练和评估模型\n",
        "for method, config in best_configs.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training and evaluating {method} model\")\n",
        "    print('='*50)\n",
        "\n",
        "    # 使用相应的采样方法处理训练数据\n",
        "    sampler = samplers[method]\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_top\n",
        "        y_resampled = y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "        X_resampled = np.array(X_resampled)  # 确保是numpy数组\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 训练模型\n",
        "    model = TabNetClassifier(**config)\n",
        "    model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    # 评估 H2 测试集\n",
        "    y_pred_h2 = model.predict(X_H2_test_scaled)\n",
        "    y_pred_proba_h2 = model.predict_proba(X_H2_test_scaled)[:, 1]\n",
        "\n",
        "    results_h2.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H2_test, y_pred_h2),\n",
        "        'Precision': precision_score(y_H2_test, y_pred_h2),\n",
        "        'Recall': recall_score(y_H2_test, y_pred_h2),\n",
        "        'F1 Score': f1_score(y_H2_test, y_pred_h2),\n",
        "        'ROC AUC': roc_auc_score(y_H2_test, y_pred_proba_h2)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH2 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H2_test, y_pred_h2))\n",
        "\n",
        "    # 评估 H1 测试集\n",
        "    y_pred_h1 = model.predict(X_H1_test_scaled)\n",
        "    y_pred_proba_h1 = model.predict_proba(X_H1_test_scaled)[:, 1]\n",
        "\n",
        "    results_h1.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H1_test, y_pred_h1),\n",
        "        'Precision': precision_score(y_H1_test, y_pred_h1),\n",
        "        'Recall': recall_score(y_H1_test, y_pred_h1),\n",
        "        'F1 Score': f1_score(y_H1_test, y_pred_h1),\n",
        "        'ROC AUC': roc_auc_score(y_H1_test, y_pred_proba_h1)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH1 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H1_test, y_pred_h1))\n",
        "\n",
        "# 创建结果DataFrame\n",
        "results_df_h2 = pd.DataFrame(results_h2).set_index('Method')\n",
        "results_df_h1 = pd.DataFrame(results_h1).set_index('Method')\n",
        "\n",
        "# 显示结果\n",
        "print(\"\\nH2 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h2)\n",
        "\n",
        "print(\"\\nH1 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h1)\n",
        "\n",
        "# 绘制结果对比图\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "results_df_h2.plot(kind='bar', ax=ax1)\n",
        "ax1.set_title('H2 Test Set Performance (Top 10 Features)')\n",
        "ax1.set_xticklabels(results_df_h2.index, rotation=45)\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "results_df_h1.plot(kind='bar', ax=ax2)\n",
        "ax2.set_title('H1 Test Set Performance (Top 10 Features)')\n",
        "ax2.set_xticklabels(results_df_h1.index, rotation=45)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存结果\n",
        "test_results = {\n",
        "    'top_features': top_features,\n",
        "    'H1_test_results': results_df_h1.to_dict(),\n",
        "    'H2_test_results': results_df_h2.to_dict(),\n",
        "    'best_configs': {k: {kk: str(vv) if isinstance(vv, type) else vv\n",
        "                        for kk, vv in v.items()}\n",
        "                    for k, v in best_configs.items()}\n",
        "}\n",
        "\n",
        "with open('tabnet_test_results_top10.json', 'w') as f:\n",
        "    json.dump(test_results, f, indent=4)"
      ],
      "metadata": {
        "id": "uyDV6DyyUfbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross-dataset evaluation: H1 test set"
      ],
      "metadata": {
        "id": "q_lLzoJAJB2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous test set"
      ],
      "metadata": {
        "id": "z8HklOEkFcEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BORUTA 4"
      ],
      "metadata": {
        "id": "pc-1x4PNU6y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 准备测试数据并转换为numpy数组\n",
        "X_H2_test_scaled = scaler.transform(H2_test[boruta_features])\n",
        "y_H2_test = H2_test['is_canceled'].values\n",
        "\n",
        "X_H1_test_scaled = scaler.transform(H1_test[boruta_features])\n",
        "y_H1_test = H1_test['is_canceled'].values\n",
        "\n",
        "# 确保训练数据也是numpy数组格式\n",
        "X_train_scaled_boruta = scaler.transform(X_train[boruta_features])\n",
        "y_train = y_train.values\n",
        "\n",
        "# 定义每种方法的最佳参数\n",
        "best_configs = {\n",
        "    'Oversample': {\n",
        "        'n_d': 10,\n",
        "        'n_a': 31,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.197029011602726,\n",
        "        'lambda_sparse': 0.00010791353833278552,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.014912435726843684},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'Undersample': {\n",
        "        'n_d': 32,\n",
        "        'n_a': 23,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.2038363939243872,\n",
        "        'lambda_sparse': 3.4596259800340263e-05,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.013128614771897024},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'SMOTE': {\n",
        "        'n_d': 17,\n",
        "        'n_a': 32,\n",
        "        'n_steps': 3,\n",
        "        'gamma': 1.0130948574947876,\n",
        "        'lambda_sparse': 0.00017931836416446544,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.01603917398477004},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    },\n",
        "    'No Sampling': {\n",
        "        'n_d': 19,\n",
        "        'n_a': 23,\n",
        "        'n_steps': 4,\n",
        "        'gamma': 1.4992406257748137,\n",
        "        'lambda_sparse': 1.0000732710913913e-06,\n",
        "        'n_independent': 2,\n",
        "        'n_shared': 2,\n",
        "        'momentum': 0.02,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {'lr': 0.0897224699282855},\n",
        "        'scheduler_params': {'step_size': 10, 'gamma': 0.9},\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
        "        'mask_type': 'sparsemax',\n",
        "        'device_name': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 定义采样方法\n",
        "samplers = {\n",
        "    'No Sampling': None,\n",
        "    'Undersample': RandomUnderSampler(random_state=42),\n",
        "    'Oversample': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42)\n",
        "}\n",
        "\n",
        "results_h1 = []\n",
        "results_h2 = []\n",
        "\n",
        "# 对每种采样方法训练和评估模型\n",
        "for method, config in best_configs.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training and evaluating {method} model\")\n",
        "    print('='*50)\n",
        "\n",
        "    # 使用相应的采样方法处理训练数据\n",
        "    sampler = samplers[method]\n",
        "    if sampler is None:\n",
        "        X_resampled = X_train_scaled_boruta\n",
        "        y_resampled = y_train\n",
        "    else:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_boruta, y_train)\n",
        "        X_resampled = np.array(X_resampled)\n",
        "        y_resampled = np.array(y_resampled)\n",
        "\n",
        "    # 训练模型\n",
        "    model = TabNetClassifier(**config)\n",
        "    model.fit(\n",
        "        X_resampled, y_resampled,\n",
        "        max_epochs=50,\n",
        "        patience=10,\n",
        "        batch_size=512,\n",
        "        virtual_batch_size=64\n",
        "    )\n",
        "\n",
        "    # 评估 H2 测试集\n",
        "    y_pred_h2 = model.predict(X_H2_test_scaled)\n",
        "    y_pred_proba_h2 = model.predict_proba(X_H2_test_scaled)[:, 1]\n",
        "\n",
        "    results_h2.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H2_test, y_pred_h2),\n",
        "        'Precision': precision_score(y_H2_test, y_pred_h2),\n",
        "        'Recall': recall_score(y_H2_test, y_pred_h2),\n",
        "        'F1 Score': f1_score(y_H2_test, y_pred_h2),\n",
        "        'ROC AUC': roc_auc_score(y_H2_test, y_pred_proba_h2)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH2 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H2_test, y_pred_h2))\n",
        "\n",
        "    # 评估 H1 测试集\n",
        "    y_pred_h1 = model.predict(X_H1_test_scaled)\n",
        "    y_pred_proba_h1 = model.predict_proba(X_H1_test_scaled)[:, 1]\n",
        "\n",
        "    results_h1.append({\n",
        "        'Method': method,\n",
        "        'Accuracy': accuracy_score(y_H1_test, y_pred_h1),\n",
        "        'Precision': precision_score(y_H1_test, y_pred_h1),\n",
        "        'Recall': recall_score(y_H1_test, y_pred_h1),\n",
        "        'F1 Score': f1_score(y_H1_test, y_pred_h1),\n",
        "        'ROC AUC': roc_auc_score(y_H1_test, y_pred_proba_h1)\n",
        "    })\n",
        "\n",
        "    print(f\"\\nH1 Test Set Results for {method}:\")\n",
        "    print(classification_report(y_H1_test, y_pred_h1))\n",
        "\n",
        "# 创建结果DataFrame\n",
        "results_df_h2 = pd.DataFrame(results_h2).set_index('Method')\n",
        "results_df_h1 = pd.DataFrame(results_h1).set_index('Method')\n",
        "\n",
        "# 显示结果\n",
        "print(\"\\nH2 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h2)\n",
        "\n",
        "print(\"\\nH1 Test Set Results Summary:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_h1)\n",
        "\n",
        "# 绘制结果对比图\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "results_df_h2.plot(kind='bar', ax=ax1)\n",
        "ax1.set_title('H2 Test Set Performance (Boruta Features)')\n",
        "ax1.set_xticklabels(results_df_h2.index, rotation=45)\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "results_df_h1.plot(kind='bar', ax=ax2)\n",
        "ax2.set_title('H1 Test Set Performance (Boruta Features)')\n",
        "ax2.set_xticklabels(results_df_h1.index, rotation=45)\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 保存结果\n",
        "test_results = {\n",
        "    'boruta_features': boruta_features,\n",
        "    'H1_test_results': results_df_h1.to_dict(),\n",
        "    'H2_test_results': results_df_h2.to_dict(),\n",
        "    'best_configs': {k: {kk: str(vv) if isinstance(vv, type) else vv\n",
        "                        for kk, vv in v.items()}\n",
        "                    for k, v in best_configs.items()}\n",
        "}\n",
        "\n",
        "with open('tabnet_test_results_boruta.json', 'w') as f:\n",
        "    json.dump(test_results, f, indent=4)"
      ],
      "metadata": {
        "id": "-D4LBqKsU6y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forgot to output the classification report, extract and organize from the text, see the excel table"
      ],
      "metadata": {
        "id": "Em276H0g1XUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#H1+H2"
      ],
      "metadata": {
        "id": "eTXvAwP1e_4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 1.Logistic Regression\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PECU7JZJe_4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "t9ARmK3We_4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Use the new combined dataset instead of concatenating H1 and H2\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Create Logistic Regression model\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "# Perform 3-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "# Add percentage labels\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Combined Dataset Confusion Matrix with Counts and Percentages')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# Calculate overall ROC AUC\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "# Plot ROC curves for each fold\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    log_reg_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Combined Dataset (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Print dataset information\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "# Train final model and get feature importance\n",
        "final_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Create feature importance DataFrame\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Logistic Regression Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EPKdGG3Ke_4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.columns)\n"
      ],
      "metadata": {
        "id": "0aFbdJ-Ae_4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_columns)\n"
      ],
      "metadata": {
        "id": "B_H8Zglce_4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "H-qR_MQje_4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient"
      ],
      "metadata": {
        "id": "eflAFdJve_4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Initial model for feature selection\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': initial_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(initial_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "# Select top 10 features\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features:\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                        feature_importance.head(10)['Coefficient']), 1):\n",
        "    print(f\"{idx}. {feature}: {coef:.4f}\")\n",
        "\n",
        "# Prepare training data with top features\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# Create new logistic regression model\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "# 3-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Top 10 Features Model)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "overall_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nOverall ROC AUC Score: {overall_auc:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    log_reg_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Top 10 Features Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Train final model\n",
        "final_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# Get final coefficients\n",
        "final_coefficients = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "# Visualize coefficients\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=final_coefficients, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Coefficients in Top 10 Features Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print coefficients with direction\n",
        "print(\"\\nFeature Coefficients (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(final_coefficients['Feature'],\n",
        "                                        final_coefficients['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")\n",
        "\n",
        "# Print model information\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of features used: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "# Compare performance\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Top 10 Features Model ROC AUC: {overall_auc:.4f}\")\n",
        "print(f\"Full Feature Model ROC AUC: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")"
      ],
      "metadata": {
        "id": "CCjG9jAge_4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "Y_H_2fJqe_4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import shap\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Initial model for SHAP values\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Calculate SHAP values\n",
        "explainer = shap.LinearExplainer(initial_model, X_train_scaled)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# Create feature importance DataFrame\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Visualize SHAP importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train.columns, show=False)\n",
        "plt.title('SHAP Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Select top 10 features\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# Prepare selected features data\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# Create and train logistic regression\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "# 3-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (SHAP Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "overall_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nOverall ROC AUC Score: {overall_auc:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    log_reg_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves (SHAP Top 10 Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Train final model\n",
        "final_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# Get feature coefficients\n",
        "feature_coefficients = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "# Plot coefficients\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_coefficients, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Coefficients (SHAP Top 10 Features)')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of original features: {X_train.shape[1]}\")\n",
        "print(f\"Number of selected features: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "print(\"\\nFeature Coefficients (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_coefficients['Feature'],\n",
        "                                        feature_coefficients['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")\n",
        "\n",
        "# SHAP analysis for final model\n",
        "final_explainer = shap.LinearExplainer(final_model, X_train_scaled_top)\n",
        "final_shap_values = final_explainer.shap_values(X_train_scaled_top)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(final_shap_values, X_train_scaled_top,\n",
        "                 feature_names=top_features, show=False)\n",
        "plt.title('SHAP Summary Plot for Selected Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# SHAP dependence plots\n",
        "for feature in top_features[:3]:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    feature_idx = top_features.index(feature)\n",
        "    shap.dependence_plot(feature_idx, final_shap_values, X_train_scaled_top,\n",
        "                        feature_names=top_features, show=False)\n",
        "    plt.title(f'SHAP Dependence Plot for {feature}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9ZEpDaY3e_4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "VOMMD0Ybe_4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Running Boruta feature selection...\")\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Ranking': boruta_selector.ranking_,\n",
        "    'Selected': selected_feat_mask\n",
        "})\n",
        "importance_df['Importance'] = max(importance_df['Ranking']) - importance_df['Ranking'] + 1\n",
        "importance_df = importance_df[importance_df['Selected']].sort_values(by='Importance', ascending=False)\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "# Logistic regression with selected features\n",
        "log_reg_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(log_reg_model, X_train_scaled_selected, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(log_reg_model, X_train_scaled_selected, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "overall_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nOverall ROC AUC Score: {overall_auc:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    log_reg_model.fit(X_train_scaled_selected[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = log_reg_model.predict_proba(X_train_scaled_selected[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves (Boruta Selected Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Train final model\n",
        "final_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "final_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Logistic Regression (Boruta Selected Features)')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of original features: {X_train.shape[1]}\")\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "print(\"\\nFeature Coefficients (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_importance['Feature'],\n",
        "                                        feature_importance['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")"
      ],
      "metadata": {
        "id": "4oD0r_yje_4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "a4I4MfTYe_4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline"
      ],
      "metadata": {
        "id": "7l-MwnHRe_4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-4, 1e4, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model = LogisticRegression(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"Optimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params\n",
        "best_params['max_iter'] = 2000\n",
        "best_params['random_state'] = 42\n",
        "final_model = LogisticRegression(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(final_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(final_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    final_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = final_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Logistic Regression Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(\"\\nClass Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "best_logistic_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_logistic_params)"
      ],
      "metadata": {
        "id": "4-fFLgR9e_4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSOSvGkGe_4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient"
      ],
      "metadata": {
        "id": "AmF7PBMQe_4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': initial_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(initial_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features:\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                        feature_importance.head(10)['Coefficient']), 1):\n",
        "    print(f\"{idx}. {feature}: {coef:.4f}\")\n",
        "\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-4, 1e4, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42\n",
        "    }\n",
        "    model = LogisticRegression(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_top, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['max_iter'] = 2000\n",
        "best_params['random_state'] = 42\n",
        "best_model = LogisticRegression(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Top 10 Features Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    best_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Top 10 Features Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = LogisticRegression(**best_params)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "final_coefficients = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=final_coefficients, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Coefficients in Optimized Top 10 Features Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Coefficients (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(final_coefficients['Feature'],\n",
        "                                        final_coefficients['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")\n",
        "\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of features used: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "6636RInCe_4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "yFG_D9VWe_4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Get SHAP feature importance\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "explainer = shap.LinearExplainer(initial_model, X_train_scaled)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"\\nSelected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-4, 1e4, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model = LogisticRegression(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_top, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['max_iter'] = 2000\n",
        "best_params['random_state'] = 42\n",
        "best_model = LogisticRegression(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    best_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = LogisticRegression(**best_params)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "feature_coefficients = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_coefficients, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Coefficients in Optimized Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "final_explainer = shap.LinearExplainer(final_model, X_train_scaled_top)\n",
        "final_shap_values = final_explainer.shap_values(X_train_scaled_top)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(final_shap_values, X_train_scaled_top,\n",
        "                 feature_names=top_features, show=False)\n",
        "plt.title('SHAP Summary Plot for Optimized Model')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Coefficients in Optimized Model (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_coefficients['Feature'],\n",
        "                                        feature_coefficients['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")\n",
        "\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of features used: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "best_lr_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_lr_params)"
      ],
      "metadata": {
        "id": "y_y9eV60e_4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "talQV4X9e_4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "print(\"Running Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-4, 1e4, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga']),\n",
        "        'max_iter': 2000,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model = LogisticRegression(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_selected, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['max_iter'] = 2000\n",
        "best_params['random_state'] = 42\n",
        "best_model = LogisticRegression(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    best_model.fit(X_train_scaled_selected[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_selected[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = LogisticRegression(**best_params)\n",
        "final_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Coefficient': final_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(final_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Coefficients in Optimized Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel and Dataset Information:\")\n",
        "print(f\"Number of original features: {X_train.shape[1]}\")\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nFeature Coefficients (with direction):\")\n",
        "for idx, (feature, coef) in enumerate(zip(feature_importance['Feature'],\n",
        "                                        feature_importance['Coefficient']), 1):\n",
        "    sign = '+' if coef > 0 else ''\n",
        "    print(f\"{idx}. {feature}: {sign}{coef:.4f}\")\n",
        "\n",
        "best_lr_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_lr_params)"
      ],
      "metadata": {
        "id": "5jOlKSofe_4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "wcJYCZtbe_4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "_Xe5T5Dke_4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {dataset_name}\\nROC-AUC: {roc_auc:.4f}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Dataset': dataset_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'Confusion Matrix': conf_matrix,\n",
        "        'Classification Report': classification_report(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train model with best parameters\n",
        "best_params = {\n",
        "    'C': 7666.758151745492,\n",
        "    'penalty': 'l2',\n",
        "    'solver': 'liblinear',\n",
        "    'max_iter': 2000,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "best_model = LogisticRegression(**best_params)\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate on combined test set\n",
        "print(\"\\nEvaluating on Combined Test Set:\")\n",
        "combined_results = evaluate_and_visualize(y_test, y_pred, y_pred_proba, 'Combined Test Set')\n",
        "\n",
        "# Previous code remains same until masks\n",
        "# Update masks for H1 (City Hotel) and H2 (Resort Hotel)\n",
        "mask_h1 = combined_test['hotel'] == 0  # City Hotel\n",
        "y_pred_h1 = best_model.predict(X_test_scaled[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled[mask_h1])[:, 1]\n",
        "print(\"\\nEvaluating on H1 Test Set:\")\n",
        "h1_results = evaluate_and_visualize(y_test[mask_h1], y_pred_h1, y_pred_proba_h1, 'H1 Test Set')\n",
        "\n",
        "mask_h2 = combined_test['hotel'] == 1  # Resort Hotel\n",
        "y_pred_h2 = best_model.predict(X_test_scaled[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled[mask_h2])[:, 1]\n",
        "print(\"\\nEvaluating on H2 Test Set:\")\n",
        "h2_results = evaluate_and_visualize(y_test[mask_h2], y_pred_h2, y_pred_proba_h2, 'H2 Test Set')\n",
        "\n",
        "# Visualize feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.abs(best_model.coef_[0])\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Logistic Regression Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print test set information\n",
        "print(\"\\nTest Set Information:\")\n",
        "print(f\"Total Test Samples: {len(X_test)}\")\n",
        "print(f\"H1 Test Samples: {sum(mask_h1)}\")\n",
        "print(f\"H2 Test Samples: {sum(mask_h2)}\")\n",
        "print(\"\\nClass Distribution in Test Set:\")\n",
        "print(y_test.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "# Create performance comparison\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Plot performance comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "performance_metrics = performance_comparison.melt(id_vars=['Dataset'], var_name='Metric', value_name='Score')\n",
        "sns.barplot(data=performance_metrics, x='Dataset', y='Score', hue='Metric')\n",
        "plt.title('Performance Comparison Across Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uc86nttee_4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Create detailed performance comparison\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Grouped bar plot\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Performance heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Relative performance heatmap\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Individual metric comparisons\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Remove extra subplots\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "# Calculate and display performance differences\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "S8bTOom-e_4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficient"
      ],
      "metadata": {
        "id": "BDEilwWke_4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, method_name, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {method_name}\\n{dataset_name} (ROC-AUC: {roc_auc:.4f})')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {method_name}\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {method_name} - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return {\n",
        "        'Dataset': dataset_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'Confusion Matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "# Data preparation\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Get top 10 features\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': initial_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(initial_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "# Prepare top features data\n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_test_scaled_top = scaler.transform(X_test_top)\n",
        "\n",
        "# Create model with best parameters\n",
        "best_params = {\n",
        "    'C': 38.31866597407751,\n",
        "    'penalty': 'l2',\n",
        "    'solver': 'liblinear',\n",
        "    'max_iter': 2000,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "best_model = LogisticRegression(**best_params)\n",
        "best_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# Evaluate on combined test set\n",
        "y_pred = best_model.predict(X_test_scaled_top)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "combined_results = evaluate_and_visualize(y_test, y_pred, y_pred_proba,\n",
        "                                        'Optimized Top 10 Model', 'Combined Test Set')\n",
        "\n",
        "# Evaluate on H1 test set\n",
        "mask_h1 = combined_test['hotel'] == 0  # City Hotel\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_top[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_top[mask_h1])[:, 1]\n",
        "h1_results = evaluate_and_visualize(y_test[mask_h1], y_pred_h1, y_pred_proba_h1,\n",
        "                                  'Optimized Top 10 Model', 'H1 Test Set')\n",
        "\n",
        "# Evaluate on H2 test set\n",
        "mask_h2 = combined_test['hotel'] == 1  # Resort Hotel\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_top[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_top[mask_h2])[:, 1]\n",
        "h2_results = evaluate_and_visualize(y_test[mask_h2], y_pred_h2, y_pred_proba_h2,\n",
        "                                  'Optimized Top 10 Model', 'H2 Test Set')\n",
        "\n",
        "# Create performance comparison\n",
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'Dataset': 'Combined Test Set',\n",
        "        'ROC AUC': roc_auc_score(y_test, y_pred_proba),\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    },\n",
        "    {\n",
        "        'Dataset': 'H1 Test Set',\n",
        "        'ROC AUC': roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        'Accuracy': accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "    },\n",
        "    {\n",
        "        'Dataset': 'H2 Test Set',\n",
        "        'ROC AUC': roc_auc_score(y_test[mask_h2], y_pred_proba_h2),\n",
        "        'Accuracy': accuracy_score(y_test[mask_h2], y_pred_h2),\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\nPerformance Summary:\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics = ['ROC AUC', 'Accuracy']\n",
        "results_melted = results_df.melt(id_vars=['Dataset'], value_vars=metrics,\n",
        "                                var_name='Metric', value_name='Score')\n",
        "\n",
        "sns.barplot(x='Dataset', y='Score', hue='Metric', data=results_melted)\n",
        "plt.title('Performance Comparison Across Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Coefficients in Final Model:\")\n",
        "final_coefficients = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Coefficient': best_model.coef_[0],\n",
        "    'Absolute_Coefficient': np.abs(best_model.coef_[0])\n",
        "}).sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "for idx, row in final_coefficients.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Coefficient']:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=final_coefficients, x='Absolute_Coefficient', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Final Model')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cgLqhjzce_4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, method_name, dataset_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {method_name}\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {method_name}\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {method_name} - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Grouped bar plot\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Performance metrics heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Relative performance heatmap\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Individual metric comparisons\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "bwfJ3h_6e_4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "9iASt_1ze_4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "initial_model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "explainer = shap.LinearExplainer(initial_model, X_train_scaled)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_test_scaled_top = scaler.transform(X_test_top)\n",
        "\n",
        "best_params = {\n",
        "    'C': 5221.17572683451,\n",
        "    'penalty': 'l2',\n",
        "    'solver': 'liblinear',\n",
        "    'max_iter': 2000,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "best_model = LogisticRegression(**best_params)\n",
        "best_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "mask_h1 = combined_test['hotel'] == 0\n",
        "mask_h2 = combined_test['hotel'] == 1\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled_top)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_top[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_top[mask_h1])[:, 1]\n",
        "\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_top[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_top[mask_h2])[:, 1]\n",
        "\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "cilXo5mVe_4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "WityXe4Je_4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42)\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_features = X_train.columns[boruta_selector.support_].tolist()\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled_selected = scaler.transform(X_test_selected)\n",
        "\n",
        "best_params = {\n",
        "    'C': 18.0836808047728,\n",
        "    'penalty': 'l1',\n",
        "    'solver': 'liblinear',\n",
        "    'max_iter': 2000,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "best_model = LogisticRegression(**best_params)\n",
        "best_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "mask_h1 = combined_test['hotel'] == 0\n",
        "mask_h2 = combined_test['hotel'] == 1\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled_selected)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_selected)[:, 1]\n",
        "\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_selected[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_selected[mask_h1])[:, 1]\n",
        "\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_selected[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_selected[mask_h2])[:, 1]\n",
        "\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "KktIV-7pe_4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2.Random Forest\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNnVwmB1e_4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "s-Nl8R5ze_40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Prepare data with combined dataset\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Create and evaluate random forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Combined Dataset Confusion Matrix (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    rf_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Combined Dataset (Random Forest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Random Forest Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Parameters:\")\n",
        "print(\"n_estimators: 100\")\n",
        "print(\"random_state: 42\")\n",
        "print(\"n_jobs: -1 (using all available cores)\")\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'][:10],\n",
        "                                              feature_importance['Importance'][:10]), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths in Random Forest')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "n_features_90 = np.argmax(importance_cum >= 0.9) + 1\n",
        "print(f\"\\nNumber of features needed to explain 90% of variance: {n_features_90}\")"
      ],
      "metadata": {
        "id": "5oIOw5hCe_40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "q0BRnk4Ve_40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "YxcfhCTLe_41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Get feature importance\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# Prepare top 10 features data\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# Create and evaluate model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "overall_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nOverall ROC AUC Score: {overall_auc:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    rf_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves (Top 10 Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Train final model and analyze\n",
        "final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths (Top 10 Features Model)')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "new_feature_importance = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=new_feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Top 10 Features Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(new_feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance (Top 10 Features)')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of original features: {X_train.shape[1]}\")\n",
        "print(f\"Number of selected features: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "print(\"\\nFeature Importance Ranking in Top 10 Features Model:\")\n",
        "for idx, (feature, importance) in enumerate(zip(new_feature_importance['Feature'],\n",
        "                                              new_feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Top 10 Features Model ROC AUC: {overall_auc:.4f}\")\n",
        "\n",
        "selected_features = top_features\n",
        "print(\"\\nSelected features saved for future use.\")"
      ],
      "metadata": {
        "id": "-QIpqKxIe_41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "pAfMPaxMe_42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 合并H1和H2的训练数据\n",
        "train_data = pd.concat([H1_train, H2_train], axis=0)\n",
        "test_data = pd.concat([H1_test, H2_test], axis=0)\n",
        "\n",
        "# 定义特征和目标变量\n",
        "X_train = train_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = train_data['is_canceled']\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 创建和训练初始模型用于SHAP值计算\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 计算SHAP值\n",
        "explainer = shap.TreeExplainer(initial_model)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values = shap_values[1]  # For binary classification, get class 1 SHAP values\n",
        "\n",
        "# 计算每个特征的平均绝对SHAP值\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 选择top 10特征\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# 可视化SHAP重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=X_train.columns, show=False)\n",
        "plt.title('SHAP Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 准备选定特征的数据\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "# 创建随机森林模型\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# 进行3-fold交叉验证并预测\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# 计算混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "# 绘制混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (SHAP Top 10 Features)')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "# 计算总体ROC AUC\n",
        "overall_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "print(f\"\\nOverall ROC AUC Score: {overall_auc:.4f}\")\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    rf_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves (SHAP Top 10 Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 训练最终模型\n",
        "final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# 评估树的深度分布\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# 获取并显示特征重要性\n",
        "rf_feature_importance = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 可视化随机森林特征重要性\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=rf_feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Random Forest (SHAP Selected Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 计算和显示SHAP值的详细分析\n",
        "final_explainer = shap.TreeExplainer(final_model)\n",
        "final_shap_values = final_explainer.shap_values(X_train_scaled_top)\n",
        "\n",
        "if isinstance(final_shap_values, list):\n",
        "    final_shap_values = final_shap_values[1]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(final_shap_values, X_train_scaled_top,\n",
        "                 feature_names=top_features, show=False)\n",
        "plt.title('SHAP Summary Plot for Selected Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 计算特征重要性的累积分布\n",
        "importance_cum = np.cumsum(rf_feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 打印模型信息\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of selected features: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "# 打印特征重要性\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "for idx, (feature, importance) in enumerate(zip(rf_feature_importance['Feature'],\n",
        "                                              rf_feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# 保存选定的特征列表\n",
        "selected_features_list = top_features\n",
        "print(\"\\nSelected features saved for future use.\")"
      ],
      "metadata": {
        "id": "Eq-vkjrIe_42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP计算部分的修改（其他代码保持不变）\n",
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# 从训练集随机抽取样本\n",
        "np.random.seed(42)\n",
        "n_samples = 1000  # 可以根据需要调整样本量\n",
        "sample_indices = np.random.choice(len(X_train_scaled), n_samples, replace=False)\n",
        "X_train_sample = X_train_scaled[sample_indices]\n",
        "\n",
        "# 使用background数据来加速计算\n",
        "background = shap.sample(X_train_scaled, 100)  # 使用100个背景样本\n",
        "\n",
        "# 创建和训练初始模型\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 计算SHAP值 - 使用近似方法\n",
        "explainer = shap.TreeExplainer(\n",
        "    initial_model,\n",
        "    data=background,\n",
        "    feature_perturbation='interventional',\n",
        "    model_output='probability'\n",
        ")\n",
        "shap_values = explainer.shap_values(X_train_sample)\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values = shap_values[1]  # For binary classification, get class 1 SHAP values\n",
        "\n",
        "# 计算每个特征的平均绝对SHAP值\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 选择top 10特征\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# 可视化SHAP重要性 - 只使用样本数据\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_train_sample,\n",
        "    feature_names=X_train.columns,\n",
        "    show=False,\n",
        "    max_display=10  # 只显示前10个特征\n",
        ")\n",
        "plt.title('SHAP Feature Importance (Based on Sample)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-_MRwhoae_49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample 1000 instances from the training data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "sample_indices = np.random.choice(len(X_train_scaled), n_samples, replace=False)\n",
        "X_train_sample = X_train_scaled[sample_indices]\n",
        "\n",
        "# Use 100 background samples\n",
        "background = shap.sample(X_train_scaled, 100)\n",
        "\n",
        "# Create and train the initial model\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Compute SHAP values using the TreeExplainer\n",
        "explainer = shap.TreeExplainer(\n",
        "    initial_model,\n",
        "    data=background,\n",
        "    feature_perturbation='interventional',\n",
        "    model_output='probability'\n",
        ")\n",
        "shap_values = explainer.shap_values(X_train_sample)\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values = shap_values[1]  # For binary classification, get class 1 SHAP values\n",
        "\n",
        "# Calculate feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Select the top 10 features\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"Selected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# Visualize the SHAP feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_train_sample,\n",
        "    feature_names=X_train.columns,\n",
        "    show=False,\n",
        "    max_display=10\n",
        ")\n",
        "plt.title('SHAP Feature Importance (Based on Sample)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BD5QURm2e_4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assume X_train_scaled and y_train are already prepared\n",
        "X_train_sample = X_train_scaled[:1000]  # Sample 1000 instances\n",
        "\n",
        "# Flatten any higher-dimensional features in X_train_sample\n",
        "X_train_sample = [x.ravel() for x in X_train_sample]\n",
        "\n",
        "# Create and train the initial model\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Compute SHAP values using the TreeExplainer\n",
        "explainer = shap.TreeExplainer(initial_model)\n",
        "shap_values = explainer.shap_values(X_train_sample)\n",
        "\n",
        "# Calculate feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.mean(np.abs(shap_values), axis=0)\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Select the top 10 features\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "print(\"Selected Top 10 Features by SHAP:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "# Visualize the SHAP feature importance\n",
        "shap.summary_plot(shap_values, X_train_sample, feature_names=X_train.columns)"
      ],
      "metadata": {
        "id": "jSJ_rtm_e_4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "mZ799bf1e_4_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjfQAm32e_4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Boruta feature selection\n",
        "print(\"Running Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Ranking': boruta_selector.ranking_,\n",
        "    'Selected': selected_feat_mask\n",
        "})\n",
        "importance_df['Importance'] = max(importance_df['Ranking']) - importance_df['Ranking'] + 1\n",
        "importance_df = importance_df[importance_df['Selected']].sort_values(by='Importance', ascending=False)\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(rf_model, X_train_scaled_selected, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(rf_model, X_train_scaled_selected, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix (Boruta Selected Features)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    rf_model.fit(X_train_scaled_selected[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = rf_model.predict_proba(X_train_scaled_selected[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves (Boruta Selected Features)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "final_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance (Boruta Selected Features)')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'],\n",
        "                                              feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "n_features_90 = np.argmax(importance_cum >= 0.9) + 1\n",
        "print(f\"\\nNumber of features needed to explain 90% of variance: {n_features_90}\")\n",
        "\n",
        "selected_features_list = selected_features\n",
        "print(\"\\nSelected features saved for future use.\")"
      ],
      "metadata": {
        "id": "ApQkvYCee_4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "Yp_gjbete_4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "fSNpRHTPe_5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"Optimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['random_state'] = 42\n",
        "best_params['n_jobs'] = -1\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Random Forest)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    best_model.fit(X_train_scaled[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Random Forest (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = RandomForestClassifier(**best_params)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Random Forest')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths in Optimized Random Forest')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nOptimized Model Information:\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "n_features_90 = np.argmax(importance_cum >= 0.9) + 1\n",
        "print(f\"\\nNumber of features needed to explain 90% of variance: {n_features_90}\")\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'][:10],\n",
        "                                              feature_importance['Importance'][:10]), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "best_rf_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_rf_params)"
      ],
      "metadata": {
        "id": "KAahjRfPe_5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "Y3pgTS85e_5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "print(\"Selected Top 10 Features:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance.head(10)['Feature'],\n",
        "                                              feature_importance.head(10)['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "X_train_top = X_train[top_features]\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_top, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['random_state'] = 42\n",
        "best_params['n_jobs'] = -1\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_top, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_top, y_train):\n",
        "    best_model.fit(X_train_scaled_top[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_top[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = RandomForestClassifier(**best_params)\n",
        "final_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths in Optimized Model')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': top_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of selected features: {len(top_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "print(\"\\nFeature Importance Ranking in Optimized Model:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'],\n",
        "                                              feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "best_rf_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_rf_params)"
      ],
      "metadata": {
        "id": "5FRAlkuhe_5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "RHrjykFme_5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Boruta feature selection\n",
        "print(\"Running Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_selected, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['random_state'] = 42\n",
        "best_params['n_jobs'] = -1\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    best_model.fit(X_train_scaled_selected[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_selected[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = RandomForestClassifier(**best_params)\n",
        "final_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths in Optimized Model')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'],\n",
        "                                              feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "best_rf_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_rf_params)"
      ],
      "metadata": {
        "id": "BboZOAGQe_5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta"
      ],
      "metadata": {
        "id": "XBwF8D_ae_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prepare data\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Boruta feature selection\n",
        "print(\"Running Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
        "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled_selected, y_train, cv=3, scoring='roc_auc')\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"\\nOptimizing hyperparameters...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(study.best_params)\n",
        "print(f\"Best ROC-AUC score: {study.best_value:.4f}\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params['random_state'] = 42\n",
        "best_params['n_jobs'] = -1\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict')\n",
        "y_pred_proba_cv = cross_val_predict(best_model, X_train_scaled_selected, y_train, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix (Optimized Model)\\nBest ROC-AUC: {study.best_value:.4f}')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "optimization_history = np.array([t.value for t in study.trials])\n",
        "plt.plot(optimization_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('ROC-AUC Score')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "fold_count = 1\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled_selected, y_train):\n",
        "    best_model.fit(X_train_scaled_selected[train_idx], y_train.iloc[train_idx])\n",
        "    y_pred_proba_fold = best_model.predict_proba(X_train_scaled_selected[test_idx])[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    roc_auc_fold = roc_auc_score(y_train.iloc[test_idx], y_pred_proba_fold)\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Optimized Model (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "final_model = RandomForestClassifier(**best_params)\n",
        "final_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "tree_depths = [tree.get_depth() for tree in final_model.estimators_]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tree_depths, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Tree Depths in Optimized Model')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in Optimized Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "plt.title('Hyperparameter Importance')\n",
        "plt.show()\n",
        "\n",
        "importance_cum = np.cumsum(feature_importance['Importance'])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(importance_cum) + 1), importance_cum)\n",
        "plt.title('Cumulative Feature Importance')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cumulative Importance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Information:\")\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Total training samples: {len(X_train)}\")\n",
        "\n",
        "print(\"\\nTree Depth Statistics:\")\n",
        "print(f\"Mean Depth: {np.mean(tree_depths):.2f}\")\n",
        "print(f\"Max Depth: {np.max(tree_depths)}\")\n",
        "print(f\"Min Depth: {np.min(tree_depths)}\")\n",
        "\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "for idx, (feature, importance) in enumerate(zip(feature_importance['Feature'],\n",
        "                                              feature_importance['Importance']), 1):\n",
        "    print(f\"{idx}. {feature}: {importance:.4f}\")\n",
        "\n",
        "best_rf_params = study.best_params\n",
        "print(\"\\nBest Hyperparameters for future use:\")\n",
        "print(best_rf_params)"
      ],
      "metadata": {
        "id": "-5xqmjSye_5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glqpgETfe_5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "Yai1ISSBe_5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "3D_vKW_he_5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Data preparation\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "X_test = combined_test[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = combined_test['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model with best parameters\n",
        "best_params = {\n",
        "    'n_estimators': 234,\n",
        "    'max_depth': 20,\n",
        "    'min_samples_split': 8,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'sqrt',\n",
        "    'criterion': 'gini',\n",
        "    'bootstrap': False,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Test set predictions\n",
        "mask_h1 = combined_test['hotel'] == 0\n",
        "mask_h2 = combined_test['hotel'] == 1\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "y_pred_h1 = best_model.predict(X_test_scaled[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled[mask_h1])[:, 1]\n",
        "\n",
        "y_pred_h2 = best_model.predict(X_test_scaled[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled[mask_h2])[:, 1]\n",
        "\n",
        "# Performance comparison\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Performance visualization\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "E5tTvWpwe_5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "ffCGWMrae_5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Prepare training data\n",
        "train_data = pd.concat([H1_train, H2_train], axis=0)\n",
        "test_data = pd.concat([H1_test, H2_test], axis=0)\n",
        "\n",
        "# Prepare feature data\n",
        "X_train = train_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = train_data['is_canceled']\n",
        "X_test = test_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = test_data['is_canceled']\n",
        "\n",
        "# Get feature importance and select top 10 features\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "# Prepare feature data\n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_test_scaled_top = scaler.transform(X_test_top)\n",
        "\n",
        "# Create model with best parameters\n",
        "best_params = {\n",
        "    'n_estimators': 214,\n",
        "    'max_depth': 20,\n",
        "    'min_samples_split': 6,\n",
        "    'min_samples_leaf': 4,\n",
        "    'max_features': 'log2',\n",
        "    'criterion': 'gini',\n",
        "    'bootstrap': False,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# Evaluate on test sets\n",
        "mask_h1 = test_data.index.isin(H1_test.index)\n",
        "mask_h2 = test_data.index.isin(H2_test.index)\n",
        "\n",
        "# Overall test set prediction\n",
        "y_pred = best_model.predict(X_test_scaled_top)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "\n",
        "# H1 test set prediction\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_top[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_top[mask_h1])[:, 1]\n",
        "\n",
        "# H2 test set prediction\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_top[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_top[mask_h2])[:, 1]\n",
        "\n",
        "# Create performance comparison table\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Plot complete performance comparison\n",
        "plt.figure(figsize=(15, 8))\n",
        "performance_metrics = performance_comparison.melt(id_vars=['Dataset'], var_name='Metric', value_name='Score')\n",
        "\n",
        "# Create grouped bar chart\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create heatmap to visualize performance metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate relative performance\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create individual comparison plots for each metric\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Remove unused subplots\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "# Calculate and display performance difference percentage\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "PRjet71Ne_5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eQYCQSoe_5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    # 计算指标\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # 混淆矩阵\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC曲线\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # 打印分类报告\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# 准备训练数据\n",
        "train_data = pd.concat([H1_train, H2_train], axis=0)\n",
        "test_data = pd.concat([H1_test, H2_test], axis=0)\n",
        "\n",
        "# 准备特征数据\n",
        "X_train = train_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = train_data['is_canceled']\n",
        "X_test = test_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = test_data['is_canceled']\n",
        "\n",
        "# 获取特征重要性并选择top10特征\n",
        "initial_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "initial_model.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': initial_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)['Feature'].tolist()\n",
        "\n",
        "# 准备特征数据\n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_top = scaler.fit_transform(X_train_top)\n",
        "X_test_scaled_top = scaler.transform(X_test_top)\n",
        "\n",
        "# 使用最佳参数创建模型\n",
        "best_params = {\n",
        "    'n_estimators': 214,\n",
        "    'max_depth': 20,\n",
        "    'min_samples_split': 6,\n",
        "    'min_samples_leaf': 4,\n",
        "    'max_features': 'log2',\n",
        "    'criterion': 'gini',\n",
        "    'bootstrap': False,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_scaled_top, y_train)\n",
        "\n",
        "# 在测试集上进行评估\n",
        "mask_h1 = test_data.index.isin(H1_test.index)\n",
        "mask_h2 = test_data.index.isin(H2_test.index)\n",
        "\n",
        "# 整体测试集预测\n",
        "y_pred = best_model.predict(X_test_scaled_top)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_top)[:, 1]\n",
        "\n",
        "# H1测试集预测\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_top[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_top[mask_h1])[:, 1]\n",
        "\n",
        "# H2测试集预测\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_top[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_top[mask_h2])[:, 1]\n",
        "\n",
        "# 创建性能比较表格\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# 绘制完整的性能比较图\n",
        "plt.figure(figsize=(15, 8))\n",
        "performance_metrics = performance_comparison.melt(id_vars=['Dataset'], var_name='Metric', value_name='Score')\n",
        "\n",
        "# 创建分组柱状图\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 创建热力图展示性能指标\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 计算每个指标的相对表现\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 为每个指标创建单独的比较图\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# 删除多余的子图\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印详细的统计分析\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "# 计算并显示性能差异百分比\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "QRb7mPuAe_5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "fR3bZFlSe_5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve, precision_score, recall_score, f1_score)\n",
        "from boruta import BorutaPy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def evaluate_and_visualize(y_true, y_pred, y_pred_proba, dataset_name):\n",
        "    \"\"\"Helper function to evaluate and visualize results\"\"\"\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=12)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix\\n{dataset_name}')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve\\n{dataset_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\nClassification Report - {dataset_name}\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Prepare training data\n",
        "train_data = pd.concat([H1_train, H2_train], axis=0)\n",
        "test_data = pd.concat([H1_test, H2_test], axis=0)\n",
        "\n",
        "# Prepare feature data\n",
        "X_train = train_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = train_data['is_canceled']\n",
        "X_test = test_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = test_data['is_canceled']\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Use Boruta for feature selection\n",
        "print(\"Running Boruta feature selection...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "boruta_selector = BorutaPy(\n",
        "    rf,\n",
        "    n_estimators='auto',\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Run Boruta selection\n",
        "boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get selected features\n",
        "selected_feat_mask = boruta_selector.support_\n",
        "selected_features = X_train.columns[selected_feat_mask].tolist()\n",
        "\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "for idx, feature in enumerate(selected_features, 1):\n",
        "    print(f\"{idx}. {feature}\")\n",
        "\n",
        "# Prepare feature data\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Standardize data\n",
        "X_train_scaled_selected = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled_selected = scaler.transform(X_test_selected)\n",
        "\n",
        "# Create model with best parameters\n",
        "best_params = {\n",
        "    'n_estimators': 295,\n",
        "    'max_depth': 20,\n",
        "    'min_samples_split': 4,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'log2',\n",
        "    'criterion': 'entropy',\n",
        "    'bootstrap': True,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "best_model = RandomForestClassifier(**best_params)\n",
        "best_model.fit(X_train_scaled_selected, y_train)\n",
        "\n",
        "# Evaluate on test sets\n",
        "mask_h1 = test_data.index.isin(H1_test.index)\n",
        "mask_h2 = test_data.index.isin(H2_test.index)\n",
        "\n",
        "# Overall test set prediction\n",
        "y_pred = best_model.predict(X_test_scaled_selected)\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled_selected)[:, 1]\n",
        "\n",
        "# H1 test set prediction\n",
        "y_pred_h1 = best_model.predict(X_test_scaled_selected[mask_h1])\n",
        "y_pred_proba_h1 = best_model.predict_proba(X_test_scaled_selected[mask_h1])[:, 1]\n",
        "\n",
        "# H2 test set prediction\n",
        "y_pred_h2 = best_model.predict(X_test_scaled_selected[mask_h2])\n",
        "y_pred_proba_h2 = best_model.predict_proba(X_test_scaled_selected[mask_h2])[:, 1]\n",
        "\n",
        "# Create performance comparison table\n",
        "performance_comparison = pd.DataFrame({\n",
        "    'Dataset': ['Combined Test Set', 'H1 Test Set', 'H2 Test Set'],\n",
        "    'ROC AUC': [\n",
        "        roc_auc_score(y_test, y_pred_proba),\n",
        "        roc_auc_score(y_test[mask_h1], y_pred_proba_h1),\n",
        "        roc_auc_score(y_test[mask_h2], y_pred_proba_h2)\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        accuracy_score(y_test[mask_h1], y_pred_h1),\n",
        "        accuracy_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred),\n",
        "        precision_score(y_test[mask_h1], y_pred_h1),\n",
        "        precision_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred),\n",
        "        recall_score(y_test[mask_h1], y_pred_h1),\n",
        "        recall_score(y_test[mask_h2], y_pred_h2)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred),\n",
        "        f1_score(y_test[mask_h1], y_pred_h1),\n",
        "        f1_score(y_test[mask_h2], y_pred_h2)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDetailed Performance Comparison:\")\n",
        "print(performance_comparison.round(4))\n",
        "\n",
        "# Plot complete performance comparison\n",
        "plt.figure(figsize=(15, 8))\n",
        "performance_metrics = performance_comparison.melt(id_vars=['Dataset'], var_name='Metric', value_name='Score')\n",
        "\n",
        "# Create grouped bar chart\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.15\n",
        "metrics = ['ROC AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "x = np.arange(len(performance_comparison['Dataset']))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i * bar_width,\n",
        "           performance_comparison[metric],\n",
        "           bar_width,\n",
        "           label=metric,\n",
        "           alpha=0.8)\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Complete Performance Comparison Across Test Sets')\n",
        "plt.xticks(x + bar_width * 2, performance_comparison['Dataset'], rotation=45)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create heatmap to visualize performance metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "metrics_df = performance_comparison.set_index('Dataset')\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.4f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Performance Metrics Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate relative performance\n",
        "relative_performance = metrics_df.div(metrics_df.max()) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(relative_performance, annot=True, cmap='YlOrRd', fmt='.1f',\n",
        "            cbar_kws={'label': 'Relative Performance (%)'})\n",
        "plt.title('Relative Performance Metrics Heatmap (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create individual comparison plots for each metric\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "colors = sns.color_palette('husl', n_colors=len(metrics))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.barplot(data=performance_comparison, x='Dataset', y=metric, ax=axes[i],\n",
        "                color=colors[i])\n",
        "    axes[i].set_title(f'{metric} Comparison')\n",
        "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
        "    axes[i].grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Remove unused subplots\n",
        "for i in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\nDetailed Statistics:\")\n",
        "print(\"\\nMean Performance Across Datasets:\")\n",
        "print(metrics_df.mean().round(4))\n",
        "print(\"\\nStandard Deviation of Performance:\")\n",
        "print(metrics_df.std().round(4))\n",
        "print(\"\\nRange of Performance (Max - Min):\")\n",
        "print((metrics_df.max() - metrics_df.min()).round(4))\n",
        "\n",
        "# Calculate and display performance difference percentage\n",
        "print(\"\\nPerformance Difference from Combined Test Set (%):\")\n",
        "baseline = metrics_df.loc['Combined Test Set']\n",
        "for dataset in ['H1 Test Set', 'H2 Test Set']:\n",
        "    diff_percentage = ((metrics_df.loc[dataset] - baseline) / baseline * 100).round(2)\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for metric, value in diff_percentage.items():\n",
        "        print(f\"{metric}: {value:+.2f}%\")"
      ],
      "metadata": {
        "id": "XdCKgvvbe_5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 3.TabNet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m8pYVKIOe_5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline model"
      ],
      "metadata": {
        "id": "z4NEx5EYe_5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "# Data preparation\n",
        "X_train = combined_train[selected_columns].drop(columns=['is_canceled'])\n",
        "y_train = combined_train['is_canceled']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# TabNet parameters\n",
        "tabnet_params = {\n",
        "    'n_d': 64,\n",
        "    'n_a': 64,\n",
        "    'n_steps': 5,\n",
        "    'gamma': 1.5,\n",
        "    'n_independent': 2,\n",
        "    'n_shared': 2,\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=2e-2),\n",
        "    'scheduler_params': dict(mode=\"min\",\n",
        "                           patience=5,\n",
        "                           min_lr=1e-5,\n",
        "                           factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Cross-validation\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "y_pred_cv = np.zeros_like(y_train)\n",
        "y_pred_proba_cv = np.zeros_like(y_train, dtype=float)\n",
        "\n",
        "fold_count = 1\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for train_idx, test_idx in cv.split(X_train_scaled, y_train):\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    X_fold_train = X_train_scaled[train_idx]\n",
        "    y_fold_train = y_train.iloc[train_idx].values\n",
        "    X_fold_test = X_train_scaled[test_idx]\n",
        "    y_fold_test = y_train.iloc[test_idx].values\n",
        "\n",
        "    clf.fit(\n",
        "        X_fold_train, y_fold_train,\n",
        "        eval_set=[(X_fold_test, y_fold_test)],\n",
        "        max_epochs=100,\n",
        "        patience=10,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128\n",
        "    )\n",
        "\n",
        "    y_pred_cv[test_idx] = clf.predict(X_fold_test)\n",
        "    y_pred_proba_cv[test_idx] = clf.predict_proba(X_fold_test)[:, 1]\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    roc_auc_fold = roc_auc_score(y_fold_test, clf.predict_proba(X_fold_test)[:, 1])\n",
        "    plt.plot(fpr, tpr, label=f'Fold {fold_count} (AUC = {roc_auc_fold:.2f})')\n",
        "    fold_count += 1\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Combined Dataset with TabNet (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=15)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Combined Dataset Confusion Matrix with TabNet')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))\n",
        "print(f\"\\nOverall ROC AUC Score: {roc_auc_score(y_train, y_pred_proba_cv):.4f}\")\n",
        "\n",
        "final_model = TabNetClassifier(**tabnet_params)\n",
        "final_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': final_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Feature Importance in TabNet Model')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Number of Features: {X_train.shape[1]}\")\n",
        "print(f\"Class Distribution in Training Set:\")\n",
        "print(y_train.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "QbtoH2sAe_5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. TabNet内置特征重要性\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('TabNet Feature Importance')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. SHAP值分析\n",
        "explainer = shap.KernelExplainer(\n",
        "    lambda x: best_model.predict_proba(x)[:, 1],\n",
        "    shap.sample(X_train_scaled, 100)\n",
        ")\n",
        "shap_values = explainer.shap_values(X_train_scaled[:100])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values, X_train_scaled[:100], feature_names=X_train.columns)\n",
        "plt.title('SHAP Summary Plot')\n",
        "plt.show()\n",
        "\n",
        "# 3. Boruta特征选择\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42)\n",
        "boruta.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 获取Boruta结果\n",
        "boruta_results = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': boruta.ranking_,\n",
        "    'Status': ['Selected' if rank <= 2 else 'Rejected' for rank in boruta.ranking_]\n",
        "})\n",
        "boruta_results = boruta_results.sort_values('Importance')\n",
        "\n",
        "# 可视化Boruta结果\n",
        "plt.figure(figsize=(12, 6))\n",
        "colors = ['green' if status == 'Selected' else 'red' for status in boruta_results['Status']]\n",
        "sns.barplot(data=boruta_results, x='Importance', y='Feature', palette=colors)\n",
        "plt.title('Boruta Feature Selection Results')\n",
        "plt.xlabel('Ranking (lower is better)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印选中的特征\n",
        "print(\"\\nSelected Features by Boruta:\")\n",
        "print(boruta_results[boruta_results['Status'] == 'Selected']['Feature'].tolist())"
      ],
      "metadata": {
        "id": "21frMtFEe_5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### different feature combinations"
      ],
      "metadata": {
        "id": "6FWvM23ze_5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 获取三种不同的特征集\n",
        "# Feature Importance top 10\n",
        "importance_features = feature_importance.nlargest(10, 'Importance')['Feature'].tolist()\n",
        "\n",
        "# SHAP top 10\n",
        "shap_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': np.abs(shap_values).mean(0)\n",
        "}).sort_values('Importance', ascending=False)\n",
        "shap_features = shap_importance.nlargest(10, 'Importance')['Feature'].tolist()\n",
        "\n",
        "# Boruta selected features\n",
        "boruta_features = boruta_results[boruta_results['Status'] == 'Selected']['Feature'].tolist()\n",
        "\n",
        "# 2. 创建三个数据集\n",
        "X_train_importance = X_train_scaled[:, [list(X_train.columns).index(col) for col in importance_features]]\n",
        "X_test_importance = X_test_scaled[:, [list(X_test.columns).index(col) for col in importance_features]]\n",
        "\n",
        "X_train_shap = X_train_scaled[:, [list(X_train.columns).index(col) for col in shap_features]]\n",
        "X_test_shap = X_test_scaled[:, [list(X_test.columns).index(col) for col in shap_features]]\n",
        "\n",
        "X_train_boruta = X_train_scaled[:, [list(X_train.columns).index(col) for col in boruta_features]]\n",
        "X_test_boruta = X_test_scaled[:, [list(X_test.columns).index(col) for col in boruta_features]]\n",
        "\n",
        "# 3. 训练三个模型\n",
        "models = {\n",
        "    'Feature Importance': TabNetClassifier(**final_params),\n",
        "    'SHAP': TabNetClassifier(**final_params),\n",
        "    'Boruta': TabNetClassifier(**final_params)\n",
        "}\n",
        "\n",
        "datasets = {\n",
        "    'Feature Importance': (X_train_importance, X_test_importance),\n",
        "    'SHAP': (X_train_shap, X_test_shap),\n",
        "    'Boruta': (X_train_boruta, X_test_boruta)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# 训练和评估每个模型\n",
        "for name, model in models.items():\n",
        "    X_train_subset, X_test_subset = datasets[name]\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(\n",
        "        X_train_subset, y_train.values,\n",
        "        eval_set=[(X_train_subset, y_train.values)],\n",
        "        max_epochs=100,\n",
        "        batch_size=2048\n",
        "    )\n",
        "\n",
        "    # 获取预测\n",
        "    y_pred = model.predict(X_test_subset)\n",
        "    y_pred_proba = model.predict_proba(X_test_subset)[:, 1]\n",
        "\n",
        "    results[name] = {\n",
        "        'predictions': y_pred,\n",
        "        'probabilities': y_pred_proba\n",
        "    }\n",
        "\n",
        "# 4. 可视化比较\n",
        "# ROC曲线比较\n",
        "plt.figure(figsize=(12, 8))\n",
        "for name, result in results.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n",
        "    roc_auc = roc_auc_score(y_test, result['probabilities'])\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves Comparison for Different Feature Selection Methods')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 混淆矩阵比较\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "for idx, (name, result) in enumerate(results.items()):\n",
        "    conf_matrix = confusion_matrix(y_test, result['predictions'])\n",
        "    conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[idx])\n",
        "\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "            axes[idx].text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "    axes[idx].set_title(f'{name} Confusion Matrix')\n",
        "    axes[idx].set_xlabel('Predicted Label')\n",
        "    axes[idx].set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印分类报告\n",
        "for name, result in results.items():\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_test, result['predictions']))\n",
        "\n",
        "# 打印特征数量比较\n",
        "print(\"\\nNumber of features used in each model:\")\n",
        "print(f\"Feature Importance top 10: {len(importance_features)}\")\n",
        "print(f\"SHAP top 10: {len(shap_features)}\")\n",
        "print(f\"Boruta: {len(boruta_features)}\")"
      ],
      "metadata": {
        "id": "EPeglfnse_5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "cA90zdxQe_5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "VP-a8HPpe_5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "rZlMn6R5e_5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyperparameter tuning"
      ],
      "metadata": {
        "id": "WOE-TnBke_5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "4ouZ-xFRe_5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    tabnet_params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [8, 16, 32, 64]),\n",
        "        'n_a': trial.suggest_categorical('n_a', [8, 16, 32, 64]),\n",
        "        'n_steps': trial.suggest_int('n_steps', 3, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 1.0, 1.5),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': {\n",
        "            'lr': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.005])\n",
        "        },\n",
        "        'scheduler_params': {\n",
        "            'mode': 'min',\n",
        "            'patience': 5,\n",
        "            'min_lr': 1e-5,\n",
        "            'factor': 0.5\n",
        "        },\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax',\n",
        "        'seed': 42\n",
        "    }\n",
        "\n",
        "    clf = TabNetClassifier(**tabnet_params)\n",
        "\n",
        "    # 使用单次验证集而不是交叉验证\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X_train_scaled, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train_split, y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        max_epochs=30,\n",
        "        patience=5,\n",
        "        batch_size=2048,\n",
        "        virtual_batch_size=256\n",
        "    )\n",
        "\n",
        "    pred_proba = clf.predict_proba(X_val_split)[:, 1]\n",
        "    return roc_auc_score(y_val_split, pred_proba)\n",
        "\n",
        "# 运行优化\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "# 打印最佳参数\n",
        "print(\"\\nBest parameters:\", study.best_trial.params)\n",
        "print(\"Best AUC score:\", study.best_trial.value)\n",
        "\n",
        "# 使用最佳参数训练最终模型\n",
        "best_params = study.best_trial.params\n",
        "final_params = {\n",
        "    'n_d': best_params['n_d'],\n",
        "    'n_a': best_params['n_a'],\n",
        "    'n_steps': best_params['n_steps'],\n",
        "    'gamma': best_params['gamma'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': {'lr': best_params['learning_rate']},\n",
        "    'scheduler_params': {\n",
        "        'mode': 'min',\n",
        "        'patience': 5,\n",
        "        'min_lr': 1e-5,\n",
        "        'factor': 0.5\n",
        "    },\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "best_model = TabNetClassifier(**final_params)\n",
        "best_model.fit(\n",
        "    X_train_scaled, y_train.values,\n",
        "    eval_set=[(X_train_scaled, y_train.values)],\n",
        "    max_epochs=100,\n",
        "    batch_size=2048\n",
        ")"
      ],
      "metadata": {
        "id": "eXcpCsO4e_5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算预测概率和ROC曲线\n",
        "y_pred_cv = best_model.predict(X_train_scaled)\n",
        "y_pred_proba_cv = best_model.predict_proba(X_train_scaled)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_train, y_pred_proba_cv)\n",
        "roc_auc = roc_auc_score(y_train, y_pred_proba_cv)\n",
        "plt.plot(fpr, tpr, label=f'TabNet (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Combined H1+H2 Dataset with TabNet (3-fold CV)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 计算和绘制混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_train, y_pred_cv)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Combined H1+H2 Confusion Matrix with TabNet')\n",
        "plt.show()\n",
        "\n",
        "# 输出分类报告\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred_cv))"
      ],
      "metadata": {
        "id": "1YBm3OCEe_5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "def get_quick_objective(X_train_data, y_train_data):\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_d': trial.suggest_categorical('n_d', [16, 32]),\n",
        "            'n_steps': trial.suggest_categorical('n_steps', [3, 4]),\n",
        "            'optimizer_fn': torch.optim.Adam,\n",
        "            'optimizer_params': {'lr': trial.suggest_categorical('learning_rate', [0.01, 0.02])},\n",
        "            'scheduler_params': {'mode': 'min', 'patience': 4, 'min_lr': 1e-5, 'factor': 0.5},\n",
        "            'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "            'mask_type': 'entmax'\n",
        "        }\n",
        "\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(X_train_data, y_train_data, test_size=0.1, random_state=42)\n",
        "\n",
        "        clf = TabNetClassifier(**params)\n",
        "        clf.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            max_epochs=20,\n",
        "            patience=4,\n",
        "            batch_size=4096\n",
        "        )\n",
        "\n",
        "        return roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
        "    return objective\n",
        "\n",
        "# 对三个特征集分别进行优化\n",
        "optimized_params = {}\n",
        "for name, (X_data, y_data) in [\n",
        "    ('Importance', (X_train_importance, y_train)),\n",
        "    ('SHAP', (X_train_shap, y_train)),\n",
        "    ('Boruta', (X_train_boruta, y_train))\n",
        "]:\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(get_quick_objective(X_data, y_data), n_trials=8)\n",
        "\n",
        "    optimized_params[name] = {\n",
        "        **study.best_trial.params,\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'scheduler_params': {'mode': 'min', 'patience': 4, 'min_lr': 1e-5, 'factor': 0.5},\n",
        "        'mask_type': 'entmax'\n",
        "    }\n",
        "    print(f\"\\n{name} Best Parameters:\", study.best_trial.params)\n",
        "    print(f\"Best AUC: {study.best_trial.value:.4f}\")\n",
        "\n",
        "# 使用优化后的参数训练最终模型\n",
        "final_models = {}\n",
        "for name, params in optimized_params.items():\n",
        "    model = TabNetClassifier(**params)\n",
        "    if name == 'Importance':\n",
        "        X_train_data, X_test_data = X_train_importance, X_test_importance\n",
        "    elif name == 'SHAP':\n",
        "        X_train_data, X_test_data = X_train_shap, X_test_shap\n",
        "    else:  # Boruta\n",
        "        X_train_data, X_test_data = X_train_boruta, X_test_boruta\n",
        "\n",
        "    model.fit(X_train_data, y_train.values, max_epochs=100, batch_size=4096)\n",
        "    final_models[name] = model"
      ],
      "metadata": {
        "id": "QH4hfPKWe_5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance（optuna+test set)"
      ],
      "metadata": {
        "id": "a41MVrWRe_5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance Model\n",
        "import optuna\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "def objective_importance(trial):\n",
        "    params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [16, 32]),\n",
        "        'n_steps': trial.suggest_categorical('n_steps', [3, 4]),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=trial.suggest_categorical('learning_rate', [0.01, 0.02])),\n",
        "        'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax'\n",
        "    }\n",
        "\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_importance, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "    clf = TabNetClassifier(**params)\n",
        "    clf.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        max_epochs=20,\n",
        "        patience=4,\n",
        "        batch_size=4096\n",
        "    )\n",
        "\n",
        "    return roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
        "\n",
        "# 优化Feature Importance模型\n",
        "study_importance = optuna.create_study(direction='maximize')\n",
        "study_importance.optimize(objective_importance, n_trials=8)\n",
        "\n",
        "# 获取最佳参数\n",
        "best_params_importance = {\n",
        "    'n_d': study_importance.best_trial.params['n_d'],\n",
        "    'n_steps': study_importance.best_trial.params['n_steps'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=study_importance.best_trial.params['learning_rate']),\n",
        "    'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax'\n",
        "}\n",
        "\n",
        "# 训练最终模型\n",
        "final_model_importance = TabNetClassifier(**best_params_importance)\n",
        "final_model_importance.fit(\n",
        "    X_train_importance, y_train.values,\n",
        "    max_epochs=100,\n",
        "    batch_size=4096\n",
        ")\n",
        "\n",
        "print(\"Feature Importance Best Parameters:\", study_importance.best_trial.params)\n",
        "print(f\"Best AUC: {study_importance.best_trial.value:.4f}\")"
      ],
      "metadata": {
        "id": "J-igpskze_5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练集评估\n",
        "y_train_pred = final_model_importance.predict(X_train_importance)\n",
        "y_train_proba = final_model_importance.predict_proba(X_train_importance)[:, 1]\n",
        "\n",
        "# 测试集评估\n",
        "y_test_pred = final_model_importance.predict(X_test_importance)\n",
        "y_test_proba = final_model_importance.predict_proba(X_test_importance)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "# 训练集ROC\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
        "roc_auc_train = roc_auc_score(y_train, y_train_proba)\n",
        "plt.plot(fpr_train, tpr_train, label=f'Train (AUC = {roc_auc_train:.3f})')\n",
        "# 测试集ROC\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "plt.plot(fpr_test, tpr_test, label=f'Test (AUC = {roc_auc_test:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Feature Importance Model)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 训练集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_percentage_train = conf_matrix_train / conf_matrix_train.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_train.shape[0]):\n",
        "    for j in range(conf_matrix_train.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_train[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Training Set Confusion Matrix (Feature Importance Model)')\n",
        "plt.show()\n",
        "\n",
        "# 测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Test Set Confusion Matrix (Feature Importance Model)')\n",
        "plt.show()\n",
        "\n",
        "# 输出训练集分类报告\n",
        "print(\"\\nTraining Set Classification Report (Feature Importance Model):\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nTest Set Classification Report (Feature Importance Model):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# 输出特征列表\n",
        "print(\"\\nFeatures used in this model:\")\n",
        "print(importance_features)\n",
        "\n",
        "# 打印样本数量信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Training Set Size: {len(X_train_importance)}\")\n",
        "print(f\"Test Set Size: {len(X_test_importance)}\")\n",
        "print(f\"Number of Features: {len(importance_features)}\")"
      ],
      "metadata": {
        "id": "bAKyH53Be_5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFRhJmKae_5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP（optuna+test set)"
      ],
      "metadata": {
        "id": "UjTpCxh5e_5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Model\n",
        "def objective_shap(trial):\n",
        "    params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [16, 32]),\n",
        "        'n_steps': trial.suggest_categorical('n_steps', [3, 4]),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=trial.suggest_categorical('learning_rate', [0.01, 0.02])),\n",
        "        'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax'\n",
        "    }\n",
        "\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_shap, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "    clf = TabNetClassifier(**params)\n",
        "    clf.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        max_epochs=20,\n",
        "        patience=4,\n",
        "        batch_size=4096\n",
        "    )\n",
        "\n",
        "    return roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
        "\n",
        "# 优化SHAP模型\n",
        "study_shap = optuna.create_study(direction='maximize')\n",
        "study_shap.optimize(objective_shap, n_trials=8)\n",
        "\n",
        "# 获取最佳参数\n",
        "best_params_shap = {\n",
        "    'n_d': study_shap.best_trial.params['n_d'],\n",
        "    'n_steps': study_shap.best_trial.params['n_steps'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=study_shap.best_trial.params['learning_rate']),\n",
        "    'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax'\n",
        "}\n",
        "\n",
        "# 训练最终模型\n",
        "final_model_shap = TabNetClassifier(**best_params_shap)\n",
        "final_model_shap.fit(\n",
        "    X_train_shap, y_train.values,\n",
        "    max_epochs=100,\n",
        "    batch_size=4096\n",
        ")\n",
        "\n",
        "print(\"SHAP Best Parameters:\", study_shap.best_trial.params)\n",
        "print(f\"Best AUC: {study_shap.best_trial.value:.4f}\")"
      ],
      "metadata": {
        "id": "NpsYR97pe_5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练集评估\n",
        "y_train_pred = final_model_shap.predict(X_train_shap)\n",
        "y_train_proba = final_model_shap.predict_proba(X_train_shap)[:, 1]\n",
        "\n",
        "# 测试集评估\n",
        "y_test_pred = final_model_shap.predict(X_test_shap)\n",
        "y_test_proba = final_model_shap.predict_proba(X_test_shap)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "# 训练集ROC\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
        "roc_auc_train = roc_auc_score(y_train, y_train_proba)\n",
        "plt.plot(fpr_train, tpr_train, label=f'Train (AUC = {roc_auc_train:.3f})')\n",
        "# 测试集ROC\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "plt.plot(fpr_test, tpr_test, label=f'Test (AUC = {roc_auc_test:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (SHAP Model)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 训练集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_percentage_train = conf_matrix_train / conf_matrix_train.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_train.shape[0]):\n",
        "    for j in range(conf_matrix_train.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_train[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Training Set Confusion Matrix (SHAP Model)')\n",
        "plt.show()\n",
        "\n",
        "# 测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Test Set Confusion Matrix (SHAP Model)')\n",
        "plt.show()\n",
        "\n",
        "# 输出训练集分类报告\n",
        "print(\"\\nTraining Set Classification Report (SHAP Model):\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nTest Set Classification Report (SHAP Model):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# 输出特征列表\n",
        "print(\"\\nFeatures used in this model:\")\n",
        "print(shap_features)\n",
        "\n",
        "# 打印样本数量信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Training Set Size: {len(X_train_shap)}\")\n",
        "print(f\"Test Set Size: {len(X_test_shap)}\")\n",
        "print(f\"Number of Features: {len(shap_features)}\")"
      ],
      "metadata": {
        "id": "zxRQ1rDxe_5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boruta（optuna+test set)"
      ],
      "metadata": {
        "id": "_RMBkTRee_5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boruta Model\n",
        "def objective_boruta(trial):\n",
        "    params = {\n",
        "        'n_d': trial.suggest_categorical('n_d', [16, 32]),\n",
        "        'n_steps': trial.suggest_categorical('n_steps', [3, 4]),\n",
        "        'optimizer_fn': torch.optim.Adam,\n",
        "        'optimizer_params': dict(lr=trial.suggest_categorical('learning_rate', [0.01, 0.02])),\n",
        "        'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "        'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        'mask_type': 'entmax'\n",
        "    }\n",
        "\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_boruta, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "    clf = TabNetClassifier(**params)\n",
        "    clf.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        max_epochs=20,\n",
        "        patience=4,\n",
        "        batch_size=4096\n",
        "    )\n",
        "\n",
        "    return roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
        "\n",
        "# 优化Boruta模型\n",
        "study_boruta = optuna.create_study(direction='maximize')\n",
        "study_boruta.optimize(objective_boruta, n_trials=8)\n",
        "\n",
        "# 获取最佳参数\n",
        "best_params_boruta = {\n",
        "    'n_d': study_boruta.best_trial.params['n_d'],\n",
        "    'n_steps': study_boruta.best_trial.params['n_steps'],\n",
        "    'optimizer_fn': torch.optim.Adam,\n",
        "    'optimizer_params': dict(lr=study_boruta.best_trial.params['learning_rate']),\n",
        "    'scheduler_params': dict(mode='min', patience=4, min_lr=1e-5, factor=0.5),\n",
        "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    'mask_type': 'entmax'\n",
        "}\n",
        "\n",
        "# 训练最终模型\n",
        "final_model_boruta = TabNetClassifier(**best_params_boruta)\n",
        "final_model_boruta.fit(\n",
        "    X_train_boruta, y_train.values,\n",
        "    max_epochs=100,\n",
        "    batch_size=4096\n",
        ")\n",
        "\n",
        "print(\"Boruta Best Parameters:\", study_boruta.best_trial.params)\n",
        "print(f\"Best AUC: {study_boruta.best_trial.value:.4f}\")"
      ],
      "metadata": {
        "id": "Wu2R9MEye_5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练集评估\n",
        "y_train_pred = final_model_boruta.predict(X_train_boruta)\n",
        "y_train_proba = final_model_boruta.predict_proba(X_train_boruta)[:, 1]\n",
        "\n",
        "# 测试集评估\n",
        "y_test_pred = final_model_boruta.predict(X_test_boruta)\n",
        "y_test_proba = final_model_boruta.predict_proba(X_test_boruta)[:, 1]\n",
        "\n",
        "# 绘制ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "# 训练集ROC\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
        "roc_auc_train = roc_auc_score(y_train, y_train_proba)\n",
        "plt.plot(fpr_train, tpr_train, label=f'Train (AUC = {roc_auc_train:.3f})')\n",
        "# 测试集ROC\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
        "plt.plot(fpr_test, tpr_test, label=f'Test (AUC = {roc_auc_test:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Boruta Model)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 训练集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_percentage_train = conf_matrix_train / conf_matrix_train.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_train.shape[0]):\n",
        "    for j in range(conf_matrix_train.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_train[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Training Set Confusion Matrix (Boruta Model)')\n",
        "plt.show()\n",
        "\n",
        "# 测试集混淆矩阵\n",
        "plt.figure(figsize=(8, 8))\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "conf_matrix_percentage_test = conf_matrix_test / conf_matrix_test.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "for i in range(conf_matrix_test.shape[0]):\n",
        "    for j in range(conf_matrix_test.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage_test[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Test Set Confusion Matrix (Boruta Model)')\n",
        "plt.show()\n",
        "\n",
        "# 输出训练集分类报告\n",
        "print(\"\\nTraining Set Classification Report (Boruta Model):\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "# 输出测试集分类报告\n",
        "print(\"\\nTest Set Classification Report (Boruta Model):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# 输出特征列表\n",
        "print(\"\\nFeatures used in this model:\")\n",
        "print(boruta_features)\n",
        "\n",
        "# 打印样本数量信息\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Training Set Size: {len(X_train_boruta)}\")\n",
        "print(f\"Test Set Size: {len(X_test_boruta)}\")\n",
        "print(f\"Number of Features: {len(boruta_features)}\")"
      ],
      "metadata": {
        "id": "bmGPTKode_5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test set"
      ],
      "metadata": {
        "id": "HSNphP6ie_5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baseline model"
      ],
      "metadata": {
        "id": "dqmIRUe-e_5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 预处理测试集\n",
        "X_test = test_data[selected_columns].drop(columns=['is_canceled'])\n",
        "y_test = test_data['is_canceled']\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 获取测试集预测\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ROC曲线\n",
        "plt.figure(figsize=(12, 8))\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "plt.plot(fpr, tpr, label=f'TabNet (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Combined H1+H2 Test Dataset with TabNet')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 混淆矩阵\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "        plt.text(j + 0.2, i + 0.2, percentage_text, ha='center', va='center', color='green', fontsize=9)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Combined H1+H2 Test Set Confusion Matrix with TabNet')\n",
        "plt.show()\n",
        "\n",
        "# 分类报告\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# 输出测试集大小信息\n",
        "print(\"\\nTest Dataset Information:\")\n",
        "print(f\"Total Test Samples: {len(X_test)}\")\n",
        "print(f\"Class Distribution in Test Set:\")\n",
        "print(y_test.value_counts(normalize=True).round(4) * 100)"
      ],
      "metadata": {
        "id": "tE-FKZa4e_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "pCS_1V2se_5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "shap"
      ],
      "metadata": {
        "id": "dira0auje_5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "boruta"
      ],
      "metadata": {
        "id": "4jYrzBp1e_5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# error analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G9QBbRnh1a4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###H1"
      ],
      "metadata": {
        "id": "IgTHfV0Rgqq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model：random forest baseline/TOP10 features/ TOP10 SHAP model with Optuna"
      ],
      "metadata": {
        "id": "dlWuXmabrNGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_channels(X_test_scaled, y_test, test_data, best_rf):\n",
        "    \"\"\"\n",
        "    对最优化随机森林模型进行分渠道分析\n",
        "    \"\"\"\n",
        "    # 存储每个渠道的结果\n",
        "    channel_results = {}\n",
        "\n",
        "    # 对每个渠道进行分析\n",
        "    for channel in test_data['market_segment'].unique():\n",
        "        # 获取该渠道的数据\n",
        "        channel_mask = test_data['market_segment'] == channel\n",
        "        X_channel = X_test_scaled[channel_mask]\n",
        "        y_channel = y_test[channel_mask]\n",
        "\n",
        "        if len(y_channel) < 50:  # 跳过样本量太小的渠道\n",
        "            continue\n",
        "\n",
        "        # 预测\n",
        "        y_pred = best_rf.predict(X_channel)\n",
        "        y_pred_proba = best_rf.predict_proba(X_channel)[:, 1]\n",
        "\n",
        "        # 计算指标\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_channel, y_pred),\n",
        "            'precision': precision_score(y_channel, y_pred),\n",
        "            'recall': recall_score(y_channel, y_pred),\n",
        "            'f1': f1_score(y_channel, y_pred),\n",
        "            'roc_auc': roc_auc_score(y_channel, y_pred_proba),\n",
        "            'conf_matrix': confusion_matrix(y_channel, y_pred),\n",
        "            'sample_size': len(y_channel)\n",
        "        }\n",
        "\n",
        "        channel_results[channel] = metrics\n",
        "\n",
        "    return channel_results\n",
        "\n",
        "def visualize_channel_results(channel_results):\n",
        "    \"\"\"\n",
        "    创建渠道分析的可视化\n",
        "    \"\"\"\n",
        "    # 1. 准备性能指标数据\n",
        "    metrics_data = []\n",
        "    for channel, metrics in channel_results.items():\n",
        "        metrics_data.append({\n",
        "            'Channel': channel,\n",
        "            'Sample Size': metrics['sample_size'],\n",
        "            'Accuracy': metrics['accuracy'],\n",
        "            'Precision': metrics['precision'],\n",
        "            'Recall': metrics['recall'],\n",
        "            'F1-Score': metrics['f1'],\n",
        "            'ROC AUC': metrics['roc_auc']\n",
        "        })\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "    # 2. 创建性能指标对比图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
        "    x = np.arange(len(metrics_df['Channel']))\n",
        "    width = 0.15\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        plt.bar(x + width*i - width*2,\n",
        "               metrics_df[metric],\n",
        "               width,\n",
        "               label=metric)\n",
        "\n",
        "    plt.xlabel('Channel')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Performance Metrics by Channel')\n",
        "    plt.xticks(x, metrics_df['Channel'], rotation=45)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. 为每个渠道创建混淆矩阵\n",
        "    for channel, metrics in channel_results.items():\n",
        "        conf_matrix = metrics['conf_matrix']\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "        # 添加百分比标注\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "                plt.text(j + 0.2, i + 0.2, percentage_text,\n",
        "                        ha='center', va='center', color='green')\n",
        "\n",
        "        plt.title(f'Confusion Matrix: {channel}\\n(n={metrics[\"sample_size\"]})')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.show()\n",
        "\n",
        "    # 4. 打印详细结果\n",
        "    print(\"\\nDetailed Performance by Channel:\")\n",
        "    print(metrics_df.round(4))\n",
        "\n",
        "    # 5. 错误率分析\n",
        "    print(\"\\nError Analysis by Channel:\")\n",
        "    for channel, metrics in channel_results.items():\n",
        "        conf_matrix = metrics['conf_matrix']\n",
        "        total = conf_matrix.sum()\n",
        "        false_positives = conf_matrix[0, 1]\n",
        "        false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "        print(f\"\\n{channel} (n={metrics['sample_size']}):\")\n",
        "        print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "        print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "        print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# 运行分析\n",
        "channel_results = analyze_channels(X_test_scaled, y_test, H1_test, best_rf)\n",
        "\n",
        "# 可视化结果\n",
        "metrics_df = visualize_channel_results(channel_results)"
      ],
      "metadata": {
        "id": "9VjqwJsWuG3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# 定义渠道映射字典\n",
        "channel_mapping = {\n",
        "    6: 'Online TA',\n",
        "    5: 'Offline TA/TO',\n",
        "    4: 'Groups',\n",
        "    3: 'Direct',\n",
        "    2: 'Corporate',\n",
        "    1: 'Complementary',\n",
        "    0: 'Aviation',\n",
        "    7: 'Undefined'\n",
        "}\n",
        "\n",
        "def analyze_channels(X_test_scaled, y_test, H1_test, best_rf):\n",
        "    \"\"\"\n",
        "    对最优化随机森林模型进行分渠道分析\n",
        "    \"\"\"\n",
        "    # 将数字编码映射回渠道名称\n",
        "    H1_test = H1_test.copy()\n",
        "    H1_test['market_segment'] = H1_test['market_segment'].map(channel_mapping)\n",
        "\n",
        "    # 获取前5个最常见的预订渠道\n",
        "    top_channels = H1_test['market_segment'].value_counts().head(5).index\n",
        "    channel_results = {}\n",
        "\n",
        "    for channel in top_channels:\n",
        "        # 获取该渠道的数据\n",
        "        channel_mask = H1_test['market_segment'] == channel\n",
        "        X_channel = X_test_scaled[channel_mask]\n",
        "        y_channel = y_test[channel_mask]\n",
        "\n",
        "        # 预测\n",
        "        y_pred = best_rf.predict(X_channel)\n",
        "        y_pred_proba = best_rf.predict_proba(X_channel)[:, 1]\n",
        "\n",
        "        # 计算指标\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_channel, y_pred),\n",
        "            'precision': precision_score(y_channel, y_pred),\n",
        "            'recall': recall_score(y_channel, y_pred),\n",
        "            'f1': f1_score(y_channel, y_pred),\n",
        "            'roc_auc': roc_auc_score(y_channel, y_pred_proba),\n",
        "            'conf_matrix': confusion_matrix(y_channel, y_pred),\n",
        "            'sample_size': len(y_channel),\n",
        "            'classification_report': classification_report(y_channel, y_pred, output_dict=True)\n",
        "        }\n",
        "\n",
        "        channel_results[channel] = metrics\n",
        "\n",
        "    return channel_results\n",
        "\n",
        "def visualize_results(channel_results):\n",
        "    \"\"\"\n",
        "    创建可视化比较\n",
        "    \"\"\"\n",
        "    # 准备数据\n",
        "    metrics_data = []\n",
        "    for channel, metrics in channel_results.items():\n",
        "        metrics_data.append({\n",
        "            'Channel': channel,\n",
        "            'Sample Size': metrics['sample_size'],\n",
        "            'Accuracy': metrics['accuracy'],\n",
        "            'Precision': metrics['precision'],\n",
        "            'Recall': metrics['recall'],\n",
        "            'F1-Score': metrics['f1'],\n",
        "            'ROC AUC': metrics['roc_auc']\n",
        "        })\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "    # 1. 创建性能指标热图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
        "    heatmap_data = metrics_df[['Channel'] + metrics_to_plot].set_index('Channel')\n",
        "    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd')\n",
        "    plt.title('Performance Metrics by Channel')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 2. 创建渠道性能对比柱状图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    x = np.arange(len(metrics_df['Channel']))\n",
        "    width = 0.15\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        plt.bar(x + width*i - width*2,\n",
        "               metrics_df[metric],\n",
        "               width,\n",
        "               label=metric)\n",
        "\n",
        "    plt.xlabel('Channel')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Performance Metrics by Channel')\n",
        "    plt.xticks(x, metrics_df['Channel'], rotation=45)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. 创建混淆矩阵可视化\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx, (channel, metrics) in enumerate(channel_results.items()):\n",
        "        conf_matrix = metrics['conf_matrix']\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                   cbar=False, ax=axes[idx])\n",
        "        axes[idx].set_title(f'{channel}\\n(n={metrics[\"sample_size\"]})')\n",
        "        axes[idx].set_xlabel('Predicted')\n",
        "        axes[idx].set_ylabel('Actual')\n",
        "\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                axes[idx].text(j + 0.2, i + 0.2,\n",
        "                             f'{conf_matrix_percentage[i, j]:.1f}%',\n",
        "                             ha='center', va='center', color='green')\n",
        "\n",
        "    # 删除多余的子图\n",
        "    if len(channel_results) < len(axes):\n",
        "        for idx in range(len(channel_results), len(axes)):\n",
        "            fig.delaxes(axes[idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. 打印详细结果\n",
        "    print(\"\\nDetailed Performance by Channel:\")\n",
        "    print(metrics_df.round(4))\n",
        "\n",
        "    # 5. 错误率分析\n",
        "    print(\"\\nError Analysis by Channel:\")\n",
        "    for channel, metrics in channel_results.items():\n",
        "        conf_matrix = metrics['conf_matrix']\n",
        "        total = conf_matrix.sum()\n",
        "        false_positives = conf_matrix[0, 1]\n",
        "        false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "        print(f\"\\n{channel} (n={metrics['sample_size']}):\")\n",
        "        print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "        print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "        print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# 运行分析\n",
        "channel_results = analyze_channels(X_test_scaled, y_test, H1_test, best_rf)\n",
        "\n",
        "# 可视化结果\n",
        "metrics_df = visualize_results(channel_results)"
      ],
      "metadata": {
        "id": "PTiDqnUMucDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###H2"
      ],
      "metadata": {
        "id": "qI9jjlaIgyIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model：random forest TOP10 features model with Optuna& Oversampling&SMOTE"
      ],
      "metadata": {
        "id": "iIjEfofOsdCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (confusion_matrix, roc_curve, classification_report,\n",
        "                           accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score)\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "def analyze_channels_with_sampling(X_train_scaled_top, y_train, H2_train, cv=3):\n",
        "    \"\"\"\n",
        "    Analyze channel performance for SMOTE and Oversampling methods\n",
        "    \"\"\"\n",
        "    # 定义采样方法\n",
        "    samplers = {\n",
        "        'SMOTE': SMOTE(random_state=42),\n",
        "        'Oversample': RandomOverSampler(random_state=42)\n",
        "    }\n",
        "\n",
        "    # 存储所有结果\n",
        "    all_results = {}\n",
        "    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    for method, sampler in samplers.items():\n",
        "        print(f\"\\n=== {method} ===\")\n",
        "        # 对训练数据进行重采样\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "        # 初始化模型\n",
        "        rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "        # 分渠道评估\n",
        "        channel_results = {}\n",
        "        for channel in H2_train['market_segment'].unique():\n",
        "            # 获取该渠道的数据\n",
        "            channel_mask = H2_train['market_segment'] == channel\n",
        "            X_channel = X_train_scaled_top[channel_mask]\n",
        "            y_channel = y_train[channel_mask]\n",
        "\n",
        "            if len(y_channel) < 50:  # 跳过样本量太小的渠道\n",
        "                continue\n",
        "\n",
        "            # 使用交叉验证进行预测\n",
        "            y_pred = cross_val_predict(rf_model, X_channel, y_channel, cv=cv_splitter)\n",
        "            y_pred_proba = cross_val_predict(rf_model, X_channel, y_channel,\n",
        "                                           cv=cv_splitter, method='predict_proba')[:, 1]\n",
        "\n",
        "            # 计算指标\n",
        "            metrics = {\n",
        "                'accuracy': accuracy_score(y_channel, y_pred),\n",
        "                'precision': precision_score(y_channel, y_pred),\n",
        "                'recall': recall_score(y_channel, y_pred),\n",
        "                'f1': f1_score(y_channel, y_pred),\n",
        "                'roc_auc': roc_auc_score(y_channel, y_pred_proba),\n",
        "                'conf_matrix': confusion_matrix(y_channel, y_pred),\n",
        "                'sample_size': len(y_channel)\n",
        "            }\n",
        "\n",
        "            channel_results[channel] = metrics\n",
        "\n",
        "        all_results[method] = channel_results\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def visualize_sampling_results(all_results):\n",
        "    \"\"\"\n",
        "    Create visualizations for sampling methods comparison\n",
        "    \"\"\"\n",
        "    # 1. 创建性能指标比较表格\n",
        "    comparison_data = []\n",
        "    for method, channel_results in all_results.items():\n",
        "        for channel, metrics in channel_results.items():\n",
        "            comparison_data.append({\n",
        "                'Method': method,\n",
        "                'Channel': channel,\n",
        "                'Sample Size': metrics['sample_size'],\n",
        "                'Accuracy': metrics['accuracy'],\n",
        "                'Precision': metrics['precision'],\n",
        "                'Recall': metrics['recall'],\n",
        "                'F1': metrics['f1'],\n",
        "                'ROC AUC': metrics['roc_auc']\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # 2. 每个渠道的混淆矩阵和ROC曲线\n",
        "    for method, channel_results in all_results.items():\n",
        "        for channel, metrics in channel_results.items():\n",
        "            conf_matrix = metrics['conf_matrix']\n",
        "            conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "            for i in range(conf_matrix.shape[0]):\n",
        "                for j in range(conf_matrix.shape[1]):\n",
        "                    percentage_text = f\"{conf_matrix_percentage[i, j]:.1f}%\"\n",
        "                    plt.text(j + 0.2, i + 0.2, percentage_text,\n",
        "                           ha='center', va='center', color='green')\n",
        "            plt.title(f'Confusion Matrix\\n{method} - {channel} (n={metrics[\"sample_size\"]})')\n",
        "            plt.xlabel('Predicted Label')\n",
        "            plt.ylabel('True Label')\n",
        "            plt.show()\n",
        "\n",
        "    # 3. 性能指标比较图\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for idx, metric in enumerate(metrics, 1):\n",
        "        plt.subplot(2, 3, idx)\n",
        "        for method in ['SMOTE', 'Oversample']:\n",
        "            method_data = comparison_df[comparison_df['Method'] == method]\n",
        "            plt.bar(np.arange(len(method_data)) + (0.35 if method == 'SMOTE' else 0),\n",
        "                   method_data[metric],\n",
        "                   width=0.35,\n",
        "                   label=method)\n",
        "        plt.title(f'{metric} by Channel')\n",
        "        plt.xticks(np.arange(len(method_data)), method_data['Channel'], rotation=45)\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. 打印详细结果\n",
        "    print(\"\\nDetailed Results by Channel:\")\n",
        "    for method in ['SMOTE', 'Oversample']:\n",
        "        print(f\"\\n=== {method} ===\")\n",
        "        method_data = comparison_df[comparison_df['Method'] == method]\n",
        "        print(method_data.round(4))\n",
        "\n",
        "        print(f\"\\nError Analysis for {method}:\")\n",
        "        for channel, metrics in all_results[method].items():\n",
        "            conf_matrix = metrics['conf_matrix']\n",
        "            total = conf_matrix.sum()\n",
        "            false_positives = conf_matrix[0, 1]\n",
        "            false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "            print(f\"\\n{channel} (n={metrics['sample_size']}):\")\n",
        "            print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "            print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "            print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "# 运行分析\n",
        "all_results = analyze_channels_with_sampling(X_train_scaled_top, y_train, H2_train)\n",
        "\n",
        "# 可视化结果\n",
        "comparison_df = visualize_sampling_results(all_results)"
      ],
      "metadata": {
        "id": "dz0acew7mmuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "# 定义渠道映射\n",
        "channel_mapping = {\n",
        "    6: 'Online TA',\n",
        "    5: 'Offline TA/TO',\n",
        "    4: 'Groups',\n",
        "    3: 'Direct',\n",
        "    2: 'Corporate',\n",
        "    1: 'Complementary',\n",
        "    0: 'Aviation',\n",
        "    7: 'Undefined'\n",
        "}\n",
        "\n",
        "def analyze_channels_cv(X_train_scaled_top, y_train, H2_train, cv=3):\n",
        "    \"\"\"\n",
        "    使用交叉验证分析各渠道的性能\n",
        "    \"\"\"\n",
        "    # 定义采样方法\n",
        "    samplers = {\n",
        "        'SMOTE': SMOTE(random_state=42),\n",
        "        'Oversample': RandomOverSampler(random_state=42)\n",
        "    }\n",
        "\n",
        "    # 存储所有结果\n",
        "    all_results = {}\n",
        "    cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    # 将数字编码映射回渠道名称\n",
        "    H2_train = H2_train.copy()\n",
        "    H2_train['market_segment'] = H2_train['market_segment'].map(channel_mapping)\n",
        "\n",
        "    for method_name, sampler in samplers.items():\n",
        "        print(f\"\\nProcessing {method_name}...\")\n",
        "        # 对数据进行重采样\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train_scaled_top, y_train)\n",
        "\n",
        "        # 初始化模型\n",
        "        model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "        # 获取前5个最常见的预订渠道\n",
        "        top_channels = H2_train['market_segment'].value_counts().head(5).index\n",
        "        channel_results = {}\n",
        "\n",
        "        for channel in top_channels:\n",
        "            # 获取该渠道的数据\n",
        "            channel_mask = H2_train['market_segment'] == channel\n",
        "            X_channel = X_train_scaled_top[channel_mask]\n",
        "            y_channel = y_train[channel_mask]\n",
        "\n",
        "            # 使用交叉验证进行预测\n",
        "            y_pred = cross_val_predict(model, X_channel, y_channel, cv=cv_splitter)\n",
        "            y_pred_proba = cross_val_predict(model, X_channel, y_channel,\n",
        "                                           cv=cv_splitter, method='predict_proba')[:, 1]\n",
        "\n",
        "            # 计算指标\n",
        "            channel_metrics = {\n",
        "                'accuracy': accuracy_score(y_channel, y_pred),\n",
        "                'roc_auc': roc_auc_score(y_channel, y_pred_proba),\n",
        "                'conf_matrix': confusion_matrix(y_channel, y_pred),\n",
        "                'sample_size': len(y_channel),\n",
        "                'classification_report': classification_report(y_channel, y_pred, output_dict=True)\n",
        "            }\n",
        "\n",
        "            channel_results[channel] = channel_metrics\n",
        "\n",
        "        all_results[method_name] = channel_results\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def visualize_results(all_results):\n",
        "    \"\"\"\n",
        "    创建可视化比较不同方法\n",
        "    \"\"\"\n",
        "    # 准备比较数据\n",
        "    comparison_data = []\n",
        "\n",
        "    for method, channel_results in all_results.items():\n",
        "        for channel, metrics in channel_results.items():\n",
        "            comparison_data.append({\n",
        "                'Method': method,\n",
        "                'Channel': channel,\n",
        "                'Accuracy': metrics['accuracy'],\n",
        "                'ROC AUC': metrics['roc_auc'],\n",
        "                'Precision': metrics['classification_report']['weighted avg']['precision'],\n",
        "                'Recall': metrics['classification_report']['weighted avg']['recall'],\n",
        "                'F1-Score': metrics['classification_report']['weighted avg']['f1-score'],\n",
        "                'Sample Size': metrics['sample_size']\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # 1. 创建性能指标热图\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    metrics_to_plot = ['Accuracy', 'ROC AUC', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "    for idx, method in enumerate(['SMOTE', 'Oversample']):\n",
        "        plt.subplot(1, 2, idx+1)\n",
        "        method_data = comparison_df[comparison_df['Method'] == method].set_index('Channel')[metrics_to_plot]\n",
        "        sns.heatmap(method_data, annot=True, fmt='.3f', cmap='YlOrRd')\n",
        "        plt.title(f'{method} Performance Metrics by Channel')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 2. 创建各指标的比较柱状图\n",
        "    channels = comparison_df['Channel'].unique()\n",
        "    for metric in metrics_to_plot:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        x = np.arange(len(channels))\n",
        "        width = 0.35\n",
        "\n",
        "        smote_values = comparison_df[comparison_df['Method'] == 'SMOTE'][metric].values\n",
        "        over_values = comparison_df[comparison_df['Method'] == 'Oversample'][metric].values\n",
        "\n",
        "        plt.bar(x - width/2, smote_values, width, label='SMOTE')\n",
        "        plt.bar(x + width/2, over_values, width, label='Oversample')\n",
        "\n",
        "        plt.xlabel('Channel')\n",
        "        plt.ylabel(metric)\n",
        "        plt.title(f'{metric} Comparison by Channel and Method')\n",
        "        plt.xticks(x, channels, rotation=45)\n",
        "        plt.legend()\n",
        "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # 3. 打印性能比较表格\n",
        "    comparison_pivot = comparison_df.pivot(index='Channel',\n",
        "                                         columns='Method',\n",
        "                                         values=['Accuracy', 'ROC AUC', 'Precision', 'Recall', 'F1-Score'])\n",
        "    print(\"\\nDetailed Performance Comparison:\")\n",
        "    print(comparison_pivot.round(4))\n",
        "\n",
        "    # 4. 错误率分析\n",
        "    print(\"\\nError Analysis by Channel and Method:\")\n",
        "    for method, channel_results in all_results.items():\n",
        "        print(f\"\\n=== {method} ===\")\n",
        "        for channel, metrics in channel_results.items():\n",
        "            conf_matrix = metrics['conf_matrix']\n",
        "            total = conf_matrix.sum()\n",
        "            false_positives = conf_matrix[0, 1]\n",
        "            false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "            print(f\"\\n{channel}:\")\n",
        "            print(f\"Sample Size: {metrics['sample_size']}\")\n",
        "            print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "            print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "            print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "# 运行分析\n",
        "all_results = analyze_channels_cv(X_train_scaled_top, y_train, H2_train)\n",
        "\n",
        "# 可视化结果\n",
        "comparison_df = visualize_results(all_results)"
      ],
      "metadata": {
        "id": "JZ5WmY6pm8K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###H1+H2"
      ],
      "metadata": {
        "id": "xnaI3GT8gyhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model：random forest TOP10 features model with Optuna"
      ],
      "metadata": {
        "id": "7E6GBEzVsfuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "def analyze_top_channels(X_test_scaled_top, y_test, test_data, best_model, n_top_channels=5):\n",
        "    \"\"\"\n",
        "    Analyze model performance for top n booking channels\n",
        "    \"\"\"\n",
        "    # 获取前5个最常见的预订渠道\n",
        "    top_channels = test_data['market_segment'].value_counts().head(n_top_channels).index\n",
        "\n",
        "    # 存储每个渠道的结果\n",
        "    channel_results = {}\n",
        "\n",
        "    # 对每个渠道进行分析\n",
        "    for channel in top_channels:\n",
        "        # 创建渠道掩码\n",
        "        channel_mask = test_data['market_segment'] == channel\n",
        "\n",
        "        # 获取该渠道的测试数据\n",
        "        X_channel = X_test_scaled_top[channel_mask]\n",
        "        y_channel = y_test[channel_mask]\n",
        "\n",
        "        # 进行预测\n",
        "        y_pred_channel = best_model.predict(X_channel)\n",
        "        y_pred_proba_channel = best_model.predict_proba(X_channel)[:, 1]\n",
        "\n",
        "        # 计算指标\n",
        "        channel_metrics = {\n",
        "            'accuracy': accuracy_score(y_channel, y_pred_channel),\n",
        "            'roc_auc': roc_auc_score(y_channel, y_pred_proba_channel),\n",
        "            'conf_matrix': confusion_matrix(y_channel, y_pred_channel),\n",
        "            'sample_size': len(y_channel),\n",
        "            'classification_report': classification_report(y_channel, y_pred_channel, output_dict=True)\n",
        "        }\n",
        "\n",
        "        channel_results[channel] = channel_metrics\n",
        "\n",
        "    return channel_results\n",
        "\n",
        "def visualize_channel_results(channel_results):\n",
        "    \"\"\"\n",
        "    创建可视化来比较不同渠道的表现\n",
        "    \"\"\"\n",
        "    # 准备数据\n",
        "    channels = list(channel_results.keys())\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Channel': channels,\n",
        "        'Accuracy': [channel_results[c]['accuracy'] for c in channels],\n",
        "        'ROC AUC': [channel_results[c]['roc_auc'] for c in channels],\n",
        "        'Sample Size': [channel_results[c]['sample_size'] for c in channels],\n",
        "        'Precision': [channel_results[c]['classification_report']['weighted avg']['precision'] for c in channels],\n",
        "        'Recall': [channel_results[c]['classification_report']['weighted avg']['recall'] for c in channels],\n",
        "        'F1-Score': [channel_results[c]['classification_report']['weighted avg']['f1-score'] for c in channels]\n",
        "    })\n",
        "\n",
        "    # 创建性能指标热图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics_heatmap = metrics_df.set_index('Channel').drop('Sample Size', axis=1)\n",
        "    sns.heatmap(metrics_heatmap, annot=True, fmt='.3f', cmap='YlOrRd')\n",
        "    plt.title('Performance Metrics by Channel')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 创建混淆矩阵可视化\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx, channel in enumerate(channels):\n",
        "        conf_matrix = channel_results[channel]['conf_matrix']\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                   cbar=False, ax=axes[idx])\n",
        "        axes[idx].set_title(f'{channel}\\n(n={channel_results[channel][\"sample_size\"]})')\n",
        "        axes[idx].set_xlabel('Predicted')\n",
        "        axes[idx].set_ylabel('Actual')\n",
        "\n",
        "        # 添加百分比标注\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                axes[idx].text(j + 0.2, i + 0.2,\n",
        "                             f'{conf_matrix_percentage[i, j]:.1f}%',\n",
        "                             ha='center', va='center', color='green')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# 运行分析\n",
        "channel_results = analyze_top_channels(X_test_scaled_top, y_test, test_data, best_model)\n",
        "metrics_df = visualize_channel_results(channel_results)\n",
        "\n",
        "# 打印详细结果\n",
        "print(\"\\nDetailed Channel Performance Summary:\")\n",
        "print(\"\\nSample Sizes:\")\n",
        "for channel in channel_results:\n",
        "    print(f\"{channel}: {channel_results[channel]['sample_size']} samples\")\n",
        "\n",
        "print(\"\\nPerformance Metrics by Channel:\")\n",
        "print(metrics_df.round(4))\n",
        "\n",
        "# 计算和显示错误率分析\n",
        "print(\"\\nError Analysis by Channel:\")\n",
        "for channel in channel_results:\n",
        "    conf_matrix = channel_results[channel]['conf_matrix']\n",
        "    total = conf_matrix.sum()\n",
        "    false_positives = conf_matrix[0, 1]\n",
        "    false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "    print(f\"\\n{channel}:\")\n",
        "    print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "    print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "    print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")"
      ],
      "metadata": {
        "id": "qBd1LC34g7Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# 创建渠道映射字典\n",
        "channel_mapping = {\n",
        "    6: 'Online TA',\n",
        "    5: 'Offline TA/TO',\n",
        "    4: 'Groups',\n",
        "    3: 'Direct',\n",
        "    2: 'Corporate',\n",
        "    1: 'Complementary',\n",
        "    0: 'Aviation',\n",
        "    7: 'Undefined'\n",
        "}\n",
        "\n",
        "def analyze_top_channels(X_test_scaled_top, y_test, test_data, best_model, n_top_channels=5):\n",
        "    \"\"\"\n",
        "    Analyze model performance for top n booking channels\n",
        "    \"\"\"\n",
        "    # 将数字编码映射回渠道名称\n",
        "    test_data = test_data.copy()\n",
        "    test_data['market_segment'] = test_data['market_segment'].map(channel_mapping)\n",
        "\n",
        "    # 获取前5个最常见的预订渠道\n",
        "    top_channels = test_data['market_segment'].value_counts().head(n_top_channels).index\n",
        "\n",
        "    # 存储每个渠道的结果\n",
        "    channel_results = {}\n",
        "\n",
        "    # 对每个渠道进行分析\n",
        "    for channel in top_channels:\n",
        "        channel_mask = test_data['market_segment'] == channel\n",
        "        X_channel = X_test_scaled_top[channel_mask]\n",
        "        y_channel = y_test[channel_mask]\n",
        "\n",
        "        y_pred_channel = best_model.predict(X_channel)\n",
        "        y_pred_proba_channel = best_model.predict_proba(X_channel)[:, 1]\n",
        "\n",
        "        channel_metrics = {\n",
        "            'accuracy': accuracy_score(y_channel, y_pred_channel),\n",
        "            'roc_auc': roc_auc_score(y_channel, y_pred_proba_channel),\n",
        "            'conf_matrix': confusion_matrix(y_channel, y_pred_channel),\n",
        "            'sample_size': len(y_channel),\n",
        "            'classification_report': classification_report(y_channel, y_pred_channel, output_dict=True)\n",
        "        }\n",
        "\n",
        "        channel_results[channel] = channel_metrics\n",
        "\n",
        "    return channel_results\n",
        "\n",
        "def visualize_channel_results(channel_results):\n",
        "    \"\"\"\n",
        "    创建可视化来比较不同渠道的表现\n",
        "    \"\"\"\n",
        "    # 准备数据\n",
        "    channels = list(channel_results.keys())\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Channel': channels,\n",
        "        'Accuracy': [channel_results[c]['accuracy'] for c in channels],\n",
        "        'ROC AUC': [channel_results[c]['roc_auc'] for c in channels],\n",
        "        'Sample Size': [channel_results[c]['sample_size'] for c in channels],\n",
        "        'Precision': [channel_results[c]['classification_report']['weighted avg']['precision'] for c in channels],\n",
        "        'Recall': [channel_results[c]['classification_report']['weighted avg']['recall'] for c in channels],\n",
        "        'F1-Score': [channel_results[c]['classification_report']['weighted avg']['f1-score'] for c in channels]\n",
        "    })\n",
        "\n",
        "    # 1. 创建性能指标热图\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics_heatmap = metrics_df.set_index('Channel').drop('Sample Size', axis=1)\n",
        "    sns.heatmap(metrics_heatmap, annot=True, fmt='.3f', cmap='YlOrRd')\n",
        "    plt.title('Performance Metrics by Channel')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 2. 创建混淆矩阵可视化\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx, channel in enumerate(channels):\n",
        "        conf_matrix = channel_results[channel]['conf_matrix']\n",
        "        conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1).reshape(-1, 1) * 100\n",
        "\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                   cbar=False, ax=axes[idx])\n",
        "        axes[idx].set_title(f'{channel}\\n(n={channel_results[channel][\"sample_size\"]})')\n",
        "        axes[idx].set_xlabel('Predicted')\n",
        "        axes[idx].set_ylabel('Actual')\n",
        "\n",
        "        for i in range(conf_matrix.shape[0]):\n",
        "            for j in range(conf_matrix.shape[1]):\n",
        "                axes[idx].text(j + 0.2, i + 0.2,\n",
        "                             f'{conf_matrix_percentage[i, j]:.1f}%',\n",
        "                             ha='center', va='center', color='green')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. 新增柱状图比较\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
        "\n",
        "    x = np.arange(len(channels))\n",
        "    width = 0.15\n",
        "    multiplier = 0\n",
        "\n",
        "    for metric in metrics_to_plot:\n",
        "        offset = width * multiplier\n",
        "        plt.bar(x + offset, metrics_df[metric], width, label=metric)\n",
        "        multiplier += 1\n",
        "\n",
        "    plt.xlabel('Channel')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Performance Metrics Comparison by Channel')\n",
        "    plt.xticks(x + width * 2, channels, rotation=45)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# 运行分析\n",
        "channel_results = analyze_top_channels(X_test_scaled_top, y_test, test_data, best_model)\n",
        "metrics_df = visualize_channel_results(channel_results)\n",
        "\n",
        "# 打印详细结果\n",
        "print(\"\\nDetailed Channel Performance Summary:\")\n",
        "print(\"\\nSample Sizes:\")\n",
        "for channel in channel_results:\n",
        "    print(f\"{channel}: {channel_results[channel]['sample_size']} samples\")\n",
        "\n",
        "print(\"\\nPerformance Metrics by Channel:\")\n",
        "print(metrics_df.round(4))\n",
        "\n",
        "# 计算和显示错误率分析\n",
        "print(\"\\nError Analysis by Channel:\")\n",
        "for channel in channel_results:\n",
        "    conf_matrix = channel_results[channel]['conf_matrix']\n",
        "    total = conf_matrix.sum()\n",
        "    false_positives = conf_matrix[0, 1]\n",
        "    false_negatives = conf_matrix[1, 0]\n",
        "\n",
        "    print(f\"\\n{channel}:\")\n",
        "    print(f\"False Positive Rate: {false_positives/total*100:.2f}%\")\n",
        "    print(f\"False Negative Rate: {false_negatives/total*100:.2f}%\")\n",
        "    print(f\"Total Error Rate: {(false_positives + false_negatives)/total*100:.2f}%\")"
      ],
      "metadata": {
        "id": "HOC_gA0QafJk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}